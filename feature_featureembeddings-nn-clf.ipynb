{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:11:49.905568Z",
     "iopub.status.busy": "2021-01-17T07:11:49.904487Z",
     "iopub.status.idle": "2021-01-17T07:11:49.937114Z",
     "shell.execute_reply": "2021-01-17T07:11:49.936506Z"
    },
    "papermill": {
     "duration": 0.07802,
     "end_time": "2021-01-17T07:11:49.937264",
     "exception": false,
     "start_time": "2021-01-17T07:11:49.859244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jane-embed-nn-model-rishi/jane_embed_nn_model_rishi.pt\n",
      "/kaggle/input/jane-street-market-prediction/example_sample_submission.csv\n",
      "/kaggle/input/jane-street-market-prediction/features.csv\n",
      "/kaggle/input/jane-street-market-prediction/example_test.csv\n",
      "/kaggle/input/jane-street-market-prediction/train.csv\n",
      "/kaggle/input/jane-street-market-prediction/janestreet/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/jane-street-market-prediction/janestreet/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:11:49.997111Z",
     "iopub.status.busy": "2021-01-17T07:11:49.995896Z",
     "iopub.status.idle": "2021-01-17T07:12:01.093058Z",
     "shell.execute_reply": "2021-01-17T07:12:01.091965Z"
    },
    "papermill": {
     "duration": 11.130218,
     "end_time": "2021-01-17T07:12:01.093209",
     "exception": false,
     "start_time": "2021-01-17T07:11:49.962991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import random\n",
    "from   tqdm import tqdm\n",
    "from   sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import psutil\n",
    "import datatable as dt\n",
    "from   collections import namedtuple\n",
    "from   sklearn.pipeline import Pipeline\n",
    "from   sklearn.impute import SimpleImputer\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from   sklearn.utils import shuffle\n",
    "import datetime\n",
    "import time\n",
    "from   sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score\n",
    "from   sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from   torch.autograd import Variable\n",
    "from   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from   transformers import TrainingArguments\n",
    "from   transformers import AdamW, BertConfig\n",
    "from   transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:12:01.152389Z",
     "iopub.status.busy": "2021-01-17T07:12:01.151666Z",
     "iopub.status.idle": "2021-01-17T07:12:01.154126Z",
     "shell.execute_reply": "2021-01-17T07:12:01.154623Z"
    },
    "papermill": {
     "duration": 0.035526,
     "end_time": "2021-01-17T07:12:01.154810",
     "exception": false,
     "start_time": "2021-01-17T07:12:01.119284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device (\"cuda:0\") if torch.cuda.is_available () else torch.device (\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:12:01.227580Z",
     "iopub.status.busy": "2021-01-17T07:12:01.226819Z",
     "iopub.status.idle": "2021-01-17T07:15:04.406804Z",
     "shell.execute_reply": "2021-01-17T07:15:04.407414Z"
    },
    "papermill": {
     "duration": 183.227039,
     "end_time": "2021-01-17T07:15:04.407604",
     "exception": false,
     "start_time": "2021-01-17T07:12:01.180565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00988744, -0.26318205, -0.36673057, ..., -0.84821191,\n",
       "         0.25335237, -0.93007367],\n",
       "       [ 0.99020936,  0.45488523,  1.14220532, ..., -0.11128175,\n",
       "        -0.5165198 , -0.06252076],\n",
       "       [ 0.99020936, -0.50483589, -0.66426957, ...,  0.86778577,\n",
       "         0.2184735 ,  0.44230275],\n",
       "       ...,\n",
       "       [ 0.99020936,  0.97064345,  1.08314151, ...,  0.77612205,\n",
       "         0.86782538,  0.78815366],\n",
       "       [ 0.99020936, -0.17157952,  0.22668871, ...,  1.78624778,\n",
       "        -0.06381184,  1.71826599],\n",
       "       [ 0.99020936, -0.68133082, -1.0726015 , ..., -1.74929201,\n",
       "        -0.08053834, -1.79724075]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {\n",
    "    'date'      : 'int64', \n",
    "    'weight'    : 'float64',\n",
    "    'resp'      : 'float64',\n",
    "    'ts_id'     : 'int64',  \n",
    "    'feature_0' : 'float64'\n",
    "}\n",
    "for i in range (1, 130):\n",
    "    k = 'feature_' + str (i)\n",
    "    dtype[k] = 'float32'\n",
    "    \n",
    "X = pd.read_csv ('../input/jane-street-market-prediction/train.csv', dtype=dtype)\n",
    "f_columns = [c for c in X.columns if \"feature\" in c]\n",
    "y = (X['resp'] > 0).astype ('int8')\n",
    "X.drop (columns=['weight', 'resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'date', 'ts_id'], inplace=True)\n",
    "preprocess_pipe =  Pipeline ([\n",
    "    (\"imputer\", SimpleImputer (missing_values=np.nan, strategy='mean')),\n",
    "    # (\"stand\",   StandardScaler())  - don't use this !\n",
    "])\n",
    "X = preprocess_pipe.fit_transform (X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.05)\n",
    "del X, y\n",
    "gc.collect ()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:04.467221Z",
     "iopub.status.busy": "2021-01-17T07:15:04.466428Z",
     "iopub.status.idle": "2021-01-17T07:15:04.469691Z",
     "shell.execute_reply": "2021-01-17T07:15:04.469104Z"
    },
    "papermill": {
     "duration": 0.03619,
     "end_time": "2021-01-17T07:15:04.469832",
     "exception": false,
     "start_time": "2021-01-17T07:15:04.433642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'feature'  : 'str', \n",
    "    'tag_0'    : 'int8'\n",
    "}\n",
    "for i in range (1, 29):\n",
    "    k = 'tag_' + str (i)\n",
    "    dtype[k] = 'int8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:04.533683Z",
     "iopub.status.busy": "2021-01-17T07:15:04.532975Z",
     "iopub.status.idle": "2021-01-17T07:15:04.570454Z",
     "shell.execute_reply": "2021-01-17T07:15:04.569753Z"
    },
    "papermill": {
     "duration": 0.073824,
     "end_time": "2021-01-17T07:15:04.570583",
     "exception": false,
     "start_time": "2021-01-17T07:15:04.496759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_0</th>\n",
       "      <th>tag_1</th>\n",
       "      <th>tag_2</th>\n",
       "      <th>tag_3</th>\n",
       "      <th>tag_4</th>\n",
       "      <th>tag_5</th>\n",
       "      <th>tag_6</th>\n",
       "      <th>tag_7</th>\n",
       "      <th>tag_8</th>\n",
       "      <th>tag_9</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_19</th>\n",
       "      <th>tag_20</th>\n",
       "      <th>tag_21</th>\n",
       "      <th>tag_22</th>\n",
       "      <th>tag_23</th>\n",
       "      <th>tag_24</th>\n",
       "      <th>tag_25</th>\n",
       "      <th>tag_26</th>\n",
       "      <th>tag_27</th>\n",
       "      <th>tag_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag_0  tag_1  tag_2  tag_3  tag_4  tag_5  tag_6  tag_7  tag_8  tag_9  ...  \\\n",
       "0      0      0      0      0      0      0      0      0      0      0  ...   \n",
       "1      0      0      0      0      0      0      1      1      0      0  ...   \n",
       "2      0      0      0      0      0      0      1      1      0      1  ...   \n",
       "3      0      0      0      0      0      0      1      0      1      0  ...   \n",
       "4      0      0      0      0      0      0      1      0      1      1  ...   \n",
       "\n",
       "   tag_19  tag_20  tag_21  tag_22  tag_23  tag_24  tag_25  tag_26  tag_27  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   tag_28  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv ('../input/jane-street-market-prediction/features.csv', usecols=range(1,30), dtype=dtype)\n",
    "N_FEATURES  = features_df.shape[0]  # the features.csv has 130 features (1st row) = no of features in train.csv (feature_0 to feature_129)\n",
    "N_FEAT_TAGS = features_df.shape[1]  # the features.csv has 29 tags\n",
    "features_df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:04.903842Z",
     "iopub.status.busy": "2021-01-17T07:15:04.903118Z",
     "iopub.status.idle": "2021-01-17T07:15:04.909695Z",
     "shell.execute_reply": "2021-01-17T07:15:04.909078Z"
    },
    "papermill": {
     "duration": 0.31119,
     "end_time": "2021-01-17T07:15:04.909853",
     "exception": false,
     "start_time": "2021-01-17T07:15:04.598663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del features_df\n",
    "gc.collect ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:04.970229Z",
     "iopub.status.busy": "2021-01-17T07:15:04.969473Z",
     "iopub.status.idle": "2021-01-17T07:15:04.974183Z",
     "shell.execute_reply": "2021-01-17T07:15:04.973612Z"
    },
    "papermill": {
     "duration": 0.037139,
     "end_time": "2021-01-17T07:15:04.974317",
     "exception": false,
     "start_time": "2021-01-17T07:15:04.937178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_FEATURES, N_FEAT_TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027192,
     "end_time": "2021-01-17T07:15:05.029344",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.002152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.097340Z",
     "iopub.status.busy": "2021-01-17T07:15:05.096618Z",
     "iopub.status.idle": "2021-01-17T07:15:05.099770Z",
     "shell.execute_reply": "2021-01-17T07:15:05.099139Z"
    },
    "papermill": {
     "duration": 0.042667,
     "end_time": "2021-01-17T07:15:05.099892",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.057225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utilities for my custom trainer\n",
    "\n",
    "def format_time (elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    \n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str (datetime.timedelta (seconds=elapsed_rounded))\n",
    "\n",
    "def compute_metrics (labels, pred_logits):\n",
    "    \n",
    "    preds   = pred_logits.argmax (-1)             #;print ('labels.shape=', labels.shape, 'preds.shape=', preds.shape, 'pred_logits.shape=', pred_logits.shape)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support (labels, preds, average='macro')\n",
    "    acc     = accuracy_score (labels, preds)\n",
    "    mcc     = matthews_corrcoef (labels, preds)   # matthews correlation coefficient\n",
    "    softmax = nn.Softmax (dim=1)\n",
    "    pred_pr = softmax (torch.tensor (pred_logits))\n",
    "    auc     = roc_auc_score (labels, pred_pr[:, 1])\n",
    "    metrics = {\n",
    "        'mcc'      : mcc,\n",
    "        'accuracy' : acc,\n",
    "        'f1'       : f1,\n",
    "        'precision': precision,\n",
    "        'recall'   : recall,\n",
    "        'auc'      : auc\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.162244Z",
     "iopub.status.busy": "2021-01-17T07:15:05.160592Z",
     "iopub.status.idle": "2021-01-17T07:15:05.261042Z",
     "shell.execute_reply": "2021-01-17T07:15:05.261667Z"
    },
    "papermill": {
     "duration": 0.133983,
     "end_time": "2021-01-17T07:15:05.261859",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.127876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyTrainer:\n",
    "    \n",
    "    def __init__(self, model, args, train_dataset, eval_dataset, compute_metrics=compute_metrics):\n",
    "        \n",
    "        self.model           = model\n",
    "        self.args            = args\n",
    "        self.train_dataset   = train_dataset\n",
    "        self.eval_dataset    = eval_dataset\n",
    "        self.compute_metrics = compute_metrics\n",
    "        self.isTrained       = False\n",
    "        self.device          = self.get_device_type ()\n",
    "        \n",
    "        # Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "        # I believe the 'W' stands for 'Weight Decay fix\"\n",
    "        self.optimizer = AdamW (model.parameters (),\n",
    "                           lr  = args.learning_rate,\n",
    "                           eps = args.adam_epsilon # args.adam_epsilon  - default is 1e-8 is “a very small number to prevent any division by zero\"\n",
    "        )\n",
    "\n",
    "        # Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "        # We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "        # training data.\n",
    "        self.epochs = self.args.num_train_epochs\n",
    "        self.train_dataloader, self.validation_dataloader, self.lr_scheduler, self.num_training_steps = self.get_dataLoaders ()        \n",
    "        return\n",
    "    \n",
    "    def get_device_type (self):\n",
    "        \n",
    "        # If there's a GPU available...\n",
    "        if torch.cuda.is_available ():    \n",
    "\n",
    "            # Tell PyTorch to use the GPU.    \n",
    "            device = torch.device (\"cuda\")\n",
    "            print('There are %d GPU(s) available.' % torch.cuda.device_count ())\n",
    "            print('We will use the GPU:', torch.cuda.get_device_name (0))\n",
    "        # If not...\n",
    "        else:\n",
    "            print('No GPU available, using the CPU instead.')\n",
    "            device = torch.device (\"cpu\")\n",
    "        return device\n",
    "    \n",
    "    def get_dataLoaders (self):        \n",
    "        \n",
    "        # Create the DataLoaders for our training and validation sets.\n",
    "        if isinstance (self.train_dataset, torch.utils.data.IterableDataset):\n",
    "            train_sampler = None\n",
    "        else:\n",
    "            train_sampler = RandomSampler (self.train_dataset)           # Better use RandomSampler\n",
    "        train_dataloader  = DataLoader (\n",
    "                    self.train_dataset,                                  # The training samples.\n",
    "                    sampler     = train_sampler,                           \n",
    "                    batch_size  = self.args.per_device_train_batch_size,\n",
    "                    num_workers = 8    # TODO: uncomment this\n",
    "        )\n",
    "        # train_dataloader  = DataLoader (self.train_dataset, batch_size=self.args.per_device_train_batch_size) # TODO: comment this\n",
    "        validation_dataloader = None\n",
    "        if self.eval_dataset:\n",
    "            \n",
    "            # For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "            validation_dataloader = DataLoader (\n",
    "                        self.eval_dataset,             # The validation/dev samples.\n",
    "                        sampler     = SequentialSampler (self.eval_dataset),\n",
    "                        batch_size  = self.args.per_device_eval_batch_size,\n",
    "                        num_workers = 8    # TODO: uncomment this\n",
    "            )\n",
    "            # validation_dataloader  = DataLoader (self.eval_dataset, batch_size=self.args.per_device_eval_batch_size) # TODO: comment this\n",
    "            \n",
    "        # Total number of training steps is [number of batches] x [number of epochs]. \n",
    "        # (Note that this is not the same as the number of training samples).\n",
    "        num_training_steps = len (train_dataloader) * self.epochs\n",
    "\n",
    "        # Create the learning rate scheduler.\n",
    "        lr_scheduler = get_linear_schedule_with_warmup (self.optimizer, \n",
    "                                                        num_warmup_steps   = self.args.warmup_steps, # Default value in run_glue.py\n",
    "                                                        num_training_steps = num_training_steps)\n",
    "        return train_dataloader, validation_dataloader, lr_scheduler, num_training_steps\n",
    "    \n",
    "    \n",
    "    def test_iterate_dataloader (self):\n",
    "        \n",
    "        for step, batch in enumerate (self.train_dataloader):\n",
    "            print (step)\n",
    "            print (batch)\n",
    "            break\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def train (self):\n",
    "        \n",
    "        # This training code is based on the `run_glue.py` script here:\n",
    "        # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "        \n",
    "        # Set the seed value all over the place to make this reproducible.\n",
    "        seed_val = 42\n",
    "        random.seed (seed_val)\n",
    "        np.random.seed (seed_val)\n",
    "        torch.manual_seed (seed_val)\n",
    "        torch.cuda.manual_seed_all (seed_val)\n",
    "\n",
    "        # We'll store a number of quantities such as training and validation loss, \n",
    "        # validation accuracy, and timings.\n",
    "        training_stats = []\n",
    "        # Measure the total training time for the whole run.\n",
    "        total_t0 = time.time ()\n",
    "        # inint min_val_loss to a large val, if after each epoch eval-loss < min_val_loss, then save the model\n",
    "        min_val_loss   = 9999\n",
    "        min_train_loss = 9999\n",
    "        step = 0\n",
    "        \n",
    "        # For each epoch...\n",
    "        for epoch_i in range (0, self.epochs):\n",
    "\n",
    "            # ========================================\n",
    "            #               Training\n",
    "            # ========================================\n",
    "\n",
    "            # Perform one full pass over the training set.\n",
    "\n",
    "            print(\"\")\n",
    "            print('======== Epoch {:} / {:} ========'.format (epoch_i + 1, self.epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time ()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            # Put the model into training mode. Don't be mislead--the call to \n",
    "            # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "            # `dropout` and `batchnorm` layers behave differently during training\n",
    "            # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "            self.model.train ()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for stp, batch in enumerate (self.train_dataloader):\n",
    "\n",
    "                step += 1\n",
    "                # Progress update every 40 batches.\n",
    "                # print ('batch =', batch)\n",
    "                if step % 50 == 0 and not step == 0:\n",
    "                    \n",
    "                    # Calculate elapsed time in minutes.\n",
    "                    elapsed = format_time (time.time() - t0)\n",
    "                    # Report progress.\n",
    "                    print ('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len (self.train_dataloader), elapsed))\n",
    "                if (self.args.max_steps > 0 and self.args.max_steps < step) or  \\\n",
    "                   (self.args.eval_steps> 0 and step % self.args.eval_steps==0 and step>0):\n",
    "                    \n",
    "                    avg_train_loss = total_train_loss / step\n",
    "                    training_time = format_time (time.time () - t0)\n",
    "                    if self.validation_dataloader:\n",
    "                        \n",
    "                        print (\"Running Validation...\")\n",
    "                        avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time = self.evaluate ()\n",
    "                        training_stats.append ({\n",
    "                                'epoch'         : epoch_i + 1,\n",
    "                                'training_loss' : avg_train_loss,\n",
    "                                'eval_loss'     : avg_val_loss,\n",
    "                                'eval_f1'       : avg_val_f1,\n",
    "                                'eval_mcc'      : avg_val_mcc, \n",
    "                                'eval_precision': avg_val_precision,\n",
    "                                'eval_recall'   : avg_val_recall,\n",
    "                                'eval_auc'      : avg_val_auc, \n",
    "                                'eval_accuracy' : avg_val_accuracy,\n",
    "                                'training_time' : training_time,\n",
    "                                'eval_time'     : validation_time                   \n",
    "                        })\n",
    "                        # save this model if the eval loss decreases from the minimum so far\n",
    "                        if avg_val_loss < min_val_loss: \n",
    "\n",
    "                            min_val_loss = avg_val_loss\n",
    "                            torch.save (model.state_dict (), \"jane_embed_nn_model_rishi.pt\")     # TODO: uncomment this\n",
    "                    \n",
    "                    if self.args.max_steps > 0 and self.args.max_steps < step :\n",
    "                        \n",
    "                        print (\"\")\n",
    "                        print (\"Training complete!\")\n",
    "                        print (\"Total training took {:} (h:mm:ss)\".format (format_time (time.time ()-total_t0)))\n",
    "                        self.isTrained = True\n",
    "                        self.plot_train_stats_regression (training_stats)\n",
    "                        return training_stats\n",
    "                    \n",
    "                self.model.zero_grad ()        \n",
    "\n",
    "                # Perform a forward pass (evaluate the model on this training batch).\n",
    "                # The documentation for this `model` function is here: \n",
    "                # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "                # It returns different numbers of parameters depending on what arguments\n",
    "                # arge given and what flags are set. For our useage here, it returns\n",
    "                # the loss (because we provided labels) and the \"logits\"--the model\n",
    "                # outputs prior to activation.\n",
    "                # loss, logits = self.model (b_inputs, .., labels=b_labels)\n",
    "                # print ('batch: \\n', batch)\n",
    "                # for k in batch:\n",
    "                #     batch[k] = batch[k].to (self.device)\n",
    "                batch['features'] = batch['features'].to (self.device).float ()\n",
    "                if 'labels' in  batch:\n",
    "                    batch['labels'] = batch['labels'].to (self.device).long ()\n",
    "                output    = self.model (**batch)\n",
    "                loss      = output.loss\n",
    "                logits    = output.logits\n",
    "                \n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "                # single value; the `.item()` function just returns the Python value \n",
    "                # from the tensor.\n",
    "                total_train_loss += loss.item ()\n",
    "                # Perform a backward pass to calculate the gradients.\n",
    "                loss.backward ()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This is to help prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                # Update parameters and take a step using the computed gradient.\n",
    "                # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "                # modified based on their gradients, the learning rate, etc.\n",
    "                self.optimizer.step ()\n",
    "                # Update the learning rate.\n",
    "                self.lr_scheduler.step ()\n",
    "            # At the end of each epoch measure stats and eval:\n",
    "            # Calculate the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len (self.train_dataloader)\n",
    "            # Measure how long this epoch took.\n",
    "            training_time = format_time (time.time () - t0)            \n",
    "            print (\"  Average training loss: {0:.2f}\".format (avg_train_loss))\n",
    "            print (\"  Training epcoh took: {:}\".format (training_time))\n",
    "            \n",
    "            if self.validation_dataloader:\n",
    "                \n",
    "                print (\"\\n  Running Validation...\")\n",
    "                avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time = self.evaluate ()\n",
    "                # Record all statistics from this epoch.\n",
    "                training_stats.append ({\n",
    "                        'epoch'         : epoch_i + 1,\n",
    "                        'training_loss' : avg_train_loss,\n",
    "                        'eval_loss'     : avg_val_loss,\n",
    "                        'eval_f1'       : avg_val_f1,\n",
    "                        'eval_mcc'      : avg_val_mcc, \n",
    "                        'eval_precision': avg_val_precision,\n",
    "                        'eval_recall'   : avg_val_recall,\n",
    "                        'eval_auc'      : avg_val_auc, \n",
    "                        'eval_accuracy' : avg_val_accuracy,\n",
    "                        'training_time' : training_time,\n",
    "                        'eval_time'     : validation_time                   \n",
    "                })\n",
    "                # save this epoch's model if the eval loss decreases from the minimum so far\n",
    "                # if avg_val_loss < min_val_loss:                    \n",
    "                #     min_val_loss = avg_val_loss\n",
    "                #     torch.save (model.state_dict (), \"jane_embed_nn_model_rishi.pt\")     # TODO: uncomment this\n",
    "                if avg_val_auc < min_val_loss:\n",
    "                    min_val_loss = avg_val_auc\n",
    "                    torch.save (model.state_dict (), \"jane_nn_clf_rishi.pt\")     # TODO: uncomment this\n",
    "            else:\n",
    "                \n",
    "                training_stats.append ({\n",
    "                    'epoch'         : epoch_i + 1,\n",
    "                    'training_loss' : avg_train_loss,\n",
    "                    'training_time' : training_time,\n",
    "                })\n",
    "                if avg_train_loss < min_train_loss: \n",
    "                    \n",
    "                    min_train_loss = avg_train_loss\n",
    "                    torch.save (model.state_dict (), \"jane_embed_nn_model_rishi.pt\")     # TODO: uncomment this\n",
    "        print (\"\")\n",
    "        print (\"Training complete!\")\n",
    "        print (\"Total training took {:} (h:mm:ss)\".format (format_time (time.time ()-total_t0)))\n",
    "        self.isTrained = True\n",
    "        self.model.eval ()\n",
    "        try:\n",
    "            self.plot_train_stats (training_stats)\n",
    "        except:\n",
    "            pass\n",
    "        return training_stats\n",
    "    \n",
    "    def evaluate (self):\n",
    "        \n",
    "        t0 = time.time ()\n",
    "        # Put the model in evaluation mode--the dropout layers behave differently\n",
    "        # during evaluation.\n",
    "        self.model.eval ()\n",
    "\n",
    "        # Tracking variables \n",
    "        total_eval_mcc       = 0\n",
    "        total_eval_f1        = 0\n",
    "        total_eval_precision = 0\n",
    "        total_eval_recall    = 0\n",
    "        total_eval_auc       = 0\n",
    "        total_eval_accuracy  = 0\n",
    "        total_eval_loss      = 0\n",
    "        nb_eval_steps        = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in self.validation_dataloader:\n",
    "            with torch.no_grad ():\n",
    "                \n",
    "                # Forward pass, calculate logit predictions.\n",
    "                # for k in batch:\n",
    "                #     batch[k] = batch[k].to (self.device)\n",
    "                batch['features'] = batch['features'].to (self.device).float ()\n",
    "                batch['labels'] = batch['labels'].to (self.device).long ()\n",
    "                output    = self.model (**batch)\n",
    "                loss      = output.loss\n",
    "                logits    = output.logits\n",
    "\n",
    "            # Accumulate the validation loss.\n",
    "            total_eval_loss += loss.item ()\n",
    "            # Move logits and labels to CPU\n",
    "            logits    = logits.detach ().cpu ().numpy ()\n",
    "            label_ids = batch['labels'].detach ().cpu ().numpy ()            \n",
    "\n",
    "            # Calculate the accuracy for this batch of test sentences, and\n",
    "            # accumulate it over all batches.\n",
    "            metrics = self.compute_metrics (label_ids, logits)\n",
    "            total_eval_mcc       += metrics['mcc']\n",
    "            total_eval_f1        += metrics['f1']\n",
    "            total_eval_precision += metrics['precision']\n",
    "            total_eval_recall    += metrics['recall']\n",
    "            total_eval_auc       += metrics['auc']\n",
    "            total_eval_accuracy  += metrics['accuracy']\n",
    "\n",
    "        # Report the final accuracy for this validation run.\n",
    "        avg_val_f1 = total_eval_f1 / len (self.validation_dataloader)\n",
    "        print (\"  F1: {0:.3f}\".format (avg_val_f1))\n",
    "        avg_val_mcc = total_eval_mcc / len (self.validation_dataloader)\n",
    "        print (\"  MCC: {0:.3f}\".format (avg_val_mcc))\n",
    "        avg_val_precision = total_eval_precision / len (self.validation_dataloader)\n",
    "        print (\"  Precision: {0:.3f}\".format (avg_val_precision))\n",
    "        avg_val_recall = total_eval_recall / len (self.validation_dataloader)\n",
    "        print (\"  Recall: {0:.3f}\".format (avg_val_recall))\n",
    "        avg_val_auc = total_eval_auc / len (self.validation_dataloader)\n",
    "        print (\"  AUC: {0:.3f}\".format (avg_val_auc))\n",
    "        avg_val_accuracy = total_eval_accuracy / len (self.validation_dataloader)\n",
    "        print (\"  Accuracy: {0:.3f}\".format (avg_val_accuracy))\n",
    "        # Calculate the average loss over all of the batches.\n",
    "        avg_val_loss = total_eval_loss / len (self.validation_dataloader)\n",
    "        # Measure how long the validation run took.\n",
    "        validation_time = format_time (time.time () - t0)\n",
    "        print (\"  Validation Loss: {0:.2f}\".format (avg_val_loss))\n",
    "        print (\"  Validation took: {:}\".format (validation_time))            \n",
    "        return avg_val_loss, avg_val_f1, avg_val_mcc, avg_val_auc, avg_val_precision, avg_val_recall, avg_val_accuracy, validation_time\n",
    "    \n",
    "    def plot_train_stats (self, training_stats):\n",
    "        \"\"\"\n",
    "        Draw Classification Report curve\n",
    "        \"\"\"\n",
    "        \n",
    "        mccs   = accuracies = f1_scores = precisions = recalls = auc = losses = epochs = -1\n",
    "        epochs = training_stats[-1]['epoch']\n",
    "        if 'eval_mcc' in training_stats[0]:\n",
    "            mccs       = [e['eval_mcc'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=mccs,       label='val_mcc')\n",
    "        if 'eval_accuracy' in training_stats[0]:\n",
    "            accuracies = [e['eval_accuracy'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=accuracies, label='val_accuracy')\n",
    "        if 'eval_f1' in training_stats[0]:\n",
    "            f1_scores  = [e['eval_f1'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=f1_scores,  label='val_f1') \n",
    "        if 'eval_precision' in training_stats[0]:\n",
    "            precisions = [e['eval_precision'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=precisions, label='val_precision')\n",
    "        if 'eval_recall' in training_stats[0]:\n",
    "            recalls    = [e['eval_recall'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=recalls,    label='val_recall')\n",
    "        if 'eval_auc' in training_stats[0]:\n",
    "            auc        = [e['eval_auc'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=mccs,       label='val_auc')\n",
    "        if 'eval_loss' in training_stats[0]:\n",
    "            losses     = [e['eval_loss'] for e in training_stats]\n",
    "        if 'training_loss'  in training_stats[0]:\n",
    "            tr_losses  = [e['training_loss'] for e in training_stats]\n",
    "            sns.lineplot (x=np.arange(1, epochs + 1), y=tr_losses,  label='tr_losses')\n",
    "            \n",
    "        plt.show ()\n",
    "        print ('mccs       :', mccs)\n",
    "        print ('accuracies :', accuracies)\n",
    "        print ('precisions :', precisions)\n",
    "        print ('recalls    :', recalls)\n",
    "        print ('f1_scores  :', f1_scores)\n",
    "        print ('auc        :', auc)\n",
    "        print ('losses     :', losses)\n",
    "        print ('tr_losses  :', tr_losses)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def getTrainedModel (self):\n",
    "        \n",
    "        if self.isTrained:\n",
    "            return self.model\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def predict (self, prediction_dataset, isRemoveLabels=True):\n",
    "        \"\"\"\n",
    "        return: pred_logits, true_labels, metrics (if true 'labels' are input in the prediction_dataset)\n",
    "        \"\"\"     \n",
    "        \n",
    "        prediction_sampler    = SequentialSampler (prediction_dataset)\n",
    "        prediction_dataloader = DataLoader (prediction_dataset, sampler=prediction_sampler, batch_size=self.args.per_device_eval_batch_size)\n",
    "        print ('Predicting labels for {:,} test sentences...'.format (len (prediction_dataset)))\n",
    "        \n",
    "        # Put model in evaluation mode\n",
    "        self.model.eval ()\n",
    "\n",
    "        # Tracking variables \n",
    "        predictions = []\n",
    "        # true_labels = []\n",
    "        \n",
    "        # Predict \n",
    "        for batch in prediction_dataloader:\n",
    "            \n",
    "            if 'labels' in batch and isRemoveLabels:\n",
    "                batch.pop ('labels')\n",
    "            # Add batch to GPU\n",
    "            # batch = {t:batch[t].to (self.device) for t in batch}\n",
    "            batch['features'] = batch['features'].to (self.device).float ()\n",
    "            if 'labels' in  batch:\n",
    "                batch['labels'] = batch['labels'].to (self.device).long ()\n",
    "\n",
    "            # Unpack the inputs from our dataloader\n",
    "            # b_input_ids, b_input_mask, b_segment_ids = batch\n",
    "\n",
    "            # Telling the model not to compute or store gradients, saving memory and \n",
    "            # speeding up prediction\n",
    "            with torch.no_grad ():\n",
    "                # Forward pass, calculate logit predictions\n",
    "                outputs = model (**batch)\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach ().cpu ().numpy ()\n",
    "            # label_ids = b_labels.to ('cpu').numpy ()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            predictions.append (logits)\n",
    "            # true_labels.append (label_ids)\n",
    "            print ('Done predictions for ', len(predictions), '/', len(prediction_dataloader), 'batches')\n",
    "        print ('Done prediction')\n",
    "        \n",
    "        # Combine the results across all batches to get the predicted logits\n",
    "        pred_logits = np.concatenate (predictions, axis=0)\n",
    "        # For each sample, pick the label (0,1,2) with the highest score.\n",
    "        # pred_labels = np.argmax (pred_logits, axis=1).flatten()\n",
    "        # returns the predicted logits\n",
    "        return pred_logits, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.028083,
     "end_time": "2021-01-17T07:15:05.317996",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.289913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026847,
     "end_time": "2021-01-17T07:15:05.372474",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.345627",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.430132Z",
     "iopub.status.busy": "2021-01-17T07:15:05.429349Z",
     "iopub.status.idle": "2021-01-17T07:15:05.441565Z",
     "shell.execute_reply": "2021-01-17T07:15:05.442147Z"
    },
    "papermill": {
     "duration": 0.042824,
     "end_time": "2021-01-17T07:15:05.442311",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.399487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a custom map type dataset\n",
    "class JaneDataset (torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, labels=None):\n",
    "        \n",
    "        if isinstance (df, pd.DataFrame):\n",
    "            df.reset_index (drop=True, inplace=True)\n",
    "        if isinstance (labels, pd.Series):\n",
    "            labels.reset_index (drop=True, inplace=True)\n",
    "        self.df     = df\n",
    "        self.labels = labels \n",
    "        return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len (self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor (idx):\n",
    "            idx = idx.tolist ()\n",
    "        \n",
    "        # date    = self.df['date'][idx]\n",
    "        # weight  = self.df['weight'][idx]\n",
    "        # ts_id   = self.df['ts_id'][idx]\n",
    "        # f_columns = ['feature_' + str(i) for i in range (N_FEATURES)]\n",
    "        \n",
    "        sample   = None\n",
    "        if isinstance (self.df, pd.DataFrame):\n",
    "            features = np.array (self.df.loc[idx, f_columns])\n",
    "        else:\n",
    "            features = self.df[idx]\n",
    "            \n",
    "        if self.labels is not None:\n",
    "            sample = {'features': features, 'labels': self.labels[idx]}\n",
    "        else:\n",
    "            sample = {'features': features}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.500266Z",
     "iopub.status.busy": "2021-01-17T07:15:05.499525Z",
     "iopub.status.idle": "2021-01-17T07:15:05.509062Z",
     "shell.execute_reply": "2021-01-17T07:15:05.508484Z"
    },
    "papermill": {
     "duration": 0.039604,
     "end_time": "2021-01-17T07:15:05.509194",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.469590",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': array([ 0.99020936,  0.45488523,  1.14220532, -0.46109841, -0.69591482,\n",
       "         2.17180943,  3.43166545,  0.27561172,  0.56094649,  0.07329252,\n",
       "         0.66792549,  0.10045709,  0.4377427 ,  0.11000273,  0.48315788,\n",
       "         0.35590271,  1.13773093,  0.66757191,  1.21704322,  0.46739139,\n",
       "         1.07378239,  0.45396536,  0.71267536,  0.62650399,  1.21338058,\n",
       "         0.70800706,  1.40783248, -0.5993255 , -0.8900598 , -0.66415203,\n",
       "        -1.02049148, -0.93568765, -1.3608721 , -0.48649584, -0.67498783,\n",
       "        -0.65147075, -0.94648011,  0.5299806 ,  0.88831872, -1.23724001,\n",
       "        -2.0778781 , -0.11436184, -0.58321078, -0.78137148,  0.62433535,\n",
       "         0.14767936, -0.2611789 , -0.48056425, -0.25946355, -0.1224427 ,\n",
       "        -0.10387388, -0.01271486, -0.45165288, -0.57711435, -0.09756256,\n",
       "        -0.22600755, -0.07484625, -0.18279358, -0.09470379, -0.08361176,\n",
       "        -0.08798811, -0.12599854, -0.23565959, -0.22941114, -0.23045503,\n",
       "         0.08710806,  0.02977019,  0.16629928,  0.1642322 ,  0.36540347,\n",
       "         1.52553206,  1.08327813, -0.37069806, -0.56268359, -0.1873151 ,\n",
       "        -0.47212425, -0.6263264 ,  1.23936798, -0.46439943, -0.55019718,\n",
       "        -0.19421694, -0.53703013, -0.60151352,  1.21555519, -0.00497125,\n",
       "        -0.71289165,  0.10285823, -0.34235961, -0.82636852,  0.60986261,\n",
       "        -0.09107403, -0.75459364,  0.084522  , -0.46011932, -0.7170471 ,\n",
       "         0.49465967,  0.15180759,  0.40535115,  0.2817646 ,  0.1223998 ,\n",
       "         0.3318151 ,  0.32997862,  0.08305292,  0.35594817,  0.12464482,\n",
       "         0.09649446,  0.420404  ,  0.29080995,  0.17511429, -0.03804224,\n",
       "         0.14343374, -0.13026601, -0.02947096,  0.55342515, -0.0238161 ,\n",
       "        -0.03608256,  0.17359249, -0.1142807 , -0.0497523 ,  0.32508823,\n",
       "        -0.62009004, -0.19937873, -0.56968559, -0.18184256, -0.62560381,\n",
       "        -0.23592411, -0.5428454 , -0.11128175, -0.5165198 , -0.06252076]),\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = JaneDataset (X_train, y_train)\n",
    "eval_dataset  = JaneDataset (X_test,  y_test)\n",
    "train_dataset[1]  # ['features'].shape                         # output    = self.model (date, weight, ts_id, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027495,
     "end_time": "2021-01-17T07:15:05.564313",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.536818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.630329Z",
     "iopub.status.busy": "2021-01-17T07:15:05.629614Z",
     "iopub.status.idle": "2021-01-17T07:15:05.633432Z",
     "shell.execute_reply": "2021-01-17T07:15:05.632786Z"
    },
    "papermill": {
     "duration": 0.041743,
     "end_time": "2021-01-17T07:15:05.633554",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.591811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN (nn.Module):\n",
    "    \n",
    "    def __init__(self, inputCount=1024, outputCount=0, hiddenLayerCounts=[128, 64, 32], drop_prob=0.2, nonlin=nn.ReLU ()):\n",
    "        \n",
    "        super(FFN, self).__init__()\n",
    "        \n",
    "        self.nonlin     = nonlin\n",
    "        self.dropout    = nn.Dropout (drop_prob)\n",
    "        self.dense1     = nn.Linear (inputCount, hiddenLayerCounts[0])\n",
    "        self.batchnorm1 = nn.BatchNorm1d (hiddenLayerCounts[0])\n",
    "        self.dense2     = nn.Linear(hiddenLayerCounts[0], hiddenLayerCounts[1])\n",
    "        self.batchnorm2 = nn.BatchNorm1d (hiddenLayerCounts[1])\n",
    "        self.dense3     = nn.Linear(hiddenLayerCounts[1], hiddenLayerCounts[2])\n",
    "        self.batchnorm3 = nn.BatchNorm1d (hiddenLayerCounts[2])        \n",
    "        self.outDense   = nn.Linear (hiddenLayerCounts[-1], outputCount)\n",
    "        self.outActivtn = None\n",
    "        if outputCount == 1 or outputCount == 2:\n",
    "            self.outActivtn = nn.Sigmoid ()\n",
    "        elif outputCount > 0:\n",
    "            self.outActivtn = nn.Softmax (dim=-1)\n",
    "        return\n",
    "\n",
    "    def forward (self, X, **kwargs):\n",
    "        \n",
    "        X = self.dropout (self.nonlin (self.batchnorm1 (self.dense1 (X))))\n",
    "        X = self.dropout (self.nonlin (self.batchnorm2 (self.dense2 (X))))\n",
    "        X = self.dropout (self.nonlin (self.batchnorm3 (self.dense3 (X))))\n",
    "        if self.outActivtn:\n",
    "            X = self.outActivtn (self.outDense (X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.714601Z",
     "iopub.status.busy": "2021-01-17T07:15:05.713878Z",
     "iopub.status.idle": "2021-01-17T07:15:05.717014Z",
     "shell.execute_reply": "2021-01-17T07:15:05.716374Z"
    },
    "papermill": {
     "duration": 0.055967,
     "end_time": "2021-01-17T07:15:05.717138",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.661171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Clf_Model (nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_dim=N_FEAT_TAGS, csv_file='../input/jane-street-market-prediction/features.csv'):\n",
    "        \n",
    "        super (Clf_Model, self).__init__()\n",
    "        global N_FEAT_TAGS\n",
    "        N_FEAT_TAGS = 29\n",
    "        \n",
    "        # store the features to tags mapping as a datframe tdf, feature_i mapping is in tdf[i, :]\n",
    "        dtype = {'tag_0' : 'int8'}\n",
    "        for i in range (1, 29):\n",
    "            k = 'tag_' + str (i)\n",
    "            dtype[k] = 'int8'\n",
    "        t_df = pd.read_csv (csv_file, usecols=range (1,N_FEAT_TAGS+1), dtype=dtype)\n",
    "        t_df['tag_29'] = np.array ([1] + ([0] * (t_df.shape[0]-1)) ).astype ('int8')\n",
    "        self.features_tag_matrix = torch.tensor (t_df.to_numpy ())\n",
    "        N_FEAT_TAGS += 1\n",
    "        \n",
    "        # print ('self.features_tag_matrix =', self.features_tag_matrix)\n",
    "        \n",
    "        # embeddings for the tags. Each feature is taken a an embedding which is an avg. of its' tag embeddings\n",
    "        self.embed_dim     = embed_dim\n",
    "        self.tag_embedding = nn.Embedding (N_FEAT_TAGS+1, embed_dim) # create a special tag if not known tag for any feature\n",
    "        self.tag_weights   = nn.Linear (N_FEAT_TAGS, 1)\n",
    "        \n",
    "        self.dropout      = nn.Dropout (0.2)\n",
    "        self.layer_normal = nn.LayerNorm (embed_dim) \n",
    "        self.ffn          = FFN (inputCount=(N_FEATURES+embed_dim), outputCount=0, hiddenLayerCounts=[(N_FEATURES+embed_dim)]*3, drop_prob=0.2, nonlin=nn.ReLU ())\n",
    "        self.outDense     = nn.Linear (N_FEATURES+embed_dim, 2)\n",
    "        self.outActivtn   = nn.LogSoftmax (dim=1)\n",
    "        self.criterion    = nn.NLLLoss ()\n",
    "        return\n",
    "    \n",
    "    def features2emb (self):\n",
    "        \"\"\"\n",
    "        idx : int feature index 0 to N_FEATURES-1 (129)\n",
    "        \"\"\"\n",
    "        \n",
    "        all_tag_idxs = torch.LongTensor (np.arange (N_FEAT_TAGS)).to (DEVICE)              # (29,)\n",
    "        tag_bools    = self.features_tag_matrix                                # (130, 29)\n",
    "        # print ('tag_bools.shape =', tag_bools.size())\n",
    "        f_emb        = self.tag_embedding (all_tag_idxs).repeat (130, 1, 1)    #;print ('1. f_emb =', f_emb) # (29, 7) * (130, 1, 1) = (130, 29, 7)\n",
    "        # print ('f_emb.shape =', f_emb.size())\n",
    "        f_emb        = f_emb * tag_bools[:, :, None]                           #;print ('2. f_emb =', f_emb) # (130, 29, 7) * (130, 29, 1) = (130, 29, 7)\n",
    "        # print ('f_emb.shape =', f_emb.size())\n",
    "        \n",
    "        # Take avg. of all the present tag's embeddings to get the embedding for a feature\n",
    "        s = torch.sum (tag_bools, dim=1)                                       # (130,)\n",
    "        # print ('s =', s)              \n",
    "        f_emb = torch.sum (f_emb, dim=-2) / s[:, None]                         # (130, 7)\n",
    "        # print ('f_emb =', f_emb)        \n",
    "        # print ('f_emb.shape =', f_emb.shape)\n",
    "        \n",
    "        # take a linear combination of the present tag's embeddings\n",
    "        # f_emb = f_emb.permute (0, 2, 1)                                        # (130, 7, 29)\n",
    "        # f_emb = self.tag_weights (f_emb)                      #;print ('3. f_emb =', f_emb)                 # (130, 7, 1)\n",
    "        # f_emb = torch.squeeze (f_emb, dim=-1)                 #;print ('4. f_emb =', f_emb)                 # (130, 7)\n",
    "        return f_emb\n",
    "    \n",
    "    def forward (self, features, labels=None):\n",
    "        \"\"\"\n",
    "        when you call `model (x ,y, z, ...)` then this method is invoked\n",
    "        \"\"\"\n",
    "        \n",
    "        features   = features.view (-1, N_FEATURES)\n",
    "        f_emb      = self.features2emb ()                                #;print ('5. f_emb =', f_emb); print ('6. features =', features) # (130, 7)\n",
    "        # print ('features.shape =', features.shape, 'f_emb.shape =', f_emb.shape)\n",
    "        features_2 = torch.matmul (features, f_emb)                      #;print ('7. features =', features) # (1, 130) * (130, 7) = (1, 7)\n",
    "        # print ('features.shape =', features.shape)\n",
    "        \n",
    "        # Concatenate the two features (features + their embeddings)\n",
    "        features   = np.hstack ((features, features_2))        \n",
    "        \n",
    "        x          = self.ffn (features)                               #;print ('8. x.shape = ', x.shape, 'x =', x)   # (1, 7) -> (1, 7)\n",
    "        # x        = self.layer_normal (x + features)                  #;print ('9. x.shape = ', x.shape, 'x =', x)   # (1, 7) -> (1, 2)\n",
    "        out_logits = self.outDense (x)                                 #;print ('10. out_logits.shape = ', out_logits.shape, 'out_logits =', out_logits)\n",
    "        # out_logits = torch.squeeze (out_logits, dim=-1)\n",
    "        if labels is None:\n",
    "            \n",
    "            # return a named tuple\n",
    "            Logits     = namedtuple ('Logits',['logits'])\n",
    "            out_logits = Logits (out_logits)\n",
    "            return out_logits                                          # you can access the value as out_logits.logits        \n",
    "        \n",
    "        log_ps     = self.outActivtn (out_logits)                      # ;print('labels.size=', labels.size(), 'log_ps.size=', log_ps.size())\n",
    "        # calculate loss, this is used for back propagation later\n",
    "        batchLoss  = self.criterion (log_ps, labels)\n",
    "        \n",
    "        # return a named tuple\n",
    "        Loss_Logits = namedtuple ('Loss_Logits',['loss','logits'])\n",
    "        loss_logits = Loss_Logits (batchLoss, out_logits)              # you can access the value as out_logits.loss, out_logits.logits\n",
    "        #print ('11. out_logits =', out_logits)\n",
    "        return loss_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.781671Z",
     "iopub.status.busy": "2021-01-17T07:15:05.780504Z",
     "iopub.status.idle": "2021-01-17T07:15:05.855677Z",
     "shell.execute_reply": "2021-01-17T07:15:05.853942Z"
    },
    "papermill": {
     "duration": 0.110396,
     "end_time": "2021-01-17T07:15:05.855858",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.745462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Clf_Model ()\n",
    "\n",
    "# This code version 1 broke after training, hence reloading that model here.\n",
    "# try:\n",
    "#     model.load_state_dict (torch.load (\"../input/jane-embed-nn-model-rishi/jane_embed_nn_model_rishi.pt\"))\n",
    "# except:\n",
    "#     model.load_state_dict (torch.load (\"../input/jane-embed-nn-model-rishi/jane_embed_nn_model_rishi.pt\", map_location='cpu'))\n",
    "model = model.float ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.921488Z",
     "iopub.status.busy": "2021-01-17T07:15:05.920767Z",
     "iopub.status.idle": "2021-01-17T07:15:05.924777Z",
     "shell.execute_reply": "2021-01-17T07:15:05.923667Z"
    },
    "papermill": {
     "duration": 0.040406,
     "end_time": "2021-01-17T07:15:05.924945",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.884539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments (\n",
    "\n",
    "    output_dir      = './results',     # output directory\n",
    "    num_train_epochs= 400,             # 400 for training from scratch\n",
    "    warmup_steps    = 50,              # for lr scheduling\n",
    "    eval_steps      = 0,               # Number of update steps between two evaluations, if <=0 then eval at end of each epoch\n",
    "    max_steps       = 0,               # If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs\n",
    "    learning_rate   = 1e-2,            # Actually = 1e-2 for training from scratch, without using the jane_embed_nn_model_rishi.pt\n",
    "    # adam_epsilon  = 1e-8             # - default is 1e-8 is “a very small number to prevent any division by zero\"\n",
    "    per_device_train_batch_size= 5000, # batch size per device during training\n",
    "    per_device_eval_batch_size = 5000, # batch size for evaluation\n",
    ")\n",
    "trainer = MyTrainer (\n",
    "    \n",
    "    model         = model,           # the instantiated 🤗 Transformers model to be trained\n",
    "    args          = training_args,   # training arguments, defined above\n",
    "    train_dataset = train_dataset,   # training dataset\n",
    "    eval_dataset  = eval_dataset,    # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:05.986557Z",
     "iopub.status.busy": "2021-01-17T07:15:05.985886Z",
     "iopub.status.idle": "2021-01-17T07:15:05.989478Z",
     "shell.execute_reply": "2021-01-17T07:15:05.988836Z"
    },
    "papermill": {
     "duration": 0.036017,
     "end_time": "2021-01-17T07:15:05.989598",
     "exception": false,
     "start_time": "2021-01-17T07:15:05.953581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.test_iterate_dataloader ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T07:15:06.052664Z",
     "iopub.status.busy": "2021-01-17T07:15:06.051960Z",
     "iopub.status.idle": "2021-01-17T10:17:37.111051Z",
     "shell.execute_reply": "2021-01-17T10:17:37.101863Z"
    },
    "papermill": {
     "duration": 10951.093298,
     "end_time": "2021-01-17T10:17:37.111205",
     "exception": false,
     "start_time": "2021-01-17T07:15:06.017907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 250 ========\n",
      "Training...\n",
      "  Batch    50  of    431.    Elapsed: 0:00:05.\n",
      "  Batch   100  of    431.    Elapsed: 0:00:09.\n",
      "  Batch   150  of    431.    Elapsed: 0:00:14.\n",
      "  Batch   200  of    431.    Elapsed: 0:00:19.\n",
      "  Batch   250  of    431.    Elapsed: 0:00:23.\n",
      "  Batch   300  of    431.    Elapsed: 0:00:27.\n",
      "  Batch   350  of    431.    Elapsed: 0:00:32.\n",
      "  Batch   400  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.475\n",
      "  MCC: 0.036\n",
      "  Precision: 0.522\n",
      "  Recall: 0.515\n",
      "  AUC: 0.529\n",
      "  Accuracy: 0.518\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 250 ========\n",
      "Training...\n",
      "  Batch   450  of    431.    Elapsed: 0:00:02.\n",
      "  Batch   500  of    431.    Elapsed: 0:00:06.\n",
      "  Batch   550  of    431.    Elapsed: 0:00:10.\n",
      "  Batch   600  of    431.    Elapsed: 0:00:15.\n",
      "  Batch   650  of    431.    Elapsed: 0:00:19.\n",
      "  Batch   700  of    431.    Elapsed: 0:00:23.\n",
      "  Batch   750  of    431.    Elapsed: 0:00:28.\n",
      "  Batch   800  of    431.    Elapsed: 0:00:33.\n",
      "  Batch   850  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.495\n",
      "  MCC: 0.037\n",
      "  Precision: 0.520\n",
      "  Recall: 0.517\n",
      "  AUC: 0.531\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 250 ========\n",
      "Training...\n",
      "  Batch   900  of    431.    Elapsed: 0:00:03.\n",
      "  Batch   950  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 1,000  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 1,050  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 1,100  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 1,150  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 1,200  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 1,250  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.490\n",
      "  MCC: 0.039\n",
      "  Precision: 0.522\n",
      "  Recall: 0.517\n",
      "  AUC: 0.531\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 4 / 250 ========\n",
      "Training...\n",
      "  Batch 1,300  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 1,350  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 1,400  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 1,450  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 1,500  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 1,550  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 1,600  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 1,650  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 1,700  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.505\n",
      "  MCC: 0.038\n",
      "  Precision: 0.520\n",
      "  Recall: 0.518\n",
      "  AUC: 0.531\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 5 / 250 ========\n",
      "Training...\n",
      "  Batch 1,750  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 1,800  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 1,850  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 1,900  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 1,950  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 2,000  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 2,050  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 2,100  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 2,150  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.480\n",
      "  MCC: 0.036\n",
      "  Precision: 0.521\n",
      "  Recall: 0.515\n",
      "  AUC: 0.530\n",
      "  Accuracy: 0.518\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 6 / 250 ========\n",
      "Training...\n",
      "  Batch 2,200  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 2,250  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 2,300  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 2,350  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 2,400  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 2,450  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 2,500  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 2,550  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.474\n",
      "  MCC: 0.040\n",
      "  Precision: 0.524\n",
      "  Recall: 0.516\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 7 / 250 ========\n",
      "Training...\n",
      "  Batch 2,600  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 2,650  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 2,700  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 2,750  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 2,800  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 2,850  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 2,900  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 2,950  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 3,000  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.409\n",
      "  MCC: 0.034\n",
      "  Precision: 0.531\n",
      "  Recall: 0.509\n",
      "  AUC: 0.529\n",
      "  Accuracy: 0.514\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 8 / 250 ========\n",
      "Training...\n",
      "  Batch 3,050  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 3,100  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 3,150  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 3,200  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 3,250  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 3,300  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 3,350  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 3,400  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.482\n",
      "  MCC: 0.040\n",
      "  Precision: 0.524\n",
      "  Recall: 0.517\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 9 / 250 ========\n",
      "Training...\n",
      "  Batch 3,450  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 3,500  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 3,550  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 3,600  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 3,650  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 3,700  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 3,750  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 3,800  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 3,850  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.416\n",
      "  MCC: 0.039\n",
      "  Precision: 0.534\n",
      "  Recall: 0.511\n",
      "  AUC: 0.530\n",
      "  Accuracy: 0.516\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 10 / 250 ========\n",
      "Training...\n",
      "  Batch 3,900  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 3,950  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 4,000  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 4,050  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 4,100  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 4,150  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 4,200  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 4,250  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 4,300  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.438\n",
      "  MCC: 0.037\n",
      "  Precision: 0.528\n",
      "  Recall: 0.513\n",
      "  AUC: 0.531\n",
      "  Accuracy: 0.517\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 11 / 250 ========\n",
      "Training...\n",
      "  Batch 4,350  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 4,400  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 4,450  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 4,500  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 4,550  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 4,600  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 4,650  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 4,700  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.420\n",
      "  MCC: 0.040\n",
      "  Precision: 0.534\n",
      "  Recall: 0.512\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.517\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 12 / 250 ========\n",
      "Training...\n",
      "  Batch 4,750  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 4,800  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 4,850  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 4,900  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 4,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 5,000  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 5,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 5,100  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 5,150  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.428\n",
      "  MCC: 0.042\n",
      "  Precision: 0.533\n",
      "  Recall: 0.513\n",
      "  AUC: 0.532\n",
      "  Accuracy: 0.518\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 13 / 250 ========\n",
      "Training...\n",
      "  Batch 5,200  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 5,250  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 5,300  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 5,350  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 5,400  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 5,450  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 5,500  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 5,550  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 5,600  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.473\n",
      "  MCC: 0.039\n",
      "  Precision: 0.524\n",
      "  Recall: 0.516\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 14 / 250 ========\n",
      "Training...\n",
      "  Batch 5,650  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 5,700  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 5,750  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 5,800  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 5,850  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 5,900  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 5,950  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 6,000  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.492\n",
      "  MCC: 0.040\n",
      "  Precision: 0.523\n",
      "  Recall: 0.518\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 15 / 250 ========\n",
      "Training...\n",
      "  Batch 6,050  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 6,100  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 6,150  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 6,200  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 6,250  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 6,300  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 6,350  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 6,400  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 6,450  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.505\n",
      "  MCC: 0.042\n",
      "  Precision: 0.522\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 16 / 250 ========\n",
      "Training...\n",
      "  Batch 6,500  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 6,550  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 6,600  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 6,650  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 6,700  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 6,750  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 6,800  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 6,850  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.466\n",
      "  MCC: 0.040\n",
      "  Precision: 0.525\n",
      "  Recall: 0.516\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 17 / 250 ========\n",
      "Training...\n",
      "  Batch 6,900  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 6,950  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 7,000  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 7,050  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 7,100  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 7,150  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 7,200  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 7,250  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 7,300  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.452\n",
      "  MCC: 0.042\n",
      "  Precision: 0.529\n",
      "  Recall: 0.515\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 18 / 250 ========\n",
      "Training...\n",
      "  Batch 7,350  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 7,400  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 7,450  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 7,500  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 7,550  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 7,600  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 7,650  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 7,700  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 7,750  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.454\n",
      "  MCC: 0.041\n",
      "  Precision: 0.528\n",
      "  Recall: 0.515\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 19 / 250 ========\n",
      "Training...\n",
      "  Batch 7,800  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 7,850  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 7,900  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 7,950  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 8,000  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 8,050  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 8,100  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 8,150  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.501\n",
      "  MCC: 0.042\n",
      "  Precision: 0.523\n",
      "  Recall: 0.519\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 20 / 250 ========\n",
      "Training...\n",
      "  Batch 8,200  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 8,250  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 8,300  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 8,350  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 8,400  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 8,450  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 8,500  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 8,550  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 8,600  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.509\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 21 / 250 ========\n",
      "Training...\n",
      "  Batch 8,650  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 8,700  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 8,750  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 8,800  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 8,850  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 8,900  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 8,950  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 9,000  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 9,050  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.043\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 22 / 250 ========\n",
      "Training...\n",
      "  Batch 9,100  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 9,150  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 9,200  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 9,250  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 9,300  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 9,350  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 9,400  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 9,450  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.442\n",
      "  MCC: 0.045\n",
      "  Precision: 0.533\n",
      "  Recall: 0.515\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 23 / 250 ========\n",
      "Training...\n",
      "  Batch 9,500  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 9,550  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 9,600  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 9,650  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 9,700  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 9,750  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 9,800  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 9,850  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 9,900  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.460\n",
      "  MCC: 0.041\n",
      "  Precision: 0.527\n",
      "  Recall: 0.515\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 24 / 250 ========\n",
      "Training...\n",
      "  Batch 9,950  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 10,000  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 10,050  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 10,100  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 10,150  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 10,200  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 10,250  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 10,300  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.043\n",
      "  Precision: 0.523\n",
      "  Recall: 0.519\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 25 / 250 ========\n",
      "Training...\n",
      "  Batch 10,350  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 10,400  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 10,450  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 10,500  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 10,550  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 10,600  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 10,650  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 10,700  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 10,750  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.435\n",
      "  MCC: 0.042\n",
      "  Precision: 0.532\n",
      "  Recall: 0.514\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.518\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 26 / 250 ========\n",
      "Training...\n",
      "  Batch 10,800  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 10,850  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 10,900  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 10,950  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 11,000  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 11,050  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 11,100  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 11,150  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 11,200  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.498\n",
      "  MCC: 0.041\n",
      "  Precision: 0.522\n",
      "  Recall: 0.518\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 27 / 250 ========\n",
      "Training...\n",
      "  Batch 11,250  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 11,300  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 11,350  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 11,400  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 11,450  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 11,500  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 11,550  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 11,600  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.500\n",
      "  MCC: 0.044\n",
      "  Precision: 0.524\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 28 / 250 ========\n",
      "Training...\n",
      "  Batch 11,650  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 11,700  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 11,750  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 11,800  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 11,850  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 11,900  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 11,950  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 12,000  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 12,050  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.489\n",
      "  MCC: 0.041\n",
      "  Precision: 0.523\n",
      "  Recall: 0.518\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 29 / 250 ========\n",
      "Training...\n",
      "  Batch 12,100  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 12,150  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 12,200  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 12,250  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 12,300  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 12,350  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 12,400  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 12,450  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.460\n",
      "  MCC: 0.044\n",
      "  Precision: 0.529\n",
      "  Recall: 0.517\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 30 / 250 ========\n",
      "Training...\n",
      "  Batch 12,500  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 12,550  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 12,600  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 12,650  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 12,700  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 12,750  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 12,800  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 12,850  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 12,900  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.489\n",
      "  MCC: 0.043\n",
      "  Precision: 0.524\n",
      "  Recall: 0.519\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 31 / 250 ========\n",
      "Training...\n",
      "  Batch 12,950  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 13,000  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 13,050  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 13,100  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 13,150  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 13,200  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 13,250  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 13,300  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 13,350  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.516\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 32 / 250 ========\n",
      "Training...\n",
      "  Batch 13,400  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 13,450  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 13,500  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 13,550  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 13,600  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 13,650  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 13,700  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 13,750  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.478\n",
      "  MCC: 0.042\n",
      "  Precision: 0.525\n",
      "  Recall: 0.517\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 33 / 250 ========\n",
      "Training...\n",
      "  Batch 13,800  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 13,850  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 13,900  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 13,950  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 14,000  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 14,050  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 14,100  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 14,150  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 14,200  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.453\n",
      "  MCC: 0.041\n",
      "  Precision: 0.528\n",
      "  Recall: 0.515\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 34 / 250 ========\n",
      "Training...\n",
      "  Batch 14,250  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 14,300  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 14,350  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 14,400  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 14,450  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 14,500  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 14,550  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 14,600  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 14,650  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.505\n",
      "  MCC: 0.043\n",
      "  Precision: 0.523\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 35 / 250 ========\n",
      "Training...\n",
      "  Batch 14,700  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 14,750  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 14,800  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 14,850  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 14,900  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 14,950  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 15,000  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 15,050  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.457\n",
      "  MCC: 0.043\n",
      "  Precision: 0.529\n",
      "  Recall: 0.516\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 36 / 250 ========\n",
      "Training...\n",
      "  Batch 15,100  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 15,150  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 15,200  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 15,250  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 15,300  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 15,350  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 15,400  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 15,450  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 15,500  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.455\n",
      "  MCC: 0.043\n",
      "  Precision: 0.529\n",
      "  Recall: 0.516\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 37 / 250 ========\n",
      "Training...\n",
      "  Batch 15,550  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 15,600  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 15,650  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 15,700  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 15,750  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 15,800  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 15,850  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 15,900  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.514\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 38 / 250 ========\n",
      "Training...\n",
      "  Batch 15,950  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 16,000  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 16,050  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 16,100  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 16,150  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 16,200  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 16,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 16,300  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 16,350  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.469\n",
      "  MCC: 0.042\n",
      "  Precision: 0.526\n",
      "  Recall: 0.517\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 39 / 250 ========\n",
      "Training...\n",
      "  Batch 16,400  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 16,450  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 16,500  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 16,550  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 16,600  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 16,650  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 16,700  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 16,750  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 16,800  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.487\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 40 / 250 ========\n",
      "Training...\n",
      "  Batch 16,850  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 16,900  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 16,950  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 17,000  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 17,050  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 17,100  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 17,150  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 17,200  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 41 / 250 ========\n",
      "Training...\n",
      "  Batch 17,250  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 17,300  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 17,350  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 17,400  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 17,450  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 17,500  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 17,550  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 17,600  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 17,650  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.445\n",
      "  MCC: 0.044\n",
      "  Precision: 0.532\n",
      "  Recall: 0.515\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 42 / 250 ========\n",
      "Training...\n",
      "  Batch 17,700  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 17,750  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 17,800  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 17,850  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 17,900  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 17,950  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 18,000  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 18,050  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 18,100  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.463\n",
      "  MCC: 0.043\n",
      "  Precision: 0.528\n",
      "  Recall: 0.516\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.520\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 43 / 250 ========\n",
      "Training...\n",
      "  Batch 18,150  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 18,200  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 18,250  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 18,300  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 18,350  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 18,400  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 18,450  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 18,500  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.504\n",
      "  MCC: 0.042\n",
      "  Precision: 0.522\n",
      "  Recall: 0.519\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 44 / 250 ========\n",
      "Training...\n",
      "  Batch 18,550  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 18,600  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 18,650  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 18,700  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 18,750  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 18,800  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 18,850  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 18,900  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 18,950  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.501\n",
      "  MCC: 0.043\n",
      "  Precision: 0.524\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 45 / 250 ========\n",
      "Training...\n",
      "  Batch 19,000  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 19,050  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 19,100  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 19,150  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 19,200  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 19,250  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 19,300  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 19,350  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.514\n",
      "  MCC: 0.043\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 46 / 250 ========\n",
      "Training...\n",
      "  Batch 19,400  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 19,450  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 19,500  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 19,550  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 19,600  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 19,650  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 19,700  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 19,750  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 19,800  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.511\n",
      "  MCC: 0.042\n",
      "  Precision: 0.522\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 47 / 250 ========\n",
      "Training...\n",
      "  Batch 19,850  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 19,900  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 19,950  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 20,000  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 20,050  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 20,100  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 20,150  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 20,200  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 20,250  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 48 / 250 ========\n",
      "Training...\n",
      "  Batch 20,300  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 20,350  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 20,400  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 20,450  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 20,500  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 20,550  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 20,600  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 20,650  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.443\n",
      "  MCC: 0.043\n",
      "  Precision: 0.531\n",
      "  Recall: 0.515\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 49 / 250 ========\n",
      "Training...\n",
      "  Batch 20,700  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 20,750  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 20,800  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 20,850  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 20,900  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 20,950  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 21,000  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 21,050  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 21,100  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.514\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 50 / 250 ========\n",
      "Training...\n",
      "  Batch 21,150  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 21,200  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 21,250  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 21,300  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 21,350  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 21,400  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 21,450  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 21,500  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 21,550  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.516\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 51 / 250 ========\n",
      "Training...\n",
      "  Batch 21,600  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 21,650  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 21,700  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 21,750  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 21,800  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 21,850  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 21,900  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 21,950  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.464\n",
      "  MCC: 0.045\n",
      "  Precision: 0.529\n",
      "  Recall: 0.517\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 52 / 250 ========\n",
      "Training...\n",
      "  Batch 22,000  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 22,050  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 22,100  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 22,150  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 22,200  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 22,250  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 22,300  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 22,350  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 22,400  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 53 / 250 ========\n",
      "Training...\n",
      "  Batch 22,450  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 22,500  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 22,550  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 22,600  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 22,650  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 22,700  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 22,750  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 22,800  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.044\n",
      "  Precision: 0.522\n",
      "  Recall: 0.522\n",
      "  AUC: 0.533\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 54 / 250 ========\n",
      "Training...\n",
      "  Batch 22,850  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 22,900  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 22,950  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 23,000  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 23,050  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 23,100  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 23,150  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 23,200  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 23,250  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.477\n",
      "  MCC: 0.045\n",
      "  Precision: 0.528\n",
      "  Recall: 0.518\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 55 / 250 ========\n",
      "Training...\n",
      "  Batch 23,300  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 23,350  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 23,400  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 23,450  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 23,500  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 23,550  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 23,600  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 23,650  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 23,700  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.470\n",
      "  MCC: 0.044\n",
      "  Precision: 0.528\n",
      "  Recall: 0.517\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 56 / 250 ========\n",
      "Training...\n",
      "  Batch 23,750  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 23,800  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 23,850  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 23,900  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 23,950  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 24,000  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 24,050  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 24,100  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.043\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 57 / 250 ========\n",
      "Training...\n",
      "  Batch 24,150  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 24,200  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 24,250  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 24,300  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 24,350  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 24,400  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 24,450  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 24,500  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 24,550  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.435\n",
      "  MCC: 0.043\n",
      "  Precision: 0.533\n",
      "  Recall: 0.514\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.519\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 58 / 250 ========\n",
      "Training...\n",
      "  Batch 24,600  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 24,650  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 24,700  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 24,750  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 24,800  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 24,850  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 24,900  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 24,950  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.459\n",
      "  MCC: 0.047\n",
      "  Precision: 0.531\n",
      "  Recall: 0.517\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 59 / 250 ========\n",
      "Training...\n",
      "  Batch 25,000  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 25,050  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 25,100  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 25,150  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 25,200  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 25,250  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 25,300  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 25,350  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 25,400  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.477\n",
      "  MCC: 0.047\n",
      "  Precision: 0.529\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 60 / 250 ========\n",
      "Training...\n",
      "  Batch 25,450  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 25,500  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 25,550  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 25,600  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 25,650  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 25,700  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 25,750  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 25,800  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 25,850  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.044\n",
      "  Precision: 0.524\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 61 / 250 ========\n",
      "Training...\n",
      "  Batch 25,900  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 25,950  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 26,000  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 26,050  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 26,100  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 26,150  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 26,200  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 26,250  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 62 / 250 ========\n",
      "Training...\n",
      "  Batch 26,300  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 26,350  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 26,400  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 26,450  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 26,500  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 26,550  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 26,600  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 26,650  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 26,700  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.515\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 63 / 250 ========\n",
      "Training...\n",
      "  Batch 26,750  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 26,800  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 26,850  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 26,900  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 26,950  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 27,000  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 27,050  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 27,100  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 27,150  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.501\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 64 / 250 ========\n",
      "Training...\n",
      "  Batch 27,200  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 27,250  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 27,300  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 27,350  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 27,400  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 27,450  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 27,500  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 27,550  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 65 / 250 ========\n",
      "Training...\n",
      "  Batch 27,600  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 27,650  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 27,700  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 27,750  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 27,800  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 27,850  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 27,900  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 27,950  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 28,000  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 66 / 250 ========\n",
      "Training...\n",
      "  Batch 28,050  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 28,100  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 28,150  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 28,200  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 28,250  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 28,300  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 28,350  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 28,400  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.478\n",
      "  MCC: 0.043\n",
      "  Precision: 0.526\n",
      "  Recall: 0.518\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 67 / 250 ========\n",
      "Training...\n",
      "  Batch 28,450  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 28,500  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 28,550  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 28,600  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 28,650  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 28,700  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 28,750  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 28,800  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 28,850  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.043\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 68 / 250 ========\n",
      "Training...\n",
      "  Batch 28,900  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 28,950  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 29,000  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 29,050  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 29,100  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 29,150  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 29,200  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 29,250  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 29,300  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.517\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 69 / 250 ========\n",
      "Training...\n",
      "  Batch 29,350  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 29,400  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 29,450  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 29,500  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 29,550  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 29,600  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 29,650  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 29,700  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.497\n",
      "  MCC: 0.044\n",
      "  Precision: 0.525\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 70 / 250 ========\n",
      "Training...\n",
      "  Batch 29,750  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 29,800  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 29,850  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 29,900  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 29,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 30,000  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 30,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 30,100  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 30,150  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.043\n",
      "  Precision: 0.523\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 71 / 250 ========\n",
      "Training...\n",
      "  Batch 30,200  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 30,250  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 30,300  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 30,350  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 30,400  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 30,450  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 30,500  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 30,550  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 30,600  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 72 / 250 ========\n",
      "Training...\n",
      "  Batch 30,650  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 30,700  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 30,750  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 30,800  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 30,850  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 30,900  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 30,950  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 31,000  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.516\n",
      "  MCC: 0.044\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 73 / 250 ========\n",
      "Training...\n",
      "  Batch 31,050  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 31,100  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 31,150  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 31,200  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 31,250  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 31,300  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 31,350  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 31,400  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 31,450  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.484\n",
      "  MCC: 0.044\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 74 / 250 ========\n",
      "Training...\n",
      "  Batch 31,500  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 31,550  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 31,600  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 31,650  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 31,700  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 31,750  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 31,800  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 31,850  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 75 / 250 ========\n",
      "Training...\n",
      "  Batch 31,900  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 31,950  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 32,000  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 32,050  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 32,100  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 32,150  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 32,200  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 32,250  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 32,300  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 76 / 250 ========\n",
      "Training...\n",
      "  Batch 32,350  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 32,400  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 32,450  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 32,500  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 32,550  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 32,600  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 32,650  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 32,700  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 32,750  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.488\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 77 / 250 ========\n",
      "Training...\n",
      "  Batch 32,800  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 32,850  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 32,900  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 32,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 33,000  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 33,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 33,100  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 33,150  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.044\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 78 / 250 ========\n",
      "Training...\n",
      "  Batch 33,200  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 33,250  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 33,300  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 33,350  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 33,400  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 33,450  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 33,500  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 33,550  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 33,600  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 79 / 250 ========\n",
      "Training...\n",
      "  Batch 33,650  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 33,700  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 33,750  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 33,800  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 33,850  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 33,900  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 33,950  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 34,000  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.494\n",
      "  MCC: 0.045\n",
      "  Precision: 0.525\n",
      "  Recall: 0.520\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 80 / 250 ========\n",
      "Training...\n",
      "  Batch 34,050  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 34,100  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 34,150  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 34,200  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 34,250  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 34,300  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 34,350  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 34,400  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 34,450  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.486\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 81 / 250 ========\n",
      "Training...\n",
      "  Batch 34,500  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 34,550  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 34,600  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 34,650  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 34,700  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 34,750  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 34,800  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 34,850  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 34,900  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.514\n",
      "  MCC: 0.043\n",
      "  Precision: 0.522\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 82 / 250 ========\n",
      "Training...\n",
      "  Batch 34,950  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 35,000  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 35,050  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 35,100  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 35,150  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 35,200  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 35,250  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 35,300  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.044\n",
      "  Precision: 0.522\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 83 / 250 ========\n",
      "Training...\n",
      "  Batch 35,350  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 35,400  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 35,450  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 35,500  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 35,550  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 35,600  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 35,650  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 35,700  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 35,750  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.534\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 84 / 250 ========\n",
      "Training...\n",
      "  Batch 35,800  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 35,850  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 35,900  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 35,950  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 36,000  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 36,050  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 36,100  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 36,150  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 36,200  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 85 / 250 ========\n",
      "Training...\n",
      "  Batch 36,250  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 36,300  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 36,350  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 36,400  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 36,450  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 36,500  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 36,550  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 36,600  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 86 / 250 ========\n",
      "Training...\n",
      "  Batch 36,650  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 36,700  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 36,750  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 36,800  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 36,850  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 36,900  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 36,950  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 37,000  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 37,050  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 87 / 250 ========\n",
      "Training...\n",
      "  Batch 37,100  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 37,150  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 37,200  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 37,250  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 37,300  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 37,350  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 37,400  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 37,450  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 88 / 250 ========\n",
      "Training...\n",
      "  Batch 37,500  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 37,550  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 37,600  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 37,650  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 37,700  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 37,750  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 37,800  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 37,850  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 37,900  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.465\n",
      "  MCC: 0.045\n",
      "  Precision: 0.529\n",
      "  Recall: 0.518\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 89 / 250 ========\n",
      "Training...\n",
      "  Batch 37,950  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 38,000  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 38,050  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 38,100  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 38,150  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 38,200  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 38,250  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 38,300  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 38,350  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 90 / 250 ========\n",
      "Training...\n",
      "  Batch 38,400  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 38,450  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 38,500  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 38,550  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 38,600  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 38,650  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 38,700  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 38,750  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 91 / 250 ========\n",
      "Training...\n",
      "  Batch 38,800  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 38,850  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 38,900  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 38,950  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 39,000  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 39,050  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 39,100  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 39,150  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 39,200  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.486\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 92 / 250 ========\n",
      "Training...\n",
      "  Batch 39,250  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 39,300  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 39,350  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 39,400  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 39,450  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 39,500  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 39,550  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 39,600  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 39,650  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 93 / 250 ========\n",
      "Training...\n",
      "  Batch 39,700  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 39,750  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 39,800  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 39,850  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 39,900  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 39,950  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 40,000  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 40,050  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.490\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 94 / 250 ========\n",
      "Training...\n",
      "  Batch 40,100  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 40,150  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 40,200  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 40,250  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 40,300  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 40,350  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 40,400  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 40,450  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 40,500  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.511\n",
      "  MCC: 0.046\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 95 / 250 ========\n",
      "Training...\n",
      "  Batch 40,550  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 40,600  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 40,650  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 40,700  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 40,750  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 40,800  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 40,850  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 40,900  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 96 / 250 ========\n",
      "Training...\n",
      "  Batch 40,950  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 41,000  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 41,050  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 41,100  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 41,150  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 41,200  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 41,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 41,300  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 41,350  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.466\n",
      "  MCC: 0.045\n",
      "  Precision: 0.529\n",
      "  Recall: 0.518\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.521\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 97 / 250 ========\n",
      "Training...\n",
      "  Batch 41,400  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 41,450  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 41,500  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 41,550  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 41,600  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 41,650  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 41,700  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 41,750  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 41,800  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.501\n",
      "  MCC: 0.043\n",
      "  Precision: 0.523\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 98 / 250 ========\n",
      "Training...\n",
      "  Batch 41,850  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 41,900  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 41,950  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 42,000  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 42,050  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 42,100  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 42,150  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 42,200  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.482\n",
      "  MCC: 0.044\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 99 / 250 ========\n",
      "Training...\n",
      "  Batch 42,250  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 42,300  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 42,350  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 42,400  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 42,450  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 42,500  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 42,550  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 42,600  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 42,650  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 100 / 250 ========\n",
      "Training...\n",
      "  Batch 42,700  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 42,750  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 42,800  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 42,850  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 42,900  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 42,950  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 43,000  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 43,050  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 43,100  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 101 / 250 ========\n",
      "Training...\n",
      "  Batch 43,150  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 43,200  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 43,250  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 43,300  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 43,350  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 43,400  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 43,450  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 43,500  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.493\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 102 / 250 ========\n",
      "Training...\n",
      "  Batch 43,550  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 43,600  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 43,650  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 43,700  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 43,750  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 43,800  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 43,850  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 43,900  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 43,950  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.481\n",
      "  MCC: 0.044\n",
      "  Precision: 0.526\n",
      "  Recall: 0.518\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 103 / 250 ========\n",
      "Training...\n",
      "  Batch 44,000  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 44,050  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 44,100  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 44,150  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 44,200  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 44,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 44,300  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 44,350  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.493\n",
      "  MCC: 0.045\n",
      "  Precision: 0.525\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 104 / 250 ========\n",
      "Training...\n",
      "  Batch 44,400  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 44,450  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 44,500  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 44,550  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 44,600  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 44,650  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 44,700  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 44,750  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 44,800  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.498\n",
      "  MCC: 0.045\n",
      "  Precision: 0.525\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 105 / 250 ========\n",
      "Training...\n",
      "  Batch 44,850  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 44,900  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 44,950  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 45,000  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 45,050  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 45,100  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 45,150  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 45,200  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 45,250  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.482\n",
      "  MCC: 0.046\n",
      "  Precision: 0.527\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 106 / 250 ========\n",
      "Training...\n",
      "  Batch 45,300  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 45,350  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 45,400  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 45,450  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 45,500  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 45,550  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 45,600  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 45,650  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.502\n",
      "  MCC: 0.044\n",
      "  Precision: 0.524\n",
      "  Recall: 0.520\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 107 / 250 ========\n",
      "Training...\n",
      "  Batch 45,700  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 45,750  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 45,800  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 45,850  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 45,900  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 45,950  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 46,000  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 46,050  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 46,100  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.487\n",
      "  MCC: 0.047\n",
      "  Precision: 0.527\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 108 / 250 ========\n",
      "Training...\n",
      "  Batch 46,150  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 46,200  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 46,250  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 46,300  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 46,350  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 46,400  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 46,450  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 46,500  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.506\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 109 / 250 ========\n",
      "Training...\n",
      "  Batch 46,550  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 46,600  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 46,650  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 46,700  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 46,750  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 46,800  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 46,850  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 46,900  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 46,950  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.046\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 110 / 250 ========\n",
      "Training...\n",
      "  Batch 47,000  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 47,050  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 47,100  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 47,150  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 47,200  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 47,250  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 47,300  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 47,350  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 47,400  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.044\n",
      "  Precision: 0.523\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 111 / 250 ========\n",
      "Training...\n",
      "  Batch 47,450  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 47,500  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 47,550  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 47,600  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 47,650  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 47,700  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 47,750  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 47,800  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.487\n",
      "  MCC: 0.046\n",
      "  Precision: 0.527\n",
      "  Recall: 0.519\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 112 / 250 ========\n",
      "Training...\n",
      "  Batch 47,850  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 47,900  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 47,950  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 48,000  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 48,050  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 48,100  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 48,150  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 48,200  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 48,250  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.502\n",
      "  MCC: 0.044\n",
      "  Precision: 0.524\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 113 / 250 ========\n",
      "Training...\n",
      "  Batch 48,300  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 48,350  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 48,400  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 48,450  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 48,500  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 48,550  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 48,600  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 48,650  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 48,700  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.493\n",
      "  MCC: 0.048\n",
      "  Precision: 0.527\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 114 / 250 ========\n",
      "Training...\n",
      "  Batch 48,750  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 48,800  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 48,850  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 48,900  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 48,950  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 49,000  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 49,050  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 49,100  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.049\n",
      "  Precision: 0.526\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 115 / 250 ========\n",
      "Training...\n",
      "  Batch 49,150  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 49,200  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 49,250  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 49,300  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 49,350  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 49,400  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 49,450  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 49,500  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 49,550  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.496\n",
      "  MCC: 0.046\n",
      "  Precision: 0.526\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 116 / 250 ========\n",
      "Training...\n",
      "  Batch 49,600  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 49,650  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 49,700  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 49,750  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 49,800  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 49,850  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 49,900  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 49,950  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 117 / 250 ========\n",
      "Training...\n",
      "  Batch 50,000  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 50,050  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 50,100  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 50,150  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 50,200  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 50,250  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 50,300  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 50,350  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 50,400  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.471\n",
      "  MCC: 0.048\n",
      "  Precision: 0.530\n",
      "  Recall: 0.519\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 118 / 250 ========\n",
      "Training...\n",
      "  Batch 50,450  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 50,500  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 50,550  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 50,600  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 50,650  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 50,700  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 50,750  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 50,800  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 50,850  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.489\n",
      "  MCC: 0.047\n",
      "  Precision: 0.527\n",
      "  Recall: 0.520\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 119 / 250 ========\n",
      "Training...\n",
      "  Batch 50,900  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 50,950  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 51,000  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 51,050  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 51,100  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 51,150  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 51,200  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 51,250  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.495\n",
      "  MCC: 0.048\n",
      "  Precision: 0.527\n",
      "  Recall: 0.521\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 120 / 250 ========\n",
      "Training...\n",
      "  Batch 51,300  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 51,350  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 51,400  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 51,450  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 51,500  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 51,550  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 51,600  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 51,650  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 51,700  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.048\n",
      "  Precision: 0.527\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 121 / 250 ========\n",
      "Training...\n",
      "  Batch 51,750  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 51,800  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 51,850  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 51,900  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 51,950  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 52,000  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 52,050  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 52,100  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 52,150  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 122 / 250 ========\n",
      "Training...\n",
      "  Batch 52,200  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 52,250  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 52,300  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 52,350  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 52,400  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 52,450  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 52,500  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 52,550  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.497\n",
      "  MCC: 0.047\n",
      "  Precision: 0.527\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 123 / 250 ========\n",
      "Training...\n",
      "  Batch 52,600  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 52,650  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 52,700  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 52,750  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 52,800  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 52,850  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 52,900  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 52,950  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 53,000  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.505\n",
      "  MCC: 0.048\n",
      "  Precision: 0.526\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 124 / 250 ========\n",
      "Training...\n",
      "  Batch 53,050  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 53,100  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 53,150  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 53,200  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 53,250  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 53,300  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 53,350  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 53,400  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.485\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.519\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 125 / 250 ========\n",
      "Training...\n",
      "  Batch 53,450  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 53,500  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 53,550  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 53,600  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 53,650  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 53,700  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 53,750  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 53,800  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 53,850  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.501\n",
      "  MCC: 0.045\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 126 / 250 ========\n",
      "Training...\n",
      "  Batch 53,900  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 53,950  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 54,000  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 54,050  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 54,100  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 54,150  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 54,200  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 54,250  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 54,300  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.494\n",
      "  MCC: 0.045\n",
      "  Precision: 0.526\n",
      "  Recall: 0.520\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 127 / 250 ========\n",
      "Training...\n",
      "  Batch 54,350  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 54,400  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 54,450  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 54,500  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 54,550  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 54,600  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 54,650  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 54,700  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 128 / 250 ========\n",
      "Training...\n",
      "  Batch 54,750  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 54,800  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 54,850  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 54,900  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 54,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 55,000  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 55,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 55,100  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 55,150  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 129 / 250 ========\n",
      "Training...\n",
      "  Batch 55,200  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 55,250  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 55,300  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 55,350  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 55,400  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 55,450  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 55,500  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 55,550  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.514\n",
      "  MCC: 0.046\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.535\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 130 / 250 ========\n",
      "Training...\n",
      "  Batch 55,600  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 55,650  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 55,700  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 55,750  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 55,800  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 55,850  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 55,900  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 55,950  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 56,000  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.479\n",
      "  MCC: 0.045\n",
      "  Precision: 0.527\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 131 / 250 ========\n",
      "Training...\n",
      "  Batch 56,050  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 56,100  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 56,150  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 56,200  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 56,250  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 56,300  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 56,350  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 56,400  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 56,450  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.477\n",
      "  MCC: 0.047\n",
      "  Precision: 0.529\n",
      "  Recall: 0.519\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 132 / 250 ========\n",
      "Training...\n",
      "  Batch 56,500  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 56,550  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 56,600  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 56,650  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 56,700  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 56,750  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 56,800  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 56,850  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.493\n",
      "  MCC: 0.047\n",
      "  Precision: 0.527\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 133 / 250 ========\n",
      "Training...\n",
      "  Batch 56,900  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 56,950  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 57,000  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 57,050  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 57,100  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 57,150  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 57,200  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 57,250  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 57,300  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.478\n",
      "  MCC: 0.047\n",
      "  Precision: 0.529\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 134 / 250 ========\n",
      "Training...\n",
      "  Batch 57,350  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 57,400  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 57,450  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 57,500  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 57,550  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 57,600  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 57,650  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 57,700  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 57,750  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.048\n",
      "  Precision: 0.526\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 135 / 250 ========\n",
      "Training...\n",
      "  Batch 57,800  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 57,850  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 57,900  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 57,950  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 58,000  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 58,050  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 58,100  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 58,150  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.048\n",
      "  Precision: 0.526\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 136 / 250 ========\n",
      "Training...\n",
      "  Batch 58,200  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 58,250  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 58,300  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 58,350  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 58,400  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 58,450  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 58,500  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 58,550  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 58,600  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.509\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 137 / 250 ========\n",
      "Training...\n",
      "  Batch 58,650  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 58,700  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 58,750  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 58,800  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 58,850  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 58,900  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 58,950  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 59,000  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.509\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 138 / 250 ========\n",
      "Training...\n",
      "  Batch 59,050  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 59,100  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 59,150  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 59,200  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 59,250  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 59,300  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 59,350  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 59,400  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 59,450  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.505\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 139 / 250 ========\n",
      "Training...\n",
      "  Batch 59,500  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 59,550  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 59,600  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 59,650  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 59,700  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 59,750  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 59,800  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 59,850  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 59,900  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.493\n",
      "  MCC: 0.044\n",
      "  Precision: 0.525\n",
      "  Recall: 0.519\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 140 / 250 ========\n",
      "Training...\n",
      "  Batch 59,950  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 60,000  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 60,050  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 60,100  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 60,150  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 60,200  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 60,250  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 60,300  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 141 / 250 ========\n",
      "Training...\n",
      "  Batch 60,350  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 60,400  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 60,450  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 60,500  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 60,550  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 60,600  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 60,650  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 60,700  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 60,750  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.498\n",
      "  MCC: 0.046\n",
      "  Precision: 0.526\n",
      "  Recall: 0.521\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 142 / 250 ========\n",
      "Training...\n",
      "  Batch 60,800  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 60,850  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 60,900  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 60,950  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 61,000  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 61,050  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 61,100  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 61,150  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 61,200  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 143 / 250 ========\n",
      "Training...\n",
      "  Batch 61,250  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 61,300  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 61,350  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 61,400  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 61,450  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 61,500  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 61,550  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 61,600  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.490\n",
      "  MCC: 0.046\n",
      "  Precision: 0.527\n",
      "  Recall: 0.520\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 144 / 250 ========\n",
      "Training...\n",
      "  Batch 61,650  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 61,700  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 61,750  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 61,800  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 61,850  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 61,900  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 61,950  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 62,000  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 62,050  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.500\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 145 / 250 ========\n",
      "Training...\n",
      "  Batch 62,100  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 62,150  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 62,200  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 62,250  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 62,300  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 62,350  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 62,400  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 62,450  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.506\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 146 / 250 ========\n",
      "Training...\n",
      "  Batch 62,500  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 62,550  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 62,600  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 62,650  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 62,700  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 62,750  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 62,800  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 62,850  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 62,900  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.502\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 147 / 250 ========\n",
      "Training...\n",
      "  Batch 62,950  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 63,000  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 63,050  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 63,100  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 63,150  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 63,200  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 63,250  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 63,300  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 63,350  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.511\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 148 / 250 ========\n",
      "Training...\n",
      "  Batch 63,400  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 63,450  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 63,500  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 63,550  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 63,600  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 63,650  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 63,700  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 63,750  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.515\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 149 / 250 ========\n",
      "Training...\n",
      "  Batch 63,800  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 63,850  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 63,900  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 63,950  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 64,000  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 64,050  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 64,100  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 64,150  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 64,200  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 150 / 250 ========\n",
      "Training...\n",
      "  Batch 64,250  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 64,300  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 64,350  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 64,400  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 64,450  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 64,500  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 64,550  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 64,600  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 64,650  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.046\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 151 / 250 ========\n",
      "Training...\n",
      "  Batch 64,700  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 64,750  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 64,800  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 64,850  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 64,900  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 64,950  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 65,000  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 65,050  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.512\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 152 / 250 ========\n",
      "Training...\n",
      "  Batch 65,100  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 65,150  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 65,200  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 65,250  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 65,300  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 65,350  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 65,400  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 65,450  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 65,500  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.513\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 153 / 250 ========\n",
      "Training...\n",
      "  Batch 65,550  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 65,600  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 65,650  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 65,700  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 65,750  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 65,800  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 65,850  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 65,900  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.517\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 154 / 250 ========\n",
      "Training...\n",
      "  Batch 65,950  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 66,000  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 66,050  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 66,100  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 66,150  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 66,200  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 66,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 66,300  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 66,350  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.046\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 155 / 250 ========\n",
      "Training...\n",
      "  Batch 66,400  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 66,450  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 66,500  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 66,550  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 66,600  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 66,650  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 66,700  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 66,750  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 66,800  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.515\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 156 / 250 ========\n",
      "Training...\n",
      "  Batch 66,850  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 66,900  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 66,950  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 67,000  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 67,050  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 67,100  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 67,150  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 67,200  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.516\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 157 / 250 ========\n",
      "Training...\n",
      "  Batch 67,250  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 67,300  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 67,350  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 67,400  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 67,450  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 67,500  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 67,550  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 67,600  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 67,650  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.499\n",
      "  MCC: 0.046\n",
      "  Precision: 0.526\n",
      "  Recall: 0.521\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 158 / 250 ========\n",
      "Training...\n",
      "  Batch 67,700  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 67,750  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 67,800  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 67,850  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 67,900  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 67,950  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 68,000  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 68,050  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.509\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 159 / 250 ========\n",
      "Training...\n",
      "  Batch 68,100  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 68,150  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 68,200  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 68,250  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 68,300  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 68,350  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 68,400  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 68,450  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 68,500  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.504\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 160 / 250 ========\n",
      "Training...\n",
      "  Batch 68,550  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 68,600  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 68,650  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 68,700  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 68,750  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 68,800  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 68,850  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 68,900  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 68,950  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 161 / 250 ========\n",
      "Training...\n",
      "  Batch 69,000  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 69,050  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 69,100  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 69,150  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 69,200  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 69,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 69,300  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 69,350  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.511\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 162 / 250 ========\n",
      "Training...\n",
      "  Batch 69,400  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 69,450  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 69,500  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 69,550  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 69,600  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 69,650  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 69,700  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 69,750  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 69,800  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 163 / 250 ========\n",
      "Training...\n",
      "  Batch 69,850  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 69,900  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 69,950  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 70,000  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 70,050  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 70,100  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 70,150  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 70,200  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 70,250  of    431.    Elapsed: 0:00:40.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.045\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 164 / 250 ========\n",
      "Training...\n",
      "  Batch 70,300  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 70,350  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 70,400  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 70,450  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 70,500  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 70,550  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 70,600  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 70,650  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 165 / 250 ========\n",
      "Training...\n",
      "  Batch 70,700  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 70,750  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 70,800  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 70,850  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 70,900  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 70,950  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 71,000  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 71,050  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 71,100  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 166 / 250 ========\n",
      "Training...\n",
      "  Batch 71,150  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 71,200  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 71,250  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 71,300  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 71,350  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 71,400  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 71,450  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 71,500  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.507\n",
      "  MCC: 0.046\n",
      "  Precision: 0.524\n",
      "  Recall: 0.521\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 167 / 250 ========\n",
      "Training...\n",
      "  Batch 71,550  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 71,600  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 71,650  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 71,700  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 71,750  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 71,800  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 71,850  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 71,900  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 71,950  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 168 / 250 ========\n",
      "Training...\n",
      "  Batch 72,000  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 72,050  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 72,100  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 72,150  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 72,200  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 72,250  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 72,300  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 72,350  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 72,400  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 169 / 250 ========\n",
      "Training...\n",
      "  Batch 72,450  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 72,500  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 72,550  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 72,600  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 72,650  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 72,700  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 72,750  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 72,800  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 170 / 250 ========\n",
      "Training...\n",
      "  Batch 72,850  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 72,900  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 72,950  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 73,000  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 73,050  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 73,100  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 73,150  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 73,200  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 73,250  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 171 / 250 ========\n",
      "Training...\n",
      "  Batch 73,300  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 73,350  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 73,400  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 73,450  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 73,500  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 73,550  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 73,600  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 73,650  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 73,700  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 172 / 250 ========\n",
      "Training...\n",
      "  Batch 73,750  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 73,800  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 73,850  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 73,900  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 73,950  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 74,000  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 74,050  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 74,100  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.508\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 173 / 250 ========\n",
      "Training...\n",
      "  Batch 74,150  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 74,200  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 74,250  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 74,300  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 74,350  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 74,400  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 74,450  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 74,500  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 74,550  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 174 / 250 ========\n",
      "Training...\n",
      "  Batch 74,600  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 74,650  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 74,700  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 74,750  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 74,800  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 74,850  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 74,900  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 74,950  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 175 / 250 ========\n",
      "Training...\n",
      "  Batch 75,000  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 75,050  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 75,100  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 75,150  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 75,200  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 75,250  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 75,300  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 75,350  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 75,400  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 176 / 250 ========\n",
      "Training...\n",
      "  Batch 75,450  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 75,500  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 75,550  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 75,600  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 75,650  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 75,700  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 75,750  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 75,800  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 75,850  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 177 / 250 ========\n",
      "Training...\n",
      "  Batch 75,900  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 75,950  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 76,000  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 76,050  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 76,100  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 76,150  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 76,200  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 76,250  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 178 / 250 ========\n",
      "Training...\n",
      "  Batch 76,300  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 76,350  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 76,400  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 76,450  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 76,500  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 76,550  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 76,600  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 76,650  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 76,700  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 179 / 250 ========\n",
      "Training...\n",
      "  Batch 76,750  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 76,800  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 76,850  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 76,900  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 76,950  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 77,000  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 77,050  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 77,100  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 180 / 250 ========\n",
      "Training...\n",
      "  Batch 77,150  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 77,200  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 77,250  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 77,300  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 77,350  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 77,400  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 77,450  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 77,500  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 77,550  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 181 / 250 ========\n",
      "Training...\n",
      "  Batch 77,600  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 77,650  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 77,700  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 77,750  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 77,800  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 77,850  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 77,900  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 77,950  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 78,000  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 182 / 250 ========\n",
      "Training...\n",
      "  Batch 78,050  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 78,100  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 78,150  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 78,200  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 78,250  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 78,300  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 78,350  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 78,400  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 183 / 250 ========\n",
      "Training...\n",
      "  Batch 78,450  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 78,500  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 78,550  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 78,600  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 78,650  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 78,700  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 78,750  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 78,800  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 78,850  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.046\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 184 / 250 ========\n",
      "Training...\n",
      "  Batch 78,900  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 78,950  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 79,000  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 79,050  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 79,100  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 79,150  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 79,200  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 79,250  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 79,300  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 185 / 250 ========\n",
      "Training...\n",
      "  Batch 79,350  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 79,400  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 79,450  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 79,500  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 79,550  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 79,600  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 79,650  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 79,700  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 186 / 250 ========\n",
      "Training...\n",
      "  Batch 79,750  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 79,800  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 79,850  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 79,900  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 79,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 80,000  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 80,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 80,100  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 80,150  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 187 / 250 ========\n",
      "Training...\n",
      "  Batch 80,200  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 80,250  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 80,300  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 80,350  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 80,400  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 80,450  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 80,500  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 80,550  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 188 / 250 ========\n",
      "Training...\n",
      "  Batch 80,600  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 80,650  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 80,700  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 80,750  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 80,800  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 80,850  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 80,900  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 80,950  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 81,000  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 189 / 250 ========\n",
      "Training...\n",
      "  Batch 81,050  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 81,100  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 81,150  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 81,200  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 81,250  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 81,300  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 81,350  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 81,400  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 81,450  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 190 / 250 ========\n",
      "Training...\n",
      "  Batch 81,500  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 81,550  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 81,600  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 81,650  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 81,700  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 81,750  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 81,800  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 81,850  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 191 / 250 ========\n",
      "Training...\n",
      "  Batch 81,900  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 81,950  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 82,000  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 82,050  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 82,100  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 82,150  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 82,200  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 82,250  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 82,300  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 192 / 250 ========\n",
      "Training...\n",
      "  Batch 82,350  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 82,400  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 82,450  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 82,500  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 82,550  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 82,600  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 82,650  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 82,700  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 82,750  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.518\n",
      "  MCC: 0.045\n",
      "  Precision: 0.523\n",
      "  Recall: 0.522\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 193 / 250 ========\n",
      "Training...\n",
      "  Batch 82,800  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 82,850  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 82,900  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 82,950  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 83,000  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 83,050  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 83,100  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 83,150  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 194 / 250 ========\n",
      "Training...\n",
      "  Batch 83,200  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 83,250  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 83,300  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 83,350  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 83,400  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 83,450  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 83,500  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 83,550  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 83,600  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.536\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 195 / 250 ========\n",
      "Training...\n",
      "  Batch 83,650  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 83,700  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 83,750  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 83,800  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 83,850  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 83,900  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 83,950  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 84,000  of    431.    Elapsed: 0:00:34.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.523\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 196 / 250 ========\n",
      "Training...\n",
      "  Batch 84,050  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 84,100  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 84,150  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 84,200  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 84,250  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 84,300  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 84,350  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 84,400  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 84,450  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 197 / 250 ========\n",
      "Training...\n",
      "  Batch 84,500  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 84,550  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 84,600  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 84,650  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 84,700  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 84,750  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 84,800  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 84,850  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 84,900  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 198 / 250 ========\n",
      "Training...\n",
      "  Batch 84,950  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 85,000  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 85,050  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 85,100  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 85,150  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 85,200  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 85,250  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 85,300  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 199 / 250 ========\n",
      "Training...\n",
      "  Batch 85,350  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 85,400  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 85,450  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 85,500  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 85,550  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 85,600  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 85,650  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 85,700  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 85,750  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 200 / 250 ========\n",
      "Training...\n",
      "  Batch 85,800  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 85,850  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 85,900  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 85,950  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 86,000  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 86,050  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 86,100  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 86,150  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 86,200  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.525\n",
      "  MCC: 0.050\n",
      "  Precision: 0.525\n",
      "  Recall: 0.525\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 201 / 250 ========\n",
      "Training...\n",
      "  Batch 86,250  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 86,300  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 86,350  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 86,400  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 86,450  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 86,500  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 86,550  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 86,600  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 202 / 250 ========\n",
      "Training...\n",
      "  Batch 86,650  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 86,700  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 86,750  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 86,800  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 86,850  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 86,900  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 86,950  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 87,000  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 87,050  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 203 / 250 ========\n",
      "Training...\n",
      "  Batch 87,100  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 87,150  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 87,200  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 87,250  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 87,300  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 87,350  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 87,400  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 87,450  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 204 / 250 ========\n",
      "Training...\n",
      "  Batch 87,500  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 87,550  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 87,600  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 87,650  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 87,700  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 87,750  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 87,800  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 87,850  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 87,900  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 205 / 250 ========\n",
      "Training...\n",
      "  Batch 87,950  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 88,000  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 88,050  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 88,100  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 88,150  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 88,200  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 88,250  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 88,300  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 88,350  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 206 / 250 ========\n",
      "Training...\n",
      "  Batch 88,400  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 88,450  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 88,500  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 88,550  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 88,600  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 88,650  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 88,700  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 88,750  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 207 / 250 ========\n",
      "Training...\n",
      "  Batch 88,800  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 88,850  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 88,900  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 88,950  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 89,000  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 89,050  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 89,100  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 89,150  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 89,200  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.518\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 208 / 250 ========\n",
      "Training...\n",
      "  Batch 89,250  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 89,300  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 89,350  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 89,400  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 89,450  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 89,500  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 89,550  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 89,600  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 209 / 250 ========\n",
      "Training...\n",
      "  Batch 89,650  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 89,700  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 89,750  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 89,800  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 89,850  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 89,900  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 89,950  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 90,000  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 90,050  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 210 / 250 ========\n",
      "Training...\n",
      "  Batch 90,100  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 90,150  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 90,200  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 90,250  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 90,300  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 90,350  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 90,400  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 90,450  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 90,500  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.518\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.522\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 211 / 250 ========\n",
      "Training...\n",
      "  Batch 90,550  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 90,600  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 90,650  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 90,700  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 90,750  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 90,800  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 90,850  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 90,900  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 212 / 250 ========\n",
      "Training...\n",
      "  Batch 90,950  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 91,000  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 91,050  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 91,100  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 91,150  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 91,200  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 91,250  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 91,300  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 91,350  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 213 / 250 ========\n",
      "Training...\n",
      "  Batch 91,400  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 91,450  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 91,500  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 91,550  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 91,600  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 91,650  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 91,700  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 91,750  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 91,800  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 214 / 250 ========\n",
      "Training...\n",
      "  Batch 91,850  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 91,900  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 91,950  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 92,000  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 92,050  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 92,100  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 92,150  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 92,200  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 215 / 250 ========\n",
      "Training...\n",
      "  Batch 92,250  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 92,300  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 92,350  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 92,400  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 92,450  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 92,500  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 92,550  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 92,600  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 92,650  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 216 / 250 ========\n",
      "Training...\n",
      "  Batch 92,700  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 92,750  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 92,800  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 92,850  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 92,900  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 92,950  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 93,000  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 93,050  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 217 / 250 ========\n",
      "Training...\n",
      "  Batch 93,100  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 93,150  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 93,200  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 93,250  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 93,300  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 93,350  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 93,400  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 93,450  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 93,500  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:38\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 218 / 250 ========\n",
      "Training...\n",
      "  Batch 93,550  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 93,600  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 93,650  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 93,700  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 93,750  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 93,800  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 93,850  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 93,900  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 93,950  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 219 / 250 ========\n",
      "Training...\n",
      "  Batch 94,000  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 94,050  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 94,100  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 94,150  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 94,200  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 94,250  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 94,300  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 94,350  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.047\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 220 / 250 ========\n",
      "Training...\n",
      "  Batch 94,400  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 94,450  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 94,500  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 94,550  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 94,600  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 94,650  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 94,700  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 94,750  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 94,800  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 221 / 250 ========\n",
      "Training...\n",
      "  Batch 94,850  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 94,900  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 94,950  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 95,000  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 95,050  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 95,100  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 95,150  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 95,200  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 95,250  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 222 / 250 ========\n",
      "Training...\n",
      "  Batch 95,300  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 95,350  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 95,400  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 95,450  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 95,500  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 95,550  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 95,600  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 95,650  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.523\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 223 / 250 ========\n",
      "Training...\n",
      "  Batch 95,700  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 95,750  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 95,800  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 95,850  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 95,900  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 95,950  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 96,000  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 96,050  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 96,100  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 224 / 250 ========\n",
      "Training...\n",
      "  Batch 96,150  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 96,200  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 96,250  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 96,300  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 96,350  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 96,400  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 96,450  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 96,500  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 225 / 250 ========\n",
      "Training...\n",
      "  Batch 96,550  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 96,600  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 96,650  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 96,700  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 96,750  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 96,800  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 96,850  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 96,900  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 96,950  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 226 / 250 ========\n",
      "Training...\n",
      "  Batch 97,000  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 97,050  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 97,100  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 97,150  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 97,200  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 97,250  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 97,300  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 97,350  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 97,400  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.525\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.525\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 227 / 250 ========\n",
      "Training...\n",
      "  Batch 97,450  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 97,500  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 97,550  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 97,600  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 97,650  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 97,700  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 97,750  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 97,800  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 228 / 250 ========\n",
      "Training...\n",
      "  Batch 97,850  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 97,900  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 97,950  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 98,000  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 98,050  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 98,100  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 98,150  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 98,200  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 98,250  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 229 / 250 ========\n",
      "Training...\n",
      "  Batch 98,300  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 98,350  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 98,400  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 98,450  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 98,500  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 98,550  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 98,600  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 98,650  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:06\n",
      "\n",
      "======== Epoch 230 / 250 ========\n",
      "Training...\n",
      "  Batch 98,700  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 98,750  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 98,800  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 98,850  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 98,900  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 98,950  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 99,000  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 99,050  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 99,100  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 231 / 250 ========\n",
      "Training...\n",
      "  Batch 99,150  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 99,200  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 99,250  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 99,300  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 99,350  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 99,400  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 99,450  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 99,500  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 99,550  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.521\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 232 / 250 ========\n",
      "Training...\n",
      "  Batch 99,600  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 99,650  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 99,700  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 99,750  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 99,800  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 99,850  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 99,900  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 99,950  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 233 / 250 ========\n",
      "Training...\n",
      "  Batch 100,000  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 100,050  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 100,100  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 100,150  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 100,200  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 100,250  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 100,300  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 100,350  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 100,400  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 234 / 250 ========\n",
      "Training...\n",
      "  Batch 100,450  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 100,500  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 100,550  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 100,600  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 100,650  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 100,700  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 100,750  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 100,800  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 100,850  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.520\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 235 / 250 ========\n",
      "Training...\n",
      "  Batch 100,900  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 100,950  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 101,000  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 101,050  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 101,100  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 101,150  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 101,200  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 101,250  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.048\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 236 / 250 ========\n",
      "Training...\n",
      "  Batch 101,300  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 101,350  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 101,400  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 101,450  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 101,500  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 101,550  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 101,600  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 101,650  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 101,700  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.518\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 237 / 250 ========\n",
      "Training...\n",
      "  Batch 101,750  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 101,800  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 101,850  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 101,900  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 101,950  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 102,000  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 102,050  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 102,100  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.519\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 238 / 250 ========\n",
      "Training...\n",
      "  Batch 102,150  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 102,200  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 102,250  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 102,300  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 102,350  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 102,400  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 102,450  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 102,500  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 102,550  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.518\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 239 / 250 ========\n",
      "Training...\n",
      "  Batch 102,600  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 102,650  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 102,700  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 102,750  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 102,800  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 102,850  of    431.    Elapsed: 0:00:25.\n",
      "  Batch 102,900  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 102,950  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 103,000  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.515\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 240 / 250 ========\n",
      "Training...\n",
      "  Batch 103,050  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 103,100  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 103,150  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 103,200  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 103,250  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 103,300  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 103,350  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 103,400  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.510\n",
      "  MCC: 0.047\n",
      "  Precision: 0.525\n",
      "  Recall: 0.522\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 241 / 250 ========\n",
      "Training...\n",
      "  Batch 103,450  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 103,500  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 103,550  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 103,600  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 103,650  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 103,700  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 103,750  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 103,800  of    431.    Elapsed: 0:00:34.\n",
      "  Batch 103,850  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.515\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 242 / 250 ========\n",
      "Training...\n",
      "  Batch 103,900  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 103,950  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 104,000  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 104,050  of    431.    Elapsed: 0:00:16.\n",
      "  Batch 104,100  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 104,150  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 104,200  of    431.    Elapsed: 0:00:30.\n",
      "  Batch 104,250  of    431.    Elapsed: 0:00:35.\n",
      "  Batch 104,300  of    431.    Elapsed: 0:00:39.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.516\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 243 / 250 ========\n",
      "Training...\n",
      "  Batch 104,350  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 104,400  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 104,450  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 104,500  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 104,550  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 104,600  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 104,650  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 104,700  of    431.    Elapsed: 0:00:37.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.517\n",
      "  MCC: 0.048\n",
      "  Precision: 0.525\n",
      "  Recall: 0.523\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 244 / 250 ========\n",
      "Training...\n",
      "  Batch 104,750  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 104,800  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 104,850  of    431.    Elapsed: 0:00:10.\n",
      "  Batch 104,900  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 104,950  of    431.    Elapsed: 0:00:19.\n",
      "  Batch 105,000  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 105,050  of    431.    Elapsed: 0:00:28.\n",
      "  Batch 105,100  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 105,150  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.517\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 245 / 250 ========\n",
      "Training...\n",
      "  Batch 105,200  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 105,250  of    431.    Elapsed: 0:00:08.\n",
      "  Batch 105,300  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 105,350  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 105,400  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 105,450  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 105,500  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 105,550  of    431.    Elapsed: 0:00:35.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.522\n",
      "  MCC: 0.050\n",
      "  Precision: 0.525\n",
      "  Recall: 0.524\n",
      "  AUC: 0.537\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 246 / 250 ========\n",
      "Training...\n",
      "  Batch 105,600  of    431.    Elapsed: 0:00:00.\n",
      "  Batch 105,650  of    431.    Elapsed: 0:00:05.\n",
      "  Batch 105,700  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 105,750  of    431.    Elapsed: 0:00:14.\n",
      "  Batch 105,800  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 105,850  of    431.    Elapsed: 0:00:23.\n",
      "  Batch 105,900  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 105,950  of    431.    Elapsed: 0:00:32.\n",
      "  Batch 106,000  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 247 / 250 ========\n",
      "Training...\n",
      "  Batch 106,050  of    431.    Elapsed: 0:00:02.\n",
      "  Batch 106,100  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 106,150  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 106,200  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 106,250  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 106,300  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 106,350  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 106,400  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 106,450  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.525\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 248 / 250 ========\n",
      "Training...\n",
      "  Batch 106,500  of    431.    Elapsed: 0:00:04.\n",
      "  Batch 106,550  of    431.    Elapsed: 0:00:09.\n",
      "  Batch 106,600  of    431.    Elapsed: 0:00:13.\n",
      "  Batch 106,650  of    431.    Elapsed: 0:00:18.\n",
      "  Batch 106,700  of    431.    Elapsed: 0:00:22.\n",
      "  Batch 106,750  of    431.    Elapsed: 0:00:27.\n",
      "  Batch 106,800  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 106,850  of    431.    Elapsed: 0:00:36.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.525\n",
      "  MCC: 0.049\n",
      "  Precision: 0.525\n",
      "  Recall: 0.525\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.525\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 249 / 250 ========\n",
      "Training...\n",
      "  Batch 106,900  of    431.    Elapsed: 0:00:01.\n",
      "  Batch 106,950  of    431.    Elapsed: 0:00:06.\n",
      "  Batch 107,000  of    431.    Elapsed: 0:00:11.\n",
      "  Batch 107,050  of    431.    Elapsed: 0:00:15.\n",
      "  Batch 107,100  of    431.    Elapsed: 0:00:20.\n",
      "  Batch 107,150  of    431.    Elapsed: 0:00:24.\n",
      "  Batch 107,200  of    431.    Elapsed: 0:00:29.\n",
      "  Batch 107,250  of    431.    Elapsed: 0:00:33.\n",
      "  Batch 107,300  of    431.    Elapsed: 0:00:38.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.524\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 250 / 250 ========\n",
      "Training...\n",
      "  Batch 107,350  of    431.    Elapsed: 0:00:03.\n",
      "  Batch 107,400  of    431.    Elapsed: 0:00:07.\n",
      "  Batch 107,450  of    431.    Elapsed: 0:00:12.\n",
      "  Batch 107,500  of    431.    Elapsed: 0:00:17.\n",
      "  Batch 107,550  of    431.    Elapsed: 0:00:21.\n",
      "  Batch 107,600  of    431.    Elapsed: 0:00:26.\n",
      "  Batch 107,650  of    431.    Elapsed: 0:00:31.\n",
      "  Batch 107,700  of    431.    Elapsed: 0:00:36.\n",
      "  Batch 107,750  of    431.    Elapsed: 0:00:40.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "  Running Validation...\n",
      "  F1: 0.523\n",
      "  MCC: 0.049\n",
      "  Precision: 0.524\n",
      "  Recall: 0.524\n",
      "  AUC: 0.538\n",
      "  Accuracy: 0.524\n",
      "  Validation Loss: 0.69\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n",
      "Total training took 3:02:30 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccs       : [0.036258670098226156, 0.03678385665289777, 0.03868069248497704, 0.03804247402001995, 0.03594839562140017, 0.03978159574445701, 0.0339857477360812, 0.040300633459607695, 0.0390248970678399, 0.0374999994038193, 0.04006346015690989, 0.041608752555185834, 0.03938496157683078, 0.04023585400232528, 0.04171348594993473, 0.03995420708651335, 0.04220449024678662, 0.04102542508702906, 0.0420542424695973, 0.043556080461086166, 0.04299271259521906, 0.04481999048639646, 0.040721878989931605, 0.04260140887807854, 0.041756204780782964, 0.04061033526539558, 0.04404170184823375, 0.04095700383142851, 0.04393085064997223, 0.04261362083991008, 0.0447849456070241, 0.04186380051983024, 0.04084971392880422, 0.04277132005175479, 0.0429263382417547, 0.043023366753387755, 0.04386004910085713, 0.041998964636989926, 0.044880439391480086, 0.047069009098105775, 0.04412816692233687, 0.04266355390680825, 0.04175207710880346, 0.04338049480433002, 0.04308504836345067, 0.04225011126067369, 0.04512015905266944, 0.04251756754877902, 0.04461309792553978, 0.043934236445890285, 0.04456676629459367, 0.04358275095241871, 0.04362132104418146, 0.04509037275901562, 0.04374917297734032, 0.043161054963924646, 0.04320257676104893, 0.04650761095408803, 0.04699577089990211, 0.0441503346964937, 0.045630740341779275, 0.04448412260417189, 0.04629273825327109, 0.045416613980715566, 0.0447206730253632, 0.04336260604349692, 0.043432601881380574, 0.045160553390564157, 0.044163513926503535, 0.04279173728077099, 0.0443016899514688, 0.043839870383228, 0.04425055173009216, 0.04560651990134149, 0.04668978300441493, 0.04524079255815155, 0.04447189988854689, 0.04360416494489782, 0.04452389938363482, 0.045194530471152815, 0.04272999973100495, 0.0442774293821421, 0.04473665322118279, 0.04630229870275263, 0.04436872584288007, 0.04456753548487166, 0.0453615835667931, 0.04539206454465644, 0.04615084844226038, 0.0458101362579886, 0.04479764041091503, 0.04536728205915406, 0.04500675364423481, 0.045662627720383035, 0.04487700390202495, 0.0453885225582284, 0.042987758555848125, 0.044099375086207565, 0.04503804305338469, 0.048202976311737956, 0.04531103011027951, 0.04424548760218627, 0.045017218499163104, 0.04545357838640989, 0.04552911042422936, 0.04419970478614043, 0.04672790062039675, 0.04573156436405196, 0.045916247817651336, 0.044359749328453824, 0.04550636407856037, 0.04449176957390311, 0.047592659911779134, 0.04868592399623126, 0.04625070471902906, 0.045934489289758046, 0.04782288648511717, 0.046870004630328116, 0.04795031529055533, 0.048228407621520475, 0.045026004025580095, 0.04733833056331318, 0.04807723383607678, 0.044728264881228684, 0.04537317875744773, 0.04532571243655259, 0.04578345208966947, 0.04736722055477564, 0.046244104914875454, 0.04523496876049953, 0.046851270632243196, 0.04691692422273606, 0.04706789987817688, 0.048109127538161704, 0.0481534321280478, 0.047239727122257436, 0.04467974838660993, 0.045946094132961524, 0.04368805003074278, 0.04526056129911785, 0.046033586306038154, 0.047382588550545966, 0.04621000028043205, 0.045950193461772836, 0.046470361380012364, 0.045804146892923336, 0.047009714981629064, 0.04740886521393561, 0.04785574945118342, 0.046112849868482055, 0.0476612105263226, 0.047104888955219866, 0.04785612894628788, 0.04619225031946469, 0.04688307996579081, 0.04658508015361979, 0.04647182515702225, 0.04762656535719257, 0.04687684276400448, 0.047319332451053235, 0.04661446998885533, 0.04687648967043528, 0.04513193797716839, 0.04806299786096382, 0.04634475408568727, 0.045596896691300765, 0.04717289904766509, 0.04616818738864675, 0.046257333258649176, 0.045807525733488175, 0.04868134962296299, 0.04699399762792771, 0.04814103982586448, 0.047852815420341345, 0.04776779186696448, 0.04868873087847939, 0.04903578945681789, 0.04787775803665036, 0.04851296309590374, 0.04888027243980539, 0.04817684495322366, 0.04667574029991925, 0.04592444890139519, 0.048356746394418254, 0.048107460126151, 0.047275120657798736, 0.04666422311332271, 0.04791197249352359, 0.048676717690770414, 0.046512509272328965, 0.04817599346647335, 0.0454298248726305, 0.048727136480633516, 0.047231128770550294, 0.04685918839945238, 0.047228497901231174, 0.047581645538194835, 0.047327000099755684, 0.04725315196524932, 0.05023506330057264, 0.048053228387198554, 0.04777988499187238, 0.04730899681197226, 0.04746981332884132, 0.04714237792198441, 0.04766268437204509, 0.046976088337209454, 0.048928366252564574, 0.048855958548620064, 0.04699766430963529, 0.04890533445036074, 0.049032819341313365, 0.04825305870263083, 0.04871205489629316, 0.048629254413482564, 0.04855501440133791, 0.04839246876681713, 0.048255840945651274, 0.04745929998191656, 0.04829433364632372, 0.04890125983851745, 0.04813106845925042, 0.048472015882998994, 0.04828587326660272, 0.0478954478567925, 0.04935411892044011, 0.04867470405425545, 0.04854384083776702, 0.04874440580277531, 0.04782999800203905, 0.04776569320116982, 0.048645833463475625, 0.04902563797912491, 0.04850721366257169, 0.048417141206161994, 0.04821062826874223, 0.04883959053482253, 0.04880784533216289, 0.04748158867335797, 0.04705056445703856, 0.04779788854831927, 0.04779389450225841, 0.048142638289002955, 0.0485776712187217, 0.04957489907955567, 0.04858022137661657, 0.04907164846725589, 0.049354265200323065, 0.04884120376327435, 0.04854948693775135]\n",
      "accuracies : [0.5182870884773662, 0.5191404320987655, 0.5198270061728395, 0.5199148662551438, 0.5183466049382716, 0.5196243827160494, 0.5142753600823046, 0.5202088991769549, 0.516095730452675, 0.5169863168724279, 0.5166758744855966, 0.5175951646090535, 0.5194230967078189, 0.5205749485596706, 0.5215992798353909, 0.5193189814814813, 0.519360648148148, 0.5190937242798354, 0.5216763374485597, 0.5225257716049382, 0.5221317901234567, 0.5195501028806585, 0.5193192386831275, 0.5218434156378599, 0.5181452160493827, 0.5209372942386832, 0.522481790123457, 0.5207753600823044, 0.5204309670781894, 0.5214466563786009, 0.5231649691358026, 0.5206593106995886, 0.5189336934156379, 0.5220850308641974, 0.5198775720164609, 0.5198123456790125, 0.5227172325102881, 0.5202338991769548, 0.5223113683127573, 0.5242510288065841, 0.5195456275720163, 0.5201444444444445, 0.5215834876543209, 0.5222267489711935, 0.5223515946502059, 0.5219390946502057, 0.523149794238683, 0.5188626028806584, 0.5230817386831277, 0.5227370370370369, 0.5209257716049384, 0.5225863168724278, 0.5224791666666667, 0.521836368312757, 0.5209349794238683, 0.5223843621399177, 0.5185842078189301, 0.5212836934156378, 0.5225639917695475, 0.5224973251028805, 0.5233926954732511, 0.5230186728395062, 0.5235133230452675, 0.5234643518518519, 0.5231216049382718, 0.5212310185185185, 0.5223912551440328, 0.5233319444444444, 0.5224407407407407, 0.5221305041152264, 0.5229268518518518, 0.5226756172839506, 0.521902057613169, 0.5234598251028806, 0.5240564300411523, 0.5224970164609054, 0.5228949588477367, 0.5225203703703705, 0.5224534465020575, 0.5223804012345679, 0.5221626028806586, 0.522255195473251, 0.5231262860082305, 0.5236480967078189, 0.5229251028806584, 0.5230574588477366, 0.5233787551440331, 0.5212655864197531, 0.5237461419753088, 0.523603755144033, 0.5222062242798352, 0.5233432613168724, 0.5224973765432098, 0.5235534979423869, 0.5231069958847735, 0.5212929526748968, 0.522041512345679, 0.5217434670781894, 0.5231703703703703, 0.5247619855967076, 0.5227395576131687, 0.5217234053497942, 0.522661316872428, 0.5230331275720164, 0.5222809156378602, 0.522616718106996, 0.5230434670781893, 0.5234475823045267, 0.5235901748971193, 0.5229484053497943, 0.522543158436214, 0.522760185185185, 0.5237000514403293, 0.5249547839506173, 0.5232949074074075, 0.5232826131687242, 0.5225132716049382, 0.5232066872427984, 0.5239651748971194, 0.5242632201646091, 0.5231250000000001, 0.5237819444444445, 0.5244642489711934, 0.5221191872427985, 0.5230902777777778, 0.5227973251028807, 0.5232385802469137, 0.5243614197530864, 0.5238388374485599, 0.5220419753086419, 0.522511522633745, 0.5234014917695472, 0.5226490226337449, 0.5245792181069958, 0.5245777263374486, 0.5242203703703703, 0.5230439814814817, 0.5235246399176955, 0.5220795267489712, 0.5233292181069958, 0.5232730967078187, 0.5243109567901234, 0.5229773662551439, 0.5233179526748971, 0.5237885802469134, 0.5233461419753088, 0.5241741255144035, 0.5244263374485597, 0.5244532407407407, 0.5237826646090533, 0.524490329218107, 0.5242527777777778, 0.5246541666666669, 0.5236967078189301, 0.5241831790123457, 0.5240358539094653, 0.5235274691358024, 0.5243872942386832, 0.5238941872427985, 0.5240333847736625, 0.5240005658436214, 0.5239091563786008, 0.5232907407407409, 0.5242395061728394, 0.523804012345679, 0.5234318930041152, 0.5240716563786006, 0.5226093621399177, 0.522229681069959, 0.523479269547325, 0.5248579218106997, 0.5240998456790122, 0.5241544238683129, 0.5243428497942385, 0.5244930041152264, 0.5249309156378601, 0.5249117283950616, 0.5243904835390948, 0.5244502057613167, 0.5247793724279837, 0.5239156893004117, 0.5230710905349795, 0.5225330246913581, 0.5244806584362139, 0.524236574074074, 0.5233921296296297, 0.523392438271605, 0.5243652263374486, 0.5244024691358025, 0.5239265946502056, 0.5246586419753086, 0.5234417695473251, 0.5248378086419753, 0.5233875, 0.5235093621399176, 0.5229885288065842, 0.5234858024691358, 0.5226615226337447, 0.5231041666666668, 0.5253145061728395, 0.5232845679012345, 0.5235914609053498, 0.5231884773662551, 0.5226879629629629, 0.5224241769547326, 0.5225987139917695, 0.5218479938271605, 0.523201903292181, 0.5229229938271605, 0.5219656378600822, 0.522939351851852, 0.5234141460905349, 0.5226683127572015, 0.5230421296296298, 0.5230882716049383, 0.5233259773662553, 0.523310802469136, 0.5233796810699589, 0.5227480452674896, 0.5232235082304527, 0.5239882716049381, 0.5234686213991768, 0.5242936728395063, 0.524016255144033, 0.5237838477366256, 0.5246997942386831, 0.5242676954732509, 0.5245133230452675, 0.5243745884773664, 0.5241544753086421, 0.5245299897119343, 0.5249317386831276, 0.5251304526748971, 0.5249197016460906, 0.5248024691358025, 0.5248233539094652, 0.5251221193415638, 0.52510591563786, 0.5244571502057612, 0.5241647633744856, 0.5246094135802469, 0.5246197016460907, 0.5247893004115225, 0.5249939300411522, 0.5254338477366255, 0.5248382716049382, 0.5248007201646091, 0.5246554012345679, 0.5241549382716048, 0.523618878600823]\n",
      "precisions : [0.5219441790374125, 0.5203564715001235, 0.5219458491683527, 0.5201394132843943, 0.521242514016781, 0.5244132335231984, 0.5308102755626499, 0.5237748037213162, 0.5336806906299233, 0.5278355585631872, 0.5335773961847042, 0.5332767708116857, 0.5242623577033994, 0.52266865917458, 0.5223035464794792, 0.5254850139828754, 0.5291041797834043, 0.5278520012474387, 0.52284272267784, 0.5230003127994384, 0.5217134418956977, 0.5329892420010451, 0.5267556820236187, 0.523409040574391, 0.5318000055387804, 0.5222950958411966, 0.5242048028402363, 0.5234310668001925, 0.5291331625863688, 0.5244900673077725, 0.5230504542057509, 0.5252285695235136, 0.5279644075481739, 0.5229147084609879, 0.5289040004415771, 0.5292531252532177, 0.522661932020183, 0.5264907031599383, 0.5260826526337006, 0.5240242889680812, 0.5318020336825174, 0.527797635335249, 0.522424085633706, 0.5236999983822386, 0.5222592458915322, 0.5220867160091344, 0.522744737255494, 0.531008818145997, 0.5231289554071752, 0.5225104227307265, 0.528928682961927, 0.5226241180297676, 0.5220785965001453, 0.5275557531433531, 0.5275932993153711, 0.5224258312686352, 0.5330184219871587, 0.5311399420031083, 0.5288354177457476, 0.5243730029417789, 0.5230060105598469, 0.52295423749554, 0.5254404523630974, 0.5236539978507442, 0.5233544894461966, 0.5262659443669614, 0.5220052854279478, 0.5230851114744669, 0.5245622439030058, 0.5227795917804637, 0.5231039090588909, 0.522439349718015, 0.5260462130859013, 0.5230985097797188, 0.5244163830310818, 0.5262151410142875, 0.5237501592863253, 0.5231437765306883, 0.5251553012446838, 0.5264333838869676, 0.5220268251423005, 0.5221407447687441, 0.523366731244321, 0.5232756889132689, 0.5233289275606658, 0.52317119923829, 0.5239166964518703, 0.5294049643585631, 0.5234276279910479, 0.5232956860717415, 0.5261893585325083, 0.524081179109921, 0.5258355699900518, 0.5239656461814789, 0.5238791466529791, 0.5293264623605703, 0.5234775310227938, 0.5261982411386963, 0.524033360283393, 0.524455358379239, 0.525745353800618, 0.5264863563350995, 0.5254676858055783, 0.5252548658763405, 0.5272141134871946, 0.524102332442317, 0.5273060267544062, 0.5245580074176998, 0.5244565449412957, 0.5231493836511968, 0.5265560046132486, 0.5242475268200709, 0.5271598797166788, 0.5256907636783242, 0.5259404258366156, 0.5254267382014346, 0.5302571456059048, 0.5271801312111758, 0.5271111055270031, 0.5268408916471953, 0.5227351204298968, 0.5265184577151119, 0.526039167598849, 0.5262981185617239, 0.5249145918236447, 0.5256197499060805, 0.5252702926994525, 0.524844822929806, 0.524036201878862, 0.5272930413141835, 0.5287252904843155, 0.526758134669805, 0.5287535779091267, 0.525754570209685, 0.5258384318694954, 0.5251244402408678, 0.5236273450830907, 0.524745732324035, 0.5246924252047053, 0.5238826203877279, 0.5255879840348631, 0.5251131022358373, 0.5266218714187326, 0.5253312047488433, 0.52493583332199, 0.5250153430742245, 0.5247378263400307, 0.5245611435016572, 0.5240931546300113, 0.524101491841927, 0.5250412899488006, 0.5246064562894143, 0.52461998314961, 0.5246923855864345, 0.5242500227914777, 0.5240101432792073, 0.5257118831429861, 0.5253678723479803, 0.525429672632287, 0.5237217133460673, 0.5244959723977429, 0.5235428362916539, 0.5237472542611729, 0.5240466918749197, 0.5234453417747861, 0.5243521465041626, 0.523710530663184, 0.5231443648768906, 0.5233065217821619, 0.5230946353447711, 0.5245070538727754, 0.5250231651674934, 0.5240720918736252, 0.5240070948297643, 0.5241475178446786, 0.5245832563706524, 0.5245901795022704, 0.5240419648816198, 0.5242685757930323, 0.5244881894288789, 0.5240966995807075, 0.5233605044860492, 0.5230110185504585, 0.5242167853998442, 0.524064470673333, 0.5236548752894971, 0.5233312960370805, 0.5240390965958269, 0.5243385609946536, 0.5235975695931626, 0.5243055928080045, 0.5232048795714462, 0.5244846362362291, 0.5236311375585176, 0.5234297656128448, 0.523710248627394, 0.5238177101924926, 0.5238826017528622, 0.5236966771436511, 0.5251323255593549, 0.5241582445169285, 0.5239149159595041, 0.5237110791293746, 0.5239696677649063, 0.5238427337980022, 0.5241376320330812, 0.5239703102623289, 0.5247886293136499, 0.5248582731997757, 0.5239340428395093, 0.5248846774457929, 0.5247771280994991, 0.5245316722479143, 0.5247017274627689, 0.5246218225374704, 0.5244781030516232, 0.5243742907248619, 0.5242620580970742, 0.5239427028038237, 0.5243422327578062, 0.5245083875530292, 0.5241592482592299, 0.5242362150591635, 0.5241471534454153, 0.5239557503544643, 0.5246757639286224, 0.5243383484946146, 0.5242939431693713, 0.524371103231937, 0.5239369010130207, 0.5242135536230893, 0.5245998158652875, 0.5248106356630958, 0.5246595510046316, 0.5244535390449788, 0.5247834242858184, 0.5249955255906222, 0.5250576719414622, 0.5246414481279253, 0.524902573986293, 0.5248086096273635, 0.5246685634746457, 0.5248445036599406, 0.5250816491480433, 0.5251447360628753, 0.5244817484460054, 0.5245654443611371, 0.5246761006393678, 0.5244408321077272, 0.524380646307366]\n",
      "recalls    : [0.5149788528465835, 0.5166176578367679, 0.5170452431273199, 0.5179654344039188, 0.5152096882006263, 0.5162073765083172, 0.509375927338085, 0.5170795811886267, 0.5113087293339323, 0.5126326660567262, 0.5119541708626892, 0.5130092503135962, 0.5159845925583189, 0.5178551226387735, 0.5195043240871208, 0.5156623939669736, 0.5153026494150693, 0.5151095831682417, 0.5193565581190135, 0.5206212016849701, 0.5212815323367211, 0.5152270075200888, 0.5154963918252197, 0.5193831747247654, 0.5137112240725562, 0.5184937678648871, 0.5200347029597262, 0.5178990695148632, 0.5165644194572556, 0.5185385350379262, 0.5217535355002215, 0.5173684746812514, 0.5149206357619448, 0.5199590953765683, 0.5159410569650438, 0.5158215367661255, 0.5212220427953467, 0.5166482232249966, 0.5193079684150442, 0.5230549224488271, 0.5153111680239888, 0.5163718902676279, 0.5194353923405558, 0.5198517187255702, 0.5208491880648736, 0.5202056446973539, 0.5223769903377832, 0.5145774920458617, 0.5215137197521694, 0.5214372128786854, 0.5171672538957109, 0.520989564867604, 0.5215460748865434, 0.5184469679368046, 0.5173435083216711, 0.5207674076562402, 0.514135633196673, 0.5173675500889217, 0.5191502151164319, 0.5199948428545789, 0.5226263874723359, 0.5215522502554608, 0.521059866444588, 0.521800760268037, 0.5214088173502253, 0.5178994405752122, 0.5214312064519154, 0.5220866600024507, 0.5198527919824171, 0.5200967775746996, 0.521237468846543, 0.5214127316861945, 0.5187961630402212, 0.522511862166288, 0.5223207831092652, 0.519519929152421, 0.5208189375658244, 0.5205387390475379, 0.519702255062969, 0.5193190728465868, 0.5207233204715886, 0.522136686344001, 0.5214130192459813, 0.5230273224801031, 0.5210963656303665, 0.5214306177902942, 0.5215091232180431, 0.5175204627452719, 0.5227286436824593, 0.5225211622732674, 0.519158257388202, 0.5213677059441195, 0.5196023623769482, 0.5217509821809617, 0.521085347890219, 0.5175647498337156, 0.5196788217692067, 0.5185597301249106, 0.5211007839030587, 0.5237528536954624, 0.519937732740464, 0.5184800842212288, 0.5198945523671438, 0.5204527989987917, 0.5190445554632167, 0.5202643983913174, 0.5199926278881594, 0.5212908144466694, 0.5215520699086468, 0.5212512928746853, 0.5194965805497007, 0.5204102848237631, 0.5208504626657914, 0.5230663032087203, 0.5206168215916763, 0.5207464434015625, 0.5188992057071627, 0.5202077269045222, 0.5212031665449762, 0.5216653793243098, 0.5222931418036173, 0.5211269327069105, 0.5221922095882363, 0.5190202140082502, 0.5206585035676605, 0.5200482209173719, 0.5207378107863739, 0.5225770311760624, 0.5222430049259322, 0.5187444858457834, 0.5191056815271324, 0.5205667046559871, 0.5192638802101177, 0.5224673377422497, 0.5224355841426213, 0.5222057813015002, 0.5211229464365571, 0.5213279112502466, 0.5193253267011139, 0.5214441059803228, 0.520704778113916, 0.5223504671888382, 0.5200539497038695, 0.5208388806746855, 0.5216509400749694, 0.5209681169213863, 0.5223336701064426, 0.5228778754099653, 0.5237637822803191, 0.5220570170217788, 0.5226787849367267, 0.5225438848644776, 0.5232558394592083, 0.5216035783816729, 0.5226602992669892, 0.5225966244332555, 0.5209991722637445, 0.5223545568346715, 0.52160378439494, 0.5235978048323845, 0.5221765962018948, 0.5233341584413576, 0.5214438698983385, 0.5240163221519998, 0.5229026845018175, 0.5213444096022676, 0.5234630580302647, 0.5230239995962587, 0.5229522158464759, 0.5227145477919387, 0.5241754854627916, 0.5220644654751095, 0.5240689502153871, 0.5238460230916538, 0.5236232486528548, 0.5241078899245327, 0.5244458457782661, 0.523836265274288, 0.5242443986722138, 0.5243921961399075, 0.5240801513350976, 0.523315267180216, 0.5229135515561625, 0.5241400383985912, 0.5240430001702157, 0.52362026491891, 0.5233329280372493, 0.5238731970554199, 0.5243381581487353, 0.522919978181586, 0.5238724253809739, 0.5222354466519713, 0.5242431361946994, 0.5236000085280504, 0.5234294238498599, 0.5235186741179831, 0.5237639774880684, 0.5234464929415196, 0.5235567016710396, 0.5251027539809544, 0.5238957535334593, 0.5238650048445533, 0.5235980730341748, 0.523502530639258, 0.5233028344137726, 0.5235290525410692, 0.5230156504959557, 0.5241440898752651, 0.5240053089690614, 0.5230716869845945, 0.5240283217076024, 0.5242585263895144, 0.5237282118510566, 0.5240152796426981, 0.524011383944438, 0.524078630000662, 0.5240195444384869, 0.5239945781632257, 0.5235185751175485, 0.5239537484446882, 0.5243930316632525, 0.5239722254900299, 0.5242358023289075, 0.5241387228066715, 0.5239397040226818, 0.5246783556898895, 0.5243363569516546, 0.5242499276470824, 0.5243733033915646, 0.5238931271307752, 0.5235567789133951, 0.5240492385401759, 0.5242186926943891, 0.523854497423569, 0.523966142443961, 0.523446006458578, 0.5238575678255465, 0.5237674816952608, 0.522873365854288, 0.5222246498399264, 0.5230229428007447, 0.5231497453800877, 0.5233224682699998, 0.5235213532328118, 0.5244353748379201, 0.5241000383224873, 0.5245062534284289, 0.5246781652424913, 0.5244003961794089, 0.5241693401687926]\n",
      "f1_scores  : [0.47494558089848393, 0.49461398948885343, 0.4898642931071517, 0.505478033978053, 0.4796572028876314, 0.4735524636222863, 0.40869980712700715, 0.48211898483287546, 0.4163013010060594, 0.43772745289835857, 0.420472416197116, 0.427757383680738, 0.47256824339056996, 0.4922564839867724, 0.5049651918963717, 0.46581768967366316, 0.4520322859819348, 0.4544090885890495, 0.501341068125127, 0.5088203791696855, 0.5192439065578224, 0.4419819085655523, 0.46037207142575715, 0.4989075994628293, 0.43540824655850585, 0.4982180948387502, 0.49970999579271075, 0.4891080506166652, 0.46018471542608536, 0.4888636856285408, 0.5156003951906775, 0.47825382438725744, 0.4528312723262334, 0.5049860548300547, 0.45689604429002717, 0.45501034133224083, 0.5142079079639942, 0.468987584953699, 0.4874189393201797, 0.518742194096162, 0.4454055200330654, 0.4629168239525383, 0.5040023955623828, 0.5006644760378682, 0.5138272362253667, 0.5106107731980084, 0.5207803812769722, 0.44268897300607873, 0.5137287633781782, 0.5162566834420598, 0.4642656361293234, 0.5128502681890184, 0.5190579321453039, 0.4767423176022077, 0.46978358289490957, 0.5125169184137606, 0.4354110245106284, 0.45925130434000466, 0.4768221046833083, 0.498708319466139, 0.5209920738991268, 0.5147916578172879, 0.5007584794604016, 0.5130608712924564, 0.5120310239244642, 0.47783113175257247, 0.5187324714428037, 0.517418088963498, 0.4969733778158824, 0.5065283065751317, 0.5121126629728957, 0.5164369870352934, 0.4844557090493631, 0.5198862835792325, 0.512708224716542, 0.4883095009142813, 0.5065612186864321, 0.5076082530542078, 0.49351165010411674, 0.48607927010201674, 0.5142059921427037, 0.522105934578623, 0.5120175015158882, 0.5220060382584176, 0.5102298228146647, 0.5130535957644461, 0.5100605997520717, 0.46508074750965767, 0.5196155681480553, 0.5190149125971194, 0.4861789914419144, 0.5084561116545894, 0.4901649648876086, 0.5113379529733985, 0.507652568917053, 0.46574502735162354, 0.500682147230877, 0.4823509866977172, 0.5070738471659098, 0.5207701121708667, 0.4926478067168532, 0.4808721166031142, 0.49349455865894737, 0.4978137550637993, 0.4815844033024861, 0.5015341946784364, 0.4871108009783776, 0.5059018884338448, 0.5078922202830931, 0.5120755260627933, 0.4867389963681517, 0.5017908340100391, 0.4926976533422795, 0.5115282640986913, 0.49604218840388525, 0.4989564577895434, 0.4708437341664637, 0.4887634707298684, 0.49498518753060633, 0.4987364566739829, 0.5203371955627938, 0.4968926371022913, 0.5049942698898663, 0.484849868601652, 0.5005176702614434, 0.49386231920463547, 0.49944014166553613, 0.5123266482911436, 0.5139455147436857, 0.47946553376245876, 0.47685753018868127, 0.49254189949652033, 0.4776979896695673, 0.5077948012958596, 0.5072541924460893, 0.5088872318025836, 0.5090664946443799, 0.5052910317317555, 0.4931370269364921, 0.5098174299086203, 0.49791233839576937, 0.5098310935788218, 0.4900372792352398, 0.49982594495724303, 0.5064428326569368, 0.5019996768223705, 0.5113463379972594, 0.5153143103492468, 0.5224420037040605, 0.5125226348690549, 0.5120503047990282, 0.5131982236090545, 0.5172066730209572, 0.5072639977079573, 0.51544304489212, 0.5161502226597006, 0.49921552526005913, 0.5087422723831704, 0.504084063157083, 0.5231454626126385, 0.5114676192622133, 0.5225049097545179, 0.5104522889237985, 0.5239185556589805, 0.5205447021675466, 0.5071100885073365, 0.522469578536655, 0.5221206319299739, 0.5206665148194373, 0.5210796302604995, 0.5228624319778103, 0.5084973489756214, 0.5240311467897241, 0.523241153528161, 0.5214104547751167, 0.5221725717399975, 0.5239226383103032, 0.5230442174410569, 0.5241655894049267, 0.5240608609999953, 0.5238448213066339, 0.5228938333095604, 0.5221383074711903, 0.5238729435484043, 0.5239727367090787, 0.5232561275124074, 0.5233024245215057, 0.5232426164434937, 0.5243019075580496, 0.5199485148070997, 0.5220911814018556, 0.5177804140380639, 0.5233069876852504, 0.5232661475497397, 0.5234005042225882, 0.522209587692193, 0.52328131935692, 0.520785531364623, 0.522539880383932, 0.5250046893646175, 0.5222078100020063, 0.5234109254972971, 0.5227416553001876, 0.5206651394875444, 0.5200657198010651, 0.5199365452153738, 0.5175442201246797, 0.5204786815756403, 0.5192567093377441, 0.5180830952728547, 0.5192546071850263, 0.5212539892627132, 0.5191782464575313, 0.5201185132766517, 0.5205010442656713, 0.5216714728376934, 0.5218481513238952, 0.5222970921592582, 0.520937859005318, 0.5216022991061177, 0.5235524042389395, 0.5227248813570956, 0.5241978053303419, 0.523963725240302, 0.5237089750194468, 0.5246332121002845, 0.5242234302606191, 0.5241031124132904, 0.5243180466825031, 0.5237450353721999, 0.5207569973766893, 0.5217698117530961, 0.5217749798091971, 0.5204361264936478, 0.5219482105554468, 0.5175988059835629, 0.5189703408556781, 0.5181940664365025, 0.5149433860296213, 0.5100370338773325, 0.5150714252019842, 0.5163917807687273, 0.516605153777858, 0.5167158851346053, 0.5215073165750773, 0.5225616537986438, 0.5243067780663032, 0.5246082583923799, 0.5240078298897847, 0.5227784237956916]\n",
      "auc        : [0.5288578887388136, 0.5312706530166398, 0.5308407231258866, 0.5311881780808267, 0.52952684409538, 0.5328451204574765, 0.5292331894103371, 0.532754563087324, 0.5300826493445682, 0.5314196969538959, 0.5325213964392975, 0.531829425578172, 0.5326244281064171, 0.5337138110487535, 0.5339295148243307, 0.5339707572747743, 0.5350877246654321, 0.5346311028198206, 0.5343621765972709, 0.5347828944330686, 0.5335984697889361, 0.533570916509254, 0.5338296697264834, 0.5344521989819736, 0.5341815056008207, 0.5338323461733777, 0.5348157414289393, 0.5331553892788248, 0.5349146155184753, 0.5343566549960178, 0.5339731412024668, 0.5345173883026476, 0.5334862347478678, 0.5351575796843865, 0.5346914770898642, 0.5344235769408986, 0.5348098706326804, 0.5339465485793718, 0.5349014909645752, 0.5355001876168479, 0.5344593770522302, 0.5337863079440544, 0.5347003355666393, 0.5338275790852715, 0.5333085103262055, 0.5339186585596727, 0.5347810150538955, 0.5343399536346353, 0.5351102083805789, 0.5350598925969173, 0.5349516697915265, 0.5339519268806714, 0.5333765576885889, 0.5337776352696141, 0.5356195795201083, 0.5337182371396433, 0.5349763081174284, 0.5342248561211246, 0.5356735466816905, 0.5347658058616774, 0.535019547921898, 0.5349816423623465, 0.5355693098180466, 0.5341860519913911, 0.5348870428502058, 0.5345064720476977, 0.5339296770301588, 0.5350303809476333, 0.5336864192072314, 0.5337018077295049, 0.535267626795959, 0.5353922960987804, 0.5358720723004249, 0.5353655790577149, 0.5359296574571889, 0.5354402599927314, 0.534610797067952, 0.535033427259337, 0.5343938166008019, 0.533907387331223, 0.5351807886315195, 0.5345422945018514, 0.5342856638369334, 0.5345087216486465, 0.5356067250510984, 0.534739792173022, 0.5352263356930428, 0.5355578235507282, 0.5358764141271143, 0.5364245406540576, 0.5360421662047297, 0.5357435622391905, 0.5364104418122706, 0.5356453659975463, 0.5353172691560583, 0.5357713614256537, 0.5352592666408998, 0.5352780601772863, 0.5351701709018929, 0.5361312058866247, 0.5357916231716964, 0.5361066974957895, 0.5359297982693091, 0.5361928095020517, 0.5359770733352665, 0.5347920341265816, 0.5364934823169191, 0.5356571117719924, 0.5356250355640979, 0.5349892246919933, 0.5350793236589636, 0.5356061013098118, 0.5363772885548072, 0.5362090270280503, 0.5357835715254629, 0.5360025640050977, 0.5367224331964267, 0.5367487951549625, 0.5365583900263603, 0.5366328586574446, 0.5361314143391472, 0.5362615065592922, 0.5364351336973344, 0.5350373254424466, 0.534609268151513, 0.5355043818381334, 0.5357671214346508, 0.5363725319591487, 0.5353108879556062, 0.5359998571948726, 0.536679741031923, 0.5360849999133901, 0.5364568668230922, 0.5363492936316367, 0.536372978949691, 0.5361218537124873, 0.5360697323303515, 0.5364072780820485, 0.5359415695414508, 0.5359064602048714, 0.5367397794884691, 0.5371128516125243, 0.5370592234036718, 0.5362438189668529, 0.5362303392300991, 0.53638542388467, 0.5370482983808104, 0.5364482210569101, 0.5368766560932002, 0.5359236982445007, 0.5366463519127523, 0.5368050857089915, 0.5368308519724454, 0.5370311106055438, 0.536612089257531, 0.5370576093622649, 0.5368590195624628, 0.536651854431263, 0.5365119820017381, 0.5363508006374126, 0.536487267857418, 0.5366359208481497, 0.5362208913631298, 0.5370245054570131, 0.5362120364414925, 0.5361588403711252, 0.5368937850624028, 0.536653544511921, 0.5366815932549037, 0.536760873748402, 0.5371322145809462, 0.5365416548968838, 0.5370967868180517, 0.5363703294709402, 0.5367033865175298, 0.5371627686821419, 0.5371675944255279, 0.5369274296323828, 0.5367827704915372, 0.536878574466183, 0.5365304281141959, 0.5360961737220652, 0.5362254996826998, 0.5363545773779023, 0.5366036431839148, 0.5365863838122683, 0.5360531787536057, 0.5366463342377232, 0.536455138772015, 0.536032982331846, 0.5367117569026844, 0.5357853029043084, 0.536458562709108, 0.5359682286427979, 0.5365528213745391, 0.5368556845768201, 0.5368667092555542, 0.5368758761681441, 0.5367732512502063, 0.5371338708858107, 0.5367536025310427, 0.5365655737918286, 0.5366965873846185, 0.5368384507739722, 0.5367452482495191, 0.5368335978310484, 0.5367468550551846, 0.5368449943253658, 0.5370688860797027, 0.5366889448444869, 0.5365804796348753, 0.5366555772104161, 0.5370625558437729, 0.536790753417536, 0.5373631448286585, 0.537416913127858, 0.5370077918861821, 0.5367382489472917, 0.5367886136560082, 0.5370898214977287, 0.5372758956237904, 0.5371252468376363, 0.5373281144920736, 0.5372890313912706, 0.5372678733086637, 0.5371488403023199, 0.5370311167892691, 0.5371663674616347, 0.5369142832548712, 0.5371607438376806, 0.5372111587735168, 0.5372579492291998, 0.5374147973228621, 0.5372646495812615, 0.537248853654166, 0.5373350287478037, 0.5374073302899691, 0.5373907578289984, 0.5375172290873993, 0.5374950163334457, 0.537449805964883, 0.5374202085614854, 0.5375435886893086, 0.5375258329801215, 0.5374248050221292, 0.537555145289437, 0.53752219633307, 0.5375654721749784, 0.5375198740807682, 0.5375334747815499]\n",
      "losses     : [0.6918108500540257, 0.6913714384039243, 0.6913590952754021, 0.691199050595363, 0.6916596367955208, 0.691141045341889, 0.6917775099476179, 0.6910876420636972, 0.691657812645038, 0.6911829374730587, 0.6913058037559191, 0.6910775626699129, 0.6909132897853851, 0.6908726952970028, 0.6909500571588675, 0.6908570751547813, 0.6908145907024542, 0.6909921405216058, 0.6906200783948103, 0.6907925953467687, 0.6908368468284607, 0.6909141540527344, 0.6910095276931921, 0.6907843872904778, 0.6908862628042698, 0.6909596634407839, 0.6906025744974613, 0.6907968310018381, 0.6906763191024462, 0.6906771721939245, 0.6906651395062605, 0.6906358959774176, 0.6908433002730211, 0.6906555195649465, 0.6906092539429665, 0.6907213541368643, 0.6905825200180212, 0.6906651755174001, 0.6905577518045902, 0.690506212413311, 0.6906475971142451, 0.6906375127534071, 0.6904602162539959, 0.6906132027506828, 0.6905157615741094, 0.6903968354066213, 0.6903908451398214, 0.6907300688326359, 0.6904727679987749, 0.6903905558089415, 0.6904682219028473, 0.6905806673069795, 0.6905462568004926, 0.6906892682115237, 0.6904325932264328, 0.6906627913316091, 0.690689733872811, 0.690609031667312, 0.6905020537475745, 0.6906456537544727, 0.6905582013229529, 0.6904270723462105, 0.6903953837851683, 0.6907666561504205, 0.6903407437105974, 0.6907678705950578, 0.6905465051531792, 0.6904331209758917, 0.6906701860328516, 0.6906337179243565, 0.6903360486030579, 0.6903208692868551, 0.6904530661801497, 0.6903386376798153, 0.6903583121796449, 0.6906370868285497, 0.6904451586306095, 0.690516841908296, 0.6904332066575686, 0.6905737891793251, 0.6905314363539219, 0.6905870325863361, 0.6905454633136591, 0.6904970606168112, 0.6903550152977308, 0.6904147466023763, 0.6905043857793013, 0.6904868707060814, 0.6902883487443129, 0.6901327235003313, 0.6902439321080843, 0.6902099711199602, 0.6902526306609312, 0.6904465444386005, 0.6902438079317411, 0.6904666225115458, 0.6902539556225141, 0.6902919361988703, 0.6903775619963805, 0.6902521351973215, 0.6904911336799463, 0.690484789510568, 0.6903970787922541, 0.6902831445137659, 0.6903811072309812, 0.6904994659125805, 0.6903569089869658, 0.6904355064034462, 0.6905676623185476, 0.6903442405164242, 0.6904522875944773, 0.6903044432401657, 0.6902841478586197, 0.6903311150769392, 0.6904240685204664, 0.6903616711497307, 0.6904312695066134, 0.690245204915603, 0.6902843502660593, 0.6902438153823217, 0.6903750486671925, 0.6903343784312407, 0.6902105212211609, 0.6904285562535127, 0.6904175529877344, 0.6904571652412415, 0.6902112637956938, 0.6901630361874899, 0.6903523951768875, 0.6901336635152499, 0.6903027109801769, 0.6900064932803313, 0.690297977377971, 0.6901815496385098, 0.6903934143483639, 0.6901456452906132, 0.6901491073270639, 0.6902269447843233, 0.6901469528675079, 0.6901471416155497, 0.6902291215956211, 0.6899368415276209, 0.6901580641667048, 0.6902206987142563, 0.6902047110100588, 0.690035093575716, 0.6898843310773373, 0.6900215844313303, 0.6900400208930174, 0.690154142677784, 0.6900546190639337, 0.6900741631786028, 0.6899452296396097, 0.690094937880834, 0.6899835454920927, 0.6898794906834761, 0.6899896649022897, 0.6900045486787955, 0.6900565885007381, 0.6899172551929951, 0.6898874789476395, 0.6899260692298412, 0.6899776508410772, 0.6899945649007956, 0.6901202276349068, 0.689982458949089, 0.6898226700723171, 0.6899301595985889, 0.6899450868368149, 0.6898590897520384, 0.689845584332943, 0.6899899815519651, 0.6898702618976434, 0.6899497024714947, 0.6898481287062168, 0.6897924828032652, 0.6898532745738825, 0.689850427210331, 0.6899313641091188, 0.6898466870188713, 0.6898475016156832, 0.6899459895988306, 0.6900004247824351, 0.6899028830230236, 0.6898724660277367, 0.690014224499464, 0.6900325405100981, 0.6898818587263426, 0.6898846042652925, 0.6898972764611244, 0.6898312705258528, 0.6899081021547318, 0.6899476796388626, 0.6900354934235414, 0.6898640928169092, 0.689843642214934, 0.6898765365282694, 0.6899845115840435, 0.6899969664712747, 0.6898020766675472, 0.6898283325135708, 0.6899468128879865, 0.6899653983612856, 0.68994598214825, 0.6899894302090009, 0.6899153937896093, 0.6899908011158308, 0.6900684783856074, 0.6899244859814644, 0.6899319862325987, 0.6899514446655909, 0.6899538797636827, 0.6899261511862278, 0.6898761615157127, 0.6898156106472015, 0.6898034413655599, 0.6898261358340582, 0.6898627181847891, 0.6898307502269745, 0.689753836641709, 0.6897401909033457, 0.6897783875465393, 0.6897403498490652, 0.6898760559658209, 0.689831580966711, 0.6897785154481729, 0.6897940126558145, 0.6897464146216711, 0.6897899843752384, 0.6897076529761156, 0.6896802646418413, 0.6896175419290861, 0.6896249788502852, 0.6896177803476652, 0.6896301334102949, 0.6896128915250301, 0.6895909644663334, 0.6896061661342779, 0.6895812464257082, 0.689607052753369, 0.6895965238412222, 0.6896005272865295, 0.6895984783768654, 0.6895903286834558, 0.6895989030599594, 0.6895945432285467, 0.689615352700154, 0.6896205246448517, 0.6896495272715887, 0.6896807538966337]\n",
      "tr_losses  : [0.6942566494930648, 0.6918341722123308, 0.6917526752378991, 0.6916781905908872, 0.6917138088606903, 0.691633412013751, 0.6916321854856894, 0.6916223563893489, 0.6916669247598494, 0.6915866920676973, 0.6917218157974031, 0.691554102986152, 0.6916100562586862, 0.6916287035234013, 0.6914906046783288, 0.691458726565412, 0.6914275739419764, 0.6914711113319043, 0.6913294283253965, 0.6913343438416235, 0.6913512404446259, 0.6913405459054385, 0.6912798173466304, 0.6913708323945579, 0.6911950624459304, 0.6913453119260252, 0.6912958971862173, 0.6912547304292842, 0.6911699853474469, 0.6912154682551072, 0.6910828777919512, 0.691149794032015, 0.6912889119643899, 0.6911012894039641, 0.6911603324374578, 0.6910602505688325, 0.6911399226177596, 0.6911865944375571, 0.6910806038263503, 0.690998005203194, 0.6910045662778159, 0.6911305639970606, 0.6910774032920253, 0.6909881707133937, 0.6911179251847853, 0.6910031964773369, 0.6910054626984828, 0.6911202179583485, 0.6910587980686373, 0.6909783158943991, 0.6909826696610506, 0.6910128626635346, 0.6909572036802907, 0.690925096414482, 0.6910625621503578, 0.690952018352783, 0.6910276316158179, 0.6909462290960785, 0.6909454375021419, 0.6909395044198445, 0.6908944950302903, 0.6909040059125063, 0.6909607834163232, 0.6908997792378933, 0.6908159746924575, 0.6908624412841974, 0.6908759415287983, 0.6909824933364054, 0.690888879608942, 0.6909933138612805, 0.6908499866793161, 0.6908328443281612, 0.6908011743474726, 0.6908530379945883, 0.6908458674590162, 0.6908717744588299, 0.690815444750465, 0.6908623011925381, 0.6908242927903089, 0.6908061151714723, 0.6907729671062284, 0.690837227136519, 0.6907567040273043, 0.6907912946355869, 0.6907335754890176, 0.6907475380499236, 0.6907115420996451, 0.6907361696048568, 0.6907581934519544, 0.6907680426009016, 0.6906568766193434, 0.6906256457215949, 0.6906930466815656, 0.6906346255554677, 0.6906029381497554, 0.690668929757209, 0.6906923597760654, 0.6906113899777494, 0.6906544487326991, 0.6907166318661099, 0.6906176704541713, 0.6906287256636918, 0.6906246536015911, 0.6906239205059486, 0.6905907511434533, 0.6906390740533992, 0.690623739341019, 0.6905380531696045, 0.690546613143381, 0.690620017024038, 0.690572417390872, 0.6905951184629011, 0.6905665986775799, 0.6905035657285261, 0.690504071192509, 0.6905651186569107, 0.6904840000544236, 0.6905412301939767, 0.690497181255137, 0.6905525117905124, 0.6905070008092026, 0.6905151813046838, 0.6905303425965895, 0.6905349215056116, 0.6905874233787962, 0.6905524216229291, 0.690540185522314, 0.6904767805628323, 0.690517146875023, 0.6905060483795308, 0.6905199760903892, 0.6904690423310494, 0.6904429148908557, 0.6904129186805052, 0.6904329974247518, 0.6904306981513783, 0.6904320297827576, 0.6903082231911042, 0.6904361141530101, 0.6904364897590779, 0.6903944092947479, 0.6903704482275482, 0.6903061731232292, 0.6903682783972083, 0.6903862023851435, 0.6903263882252014, 0.6903121843415457, 0.6903444998778766, 0.6903751043045327, 0.6903066453966906, 0.6902433766566407, 0.6902971700559912, 0.690227648774875, 0.6902611499042909, 0.6902722611228164, 0.690263537547428, 0.6902587151029547, 0.6902124181977557, 0.690236926493678, 0.6902197130594895, 0.6902918399348337, 0.6902968169918193, 0.6902686526216653, 0.6902122031508355, 0.6901990931714493, 0.6902104477871321, 0.6902400155631683, 0.6901959775495419, 0.6901763431434011, 0.6901730589413034, 0.6901878597011699, 0.6901408294237407, 0.6901108556169921, 0.6901730272720142, 0.6901394847927403, 0.6901607920011622, 0.6901288318799986, 0.6901244525289868, 0.6900950743538045, 0.6901205005059386, 0.6901292067945971, 0.6900969664901149, 0.6900854510386969, 0.6900935351433721, 0.6900849652124391, 0.6901193575073561, 0.6901098540930073, 0.6900651298653498, 0.6900640900339715, 0.6900548192298606, 0.6900649246372922, 0.6900496578271871, 0.6900191240686828, 0.6900414008552126, 0.6900145700525518, 0.6900034166544053, 0.6900086122156572, 0.6900040994110904, 0.6899485839768518, 0.6900076819129997, 0.6899476109413979, 0.6899763438375256, 0.6899390639672424, 0.6900073111472163, 0.6899439651009102, 0.6899242016666174, 0.6899526570070094, 0.6899081082742341, 0.689956237572805, 0.689903237565211, 0.6899082940028605, 0.6899414350151186, 0.6899548540812357, 0.689890283304688, 0.689887803557854, 0.6898622711960511, 0.6898927388501002, 0.6898612230670425, 0.6898444247909599, 0.6898084177771743, 0.6898467448084095, 0.689846551473622, 0.6898772766307999, 0.6898625849847727, 0.6898583382575528, 0.6898438659455549, 0.6898394650207041, 0.6898026556260625, 0.689801325654209, 0.6897861275761421, 0.6897650479993798, 0.6898022742116534, 0.6897906822837423, 0.6897907746640269, 0.6897503376836843, 0.6897432703153163, 0.6897592627531968, 0.6897362738916879, 0.689735364609694, 0.6897581880717709, 0.6897260794230238, 0.689695773434473, 0.6897309202605776, 0.6896949471287827, 0.6896779918891924, 0.6897024604947827, 0.6897032700669185, 0.6896912732146455, 0.6896830468056097, 0.6896718076652828]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1,\n",
       "  'training_loss': 0.6942566494930648,\n",
       "  'eval_loss': 0.6918108500540257,\n",
       "  'eval_f1': 0.47494558089848393,\n",
       "  'eval_mcc': 0.036258670098226156,\n",
       "  'eval_precision': 0.5219441790374125,\n",
       "  'eval_recall': 0.5149788528465835,\n",
       "  'eval_auc': 0.5288578887388136,\n",
       "  'eval_accuracy': 0.5182870884773662,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 2,\n",
       "  'training_loss': 0.6918341722123308,\n",
       "  'eval_loss': 0.6913714384039243,\n",
       "  'eval_f1': 0.49461398948885343,\n",
       "  'eval_mcc': 0.03678385665289777,\n",
       "  'eval_precision': 0.5203564715001235,\n",
       "  'eval_recall': 0.5166176578367679,\n",
       "  'eval_auc': 0.5312706530166398,\n",
       "  'eval_accuracy': 0.5191404320987655,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 3,\n",
       "  'training_loss': 0.6917526752378991,\n",
       "  'eval_loss': 0.6913590952754021,\n",
       "  'eval_f1': 0.4898642931071517,\n",
       "  'eval_mcc': 0.03868069248497704,\n",
       "  'eval_precision': 0.5219458491683527,\n",
       "  'eval_recall': 0.5170452431273199,\n",
       "  'eval_auc': 0.5308407231258866,\n",
       "  'eval_accuracy': 0.5198270061728395,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 4,\n",
       "  'training_loss': 0.6916781905908872,\n",
       "  'eval_loss': 0.691199050595363,\n",
       "  'eval_f1': 0.505478033978053,\n",
       "  'eval_mcc': 0.03804247402001995,\n",
       "  'eval_precision': 0.5201394132843943,\n",
       "  'eval_recall': 0.5179654344039188,\n",
       "  'eval_auc': 0.5311881780808267,\n",
       "  'eval_accuracy': 0.5199148662551438,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 5,\n",
       "  'training_loss': 0.6917138088606903,\n",
       "  'eval_loss': 0.6916596367955208,\n",
       "  'eval_f1': 0.4796572028876314,\n",
       "  'eval_mcc': 0.03594839562140017,\n",
       "  'eval_precision': 0.521242514016781,\n",
       "  'eval_recall': 0.5152096882006263,\n",
       "  'eval_auc': 0.52952684409538,\n",
       "  'eval_accuracy': 0.5183466049382716,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 6,\n",
       "  'training_loss': 0.691633412013751,\n",
       "  'eval_loss': 0.691141045341889,\n",
       "  'eval_f1': 0.4735524636222863,\n",
       "  'eval_mcc': 0.03978159574445701,\n",
       "  'eval_precision': 0.5244132335231984,\n",
       "  'eval_recall': 0.5162073765083172,\n",
       "  'eval_auc': 0.5328451204574765,\n",
       "  'eval_accuracy': 0.5196243827160494,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:06'},\n",
       " {'epoch': 7,\n",
       "  'training_loss': 0.6916321854856894,\n",
       "  'eval_loss': 0.6917775099476179,\n",
       "  'eval_f1': 0.40869980712700715,\n",
       "  'eval_mcc': 0.0339857477360812,\n",
       "  'eval_precision': 0.5308102755626499,\n",
       "  'eval_recall': 0.509375927338085,\n",
       "  'eval_auc': 0.5292331894103371,\n",
       "  'eval_accuracy': 0.5142753600823046,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 8,\n",
       "  'training_loss': 0.6916223563893489,\n",
       "  'eval_loss': 0.6910876420636972,\n",
       "  'eval_f1': 0.48211898483287546,\n",
       "  'eval_mcc': 0.040300633459607695,\n",
       "  'eval_precision': 0.5237748037213162,\n",
       "  'eval_recall': 0.5170795811886267,\n",
       "  'eval_auc': 0.532754563087324,\n",
       "  'eval_accuracy': 0.5202088991769549,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 9,\n",
       "  'training_loss': 0.6916669247598494,\n",
       "  'eval_loss': 0.691657812645038,\n",
       "  'eval_f1': 0.4163013010060594,\n",
       "  'eval_mcc': 0.0390248970678399,\n",
       "  'eval_precision': 0.5336806906299233,\n",
       "  'eval_recall': 0.5113087293339323,\n",
       "  'eval_auc': 0.5300826493445682,\n",
       "  'eval_accuracy': 0.516095730452675,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 10,\n",
       "  'training_loss': 0.6915866920676973,\n",
       "  'eval_loss': 0.6911829374730587,\n",
       "  'eval_f1': 0.43772745289835857,\n",
       "  'eval_mcc': 0.0374999994038193,\n",
       "  'eval_precision': 0.5278355585631872,\n",
       "  'eval_recall': 0.5126326660567262,\n",
       "  'eval_auc': 0.5314196969538959,\n",
       "  'eval_accuracy': 0.5169863168724279,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 11,\n",
       "  'training_loss': 0.6917218157974031,\n",
       "  'eval_loss': 0.6913058037559191,\n",
       "  'eval_f1': 0.420472416197116,\n",
       "  'eval_mcc': 0.04006346015690989,\n",
       "  'eval_precision': 0.5335773961847042,\n",
       "  'eval_recall': 0.5119541708626892,\n",
       "  'eval_auc': 0.5325213964392975,\n",
       "  'eval_accuracy': 0.5166758744855966,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 12,\n",
       "  'training_loss': 0.691554102986152,\n",
       "  'eval_loss': 0.6910775626699129,\n",
       "  'eval_f1': 0.427757383680738,\n",
       "  'eval_mcc': 0.041608752555185834,\n",
       "  'eval_precision': 0.5332767708116857,\n",
       "  'eval_recall': 0.5130092503135962,\n",
       "  'eval_auc': 0.531829425578172,\n",
       "  'eval_accuracy': 0.5175951646090535,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 13,\n",
       "  'training_loss': 0.6916100562586862,\n",
       "  'eval_loss': 0.6909132897853851,\n",
       "  'eval_f1': 0.47256824339056996,\n",
       "  'eval_mcc': 0.03938496157683078,\n",
       "  'eval_precision': 0.5242623577033994,\n",
       "  'eval_recall': 0.5159845925583189,\n",
       "  'eval_auc': 0.5326244281064171,\n",
       "  'eval_accuracy': 0.5194230967078189,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 14,\n",
       "  'training_loss': 0.6916287035234013,\n",
       "  'eval_loss': 0.6908726952970028,\n",
       "  'eval_f1': 0.4922564839867724,\n",
       "  'eval_mcc': 0.04023585400232528,\n",
       "  'eval_precision': 0.52266865917458,\n",
       "  'eval_recall': 0.5178551226387735,\n",
       "  'eval_auc': 0.5337138110487535,\n",
       "  'eval_accuracy': 0.5205749485596706,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 15,\n",
       "  'training_loss': 0.6914906046783288,\n",
       "  'eval_loss': 0.6909500571588675,\n",
       "  'eval_f1': 0.5049651918963717,\n",
       "  'eval_mcc': 0.04171348594993473,\n",
       "  'eval_precision': 0.5223035464794792,\n",
       "  'eval_recall': 0.5195043240871208,\n",
       "  'eval_auc': 0.5339295148243307,\n",
       "  'eval_accuracy': 0.5215992798353909,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 16,\n",
       "  'training_loss': 0.691458726565412,\n",
       "  'eval_loss': 0.6908570751547813,\n",
       "  'eval_f1': 0.46581768967366316,\n",
       "  'eval_mcc': 0.03995420708651335,\n",
       "  'eval_precision': 0.5254850139828754,\n",
       "  'eval_recall': 0.5156623939669736,\n",
       "  'eval_auc': 0.5339707572747743,\n",
       "  'eval_accuracy': 0.5193189814814813,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 17,\n",
       "  'training_loss': 0.6914275739419764,\n",
       "  'eval_loss': 0.6908145907024542,\n",
       "  'eval_f1': 0.4520322859819348,\n",
       "  'eval_mcc': 0.04220449024678662,\n",
       "  'eval_precision': 0.5291041797834043,\n",
       "  'eval_recall': 0.5153026494150693,\n",
       "  'eval_auc': 0.5350877246654321,\n",
       "  'eval_accuracy': 0.519360648148148,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 18,\n",
       "  'training_loss': 0.6914711113319043,\n",
       "  'eval_loss': 0.6909921405216058,\n",
       "  'eval_f1': 0.4544090885890495,\n",
       "  'eval_mcc': 0.04102542508702906,\n",
       "  'eval_precision': 0.5278520012474387,\n",
       "  'eval_recall': 0.5151095831682417,\n",
       "  'eval_auc': 0.5346311028198206,\n",
       "  'eval_accuracy': 0.5190937242798354,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 19,\n",
       "  'training_loss': 0.6913294283253965,\n",
       "  'eval_loss': 0.6906200783948103,\n",
       "  'eval_f1': 0.501341068125127,\n",
       "  'eval_mcc': 0.0420542424695973,\n",
       "  'eval_precision': 0.52284272267784,\n",
       "  'eval_recall': 0.5193565581190135,\n",
       "  'eval_auc': 0.5343621765972709,\n",
       "  'eval_accuracy': 0.5216763374485597,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 20,\n",
       "  'training_loss': 0.6913343438416235,\n",
       "  'eval_loss': 0.6907925953467687,\n",
       "  'eval_f1': 0.5088203791696855,\n",
       "  'eval_mcc': 0.043556080461086166,\n",
       "  'eval_precision': 0.5230003127994384,\n",
       "  'eval_recall': 0.5206212016849701,\n",
       "  'eval_auc': 0.5347828944330686,\n",
       "  'eval_accuracy': 0.5225257716049382,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 21,\n",
       "  'training_loss': 0.6913512404446259,\n",
       "  'eval_loss': 0.6908368468284607,\n",
       "  'eval_f1': 0.5192439065578224,\n",
       "  'eval_mcc': 0.04299271259521906,\n",
       "  'eval_precision': 0.5217134418956977,\n",
       "  'eval_recall': 0.5212815323367211,\n",
       "  'eval_auc': 0.5335984697889361,\n",
       "  'eval_accuracy': 0.5221317901234567,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 22,\n",
       "  'training_loss': 0.6913405459054385,\n",
       "  'eval_loss': 0.6909141540527344,\n",
       "  'eval_f1': 0.4419819085655523,\n",
       "  'eval_mcc': 0.04481999048639646,\n",
       "  'eval_precision': 0.5329892420010451,\n",
       "  'eval_recall': 0.5152270075200888,\n",
       "  'eval_auc': 0.533570916509254,\n",
       "  'eval_accuracy': 0.5195501028806585,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 23,\n",
       "  'training_loss': 0.6912798173466304,\n",
       "  'eval_loss': 0.6910095276931921,\n",
       "  'eval_f1': 0.46037207142575715,\n",
       "  'eval_mcc': 0.040721878989931605,\n",
       "  'eval_precision': 0.5267556820236187,\n",
       "  'eval_recall': 0.5154963918252197,\n",
       "  'eval_auc': 0.5338296697264834,\n",
       "  'eval_accuracy': 0.5193192386831275,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 24,\n",
       "  'training_loss': 0.6913708323945579,\n",
       "  'eval_loss': 0.6907843872904778,\n",
       "  'eval_f1': 0.4989075994628293,\n",
       "  'eval_mcc': 0.04260140887807854,\n",
       "  'eval_precision': 0.523409040574391,\n",
       "  'eval_recall': 0.5193831747247654,\n",
       "  'eval_auc': 0.5344521989819736,\n",
       "  'eval_accuracy': 0.5218434156378599,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 25,\n",
       "  'training_loss': 0.6911950624459304,\n",
       "  'eval_loss': 0.6908862628042698,\n",
       "  'eval_f1': 0.43540824655850585,\n",
       "  'eval_mcc': 0.041756204780782964,\n",
       "  'eval_precision': 0.5318000055387804,\n",
       "  'eval_recall': 0.5137112240725562,\n",
       "  'eval_auc': 0.5341815056008207,\n",
       "  'eval_accuracy': 0.5181452160493827,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 26,\n",
       "  'training_loss': 0.6913453119260252,\n",
       "  'eval_loss': 0.6909596634407839,\n",
       "  'eval_f1': 0.4982180948387502,\n",
       "  'eval_mcc': 0.04061033526539558,\n",
       "  'eval_precision': 0.5222950958411966,\n",
       "  'eval_recall': 0.5184937678648871,\n",
       "  'eval_auc': 0.5338323461733777,\n",
       "  'eval_accuracy': 0.5209372942386832,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 27,\n",
       "  'training_loss': 0.6912958971862173,\n",
       "  'eval_loss': 0.6906025744974613,\n",
       "  'eval_f1': 0.49970999579271075,\n",
       "  'eval_mcc': 0.04404170184823375,\n",
       "  'eval_precision': 0.5242048028402363,\n",
       "  'eval_recall': 0.5200347029597262,\n",
       "  'eval_auc': 0.5348157414289393,\n",
       "  'eval_accuracy': 0.522481790123457,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 28,\n",
       "  'training_loss': 0.6912547304292842,\n",
       "  'eval_loss': 0.6907968310018381,\n",
       "  'eval_f1': 0.4891080506166652,\n",
       "  'eval_mcc': 0.04095700383142851,\n",
       "  'eval_precision': 0.5234310668001925,\n",
       "  'eval_recall': 0.5178990695148632,\n",
       "  'eval_auc': 0.5331553892788248,\n",
       "  'eval_accuracy': 0.5207753600823044,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 29,\n",
       "  'training_loss': 0.6911699853474469,\n",
       "  'eval_loss': 0.6906763191024462,\n",
       "  'eval_f1': 0.46018471542608536,\n",
       "  'eval_mcc': 0.04393085064997223,\n",
       "  'eval_precision': 0.5291331625863688,\n",
       "  'eval_recall': 0.5165644194572556,\n",
       "  'eval_auc': 0.5349146155184753,\n",
       "  'eval_accuracy': 0.5204309670781894,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 30,\n",
       "  'training_loss': 0.6912154682551072,\n",
       "  'eval_loss': 0.6906771721939245,\n",
       "  'eval_f1': 0.4888636856285408,\n",
       "  'eval_mcc': 0.04261362083991008,\n",
       "  'eval_precision': 0.5244900673077725,\n",
       "  'eval_recall': 0.5185385350379262,\n",
       "  'eval_auc': 0.5343566549960178,\n",
       "  'eval_accuracy': 0.5214466563786009,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 31,\n",
       "  'training_loss': 0.6910828777919512,\n",
       "  'eval_loss': 0.6906651395062605,\n",
       "  'eval_f1': 0.5156003951906775,\n",
       "  'eval_mcc': 0.0447849456070241,\n",
       "  'eval_precision': 0.5230504542057509,\n",
       "  'eval_recall': 0.5217535355002215,\n",
       "  'eval_auc': 0.5339731412024668,\n",
       "  'eval_accuracy': 0.5231649691358026,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 32,\n",
       "  'training_loss': 0.691149794032015,\n",
       "  'eval_loss': 0.6906358959774176,\n",
       "  'eval_f1': 0.47825382438725744,\n",
       "  'eval_mcc': 0.04186380051983024,\n",
       "  'eval_precision': 0.5252285695235136,\n",
       "  'eval_recall': 0.5173684746812514,\n",
       "  'eval_auc': 0.5345173883026476,\n",
       "  'eval_accuracy': 0.5206593106995886,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 33,\n",
       "  'training_loss': 0.6912889119643899,\n",
       "  'eval_loss': 0.6908433002730211,\n",
       "  'eval_f1': 0.4528312723262334,\n",
       "  'eval_mcc': 0.04084971392880422,\n",
       "  'eval_precision': 0.5279644075481739,\n",
       "  'eval_recall': 0.5149206357619448,\n",
       "  'eval_auc': 0.5334862347478678,\n",
       "  'eval_accuracy': 0.5189336934156379,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 34,\n",
       "  'training_loss': 0.6911012894039641,\n",
       "  'eval_loss': 0.6906555195649465,\n",
       "  'eval_f1': 0.5049860548300547,\n",
       "  'eval_mcc': 0.04277132005175479,\n",
       "  'eval_precision': 0.5229147084609879,\n",
       "  'eval_recall': 0.5199590953765683,\n",
       "  'eval_auc': 0.5351575796843865,\n",
       "  'eval_accuracy': 0.5220850308641974,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 35,\n",
       "  'training_loss': 0.6911603324374578,\n",
       "  'eval_loss': 0.6906092539429665,\n",
       "  'eval_f1': 0.45689604429002717,\n",
       "  'eval_mcc': 0.0429263382417547,\n",
       "  'eval_precision': 0.5289040004415771,\n",
       "  'eval_recall': 0.5159410569650438,\n",
       "  'eval_auc': 0.5346914770898642,\n",
       "  'eval_accuracy': 0.5198775720164609,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 36,\n",
       "  'training_loss': 0.6910602505688325,\n",
       "  'eval_loss': 0.6907213541368643,\n",
       "  'eval_f1': 0.45501034133224083,\n",
       "  'eval_mcc': 0.043023366753387755,\n",
       "  'eval_precision': 0.5292531252532177,\n",
       "  'eval_recall': 0.5158215367661255,\n",
       "  'eval_auc': 0.5344235769408986,\n",
       "  'eval_accuracy': 0.5198123456790125,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 37,\n",
       "  'training_loss': 0.6911399226177596,\n",
       "  'eval_loss': 0.6905825200180212,\n",
       "  'eval_f1': 0.5142079079639942,\n",
       "  'eval_mcc': 0.04386004910085713,\n",
       "  'eval_precision': 0.522661932020183,\n",
       "  'eval_recall': 0.5212220427953467,\n",
       "  'eval_auc': 0.5348098706326804,\n",
       "  'eval_accuracy': 0.5227172325102881,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 38,\n",
       "  'training_loss': 0.6911865944375571,\n",
       "  'eval_loss': 0.6906651755174001,\n",
       "  'eval_f1': 0.468987584953699,\n",
       "  'eval_mcc': 0.041998964636989926,\n",
       "  'eval_precision': 0.5264907031599383,\n",
       "  'eval_recall': 0.5166482232249966,\n",
       "  'eval_auc': 0.5339465485793718,\n",
       "  'eval_accuracy': 0.5202338991769548,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 39,\n",
       "  'training_loss': 0.6910806038263503,\n",
       "  'eval_loss': 0.6905577518045902,\n",
       "  'eval_f1': 0.4874189393201797,\n",
       "  'eval_mcc': 0.044880439391480086,\n",
       "  'eval_precision': 0.5260826526337006,\n",
       "  'eval_recall': 0.5193079684150442,\n",
       "  'eval_auc': 0.5349014909645752,\n",
       "  'eval_accuracy': 0.5223113683127573,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 40,\n",
       "  'training_loss': 0.690998005203194,\n",
       "  'eval_loss': 0.690506212413311,\n",
       "  'eval_f1': 0.518742194096162,\n",
       "  'eval_mcc': 0.047069009098105775,\n",
       "  'eval_precision': 0.5240242889680812,\n",
       "  'eval_recall': 0.5230549224488271,\n",
       "  'eval_auc': 0.5355001876168479,\n",
       "  'eval_accuracy': 0.5242510288065841,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 41,\n",
       "  'training_loss': 0.6910045662778159,\n",
       "  'eval_loss': 0.6906475971142451,\n",
       "  'eval_f1': 0.4454055200330654,\n",
       "  'eval_mcc': 0.04412816692233687,\n",
       "  'eval_precision': 0.5318020336825174,\n",
       "  'eval_recall': 0.5153111680239888,\n",
       "  'eval_auc': 0.5344593770522302,\n",
       "  'eval_accuracy': 0.5195456275720163,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 42,\n",
       "  'training_loss': 0.6911305639970606,\n",
       "  'eval_loss': 0.6906375127534071,\n",
       "  'eval_f1': 0.4629168239525383,\n",
       "  'eval_mcc': 0.04266355390680825,\n",
       "  'eval_precision': 0.527797635335249,\n",
       "  'eval_recall': 0.5163718902676279,\n",
       "  'eval_auc': 0.5337863079440544,\n",
       "  'eval_accuracy': 0.5201444444444445,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 43,\n",
       "  'training_loss': 0.6910774032920253,\n",
       "  'eval_loss': 0.6904602162539959,\n",
       "  'eval_f1': 0.5040023955623828,\n",
       "  'eval_mcc': 0.04175207710880346,\n",
       "  'eval_precision': 0.522424085633706,\n",
       "  'eval_recall': 0.5194353923405558,\n",
       "  'eval_auc': 0.5347003355666393,\n",
       "  'eval_accuracy': 0.5215834876543209,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 44,\n",
       "  'training_loss': 0.6909881707133937,\n",
       "  'eval_loss': 0.6906132027506828,\n",
       "  'eval_f1': 0.5006644760378682,\n",
       "  'eval_mcc': 0.04338049480433002,\n",
       "  'eval_precision': 0.5236999983822386,\n",
       "  'eval_recall': 0.5198517187255702,\n",
       "  'eval_auc': 0.5338275790852715,\n",
       "  'eval_accuracy': 0.5222267489711935,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 45,\n",
       "  'training_loss': 0.6911179251847853,\n",
       "  'eval_loss': 0.6905157615741094,\n",
       "  'eval_f1': 0.5138272362253667,\n",
       "  'eval_mcc': 0.04308504836345067,\n",
       "  'eval_precision': 0.5222592458915322,\n",
       "  'eval_recall': 0.5208491880648736,\n",
       "  'eval_auc': 0.5333085103262055,\n",
       "  'eval_accuracy': 0.5223515946502059,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 46,\n",
       "  'training_loss': 0.6910031964773369,\n",
       "  'eval_loss': 0.6903968354066213,\n",
       "  'eval_f1': 0.5106107731980084,\n",
       "  'eval_mcc': 0.04225011126067369,\n",
       "  'eval_precision': 0.5220867160091344,\n",
       "  'eval_recall': 0.5202056446973539,\n",
       "  'eval_auc': 0.5339186585596727,\n",
       "  'eval_accuracy': 0.5219390946502057,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 47,\n",
       "  'training_loss': 0.6910054626984828,\n",
       "  'eval_loss': 0.6903908451398214,\n",
       "  'eval_f1': 0.5207803812769722,\n",
       "  'eval_mcc': 0.04512015905266944,\n",
       "  'eval_precision': 0.522744737255494,\n",
       "  'eval_recall': 0.5223769903377832,\n",
       "  'eval_auc': 0.5347810150538955,\n",
       "  'eval_accuracy': 0.523149794238683,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 48,\n",
       "  'training_loss': 0.6911202179583485,\n",
       "  'eval_loss': 0.6907300688326359,\n",
       "  'eval_f1': 0.44268897300607873,\n",
       "  'eval_mcc': 0.04251756754877902,\n",
       "  'eval_precision': 0.531008818145997,\n",
       "  'eval_recall': 0.5145774920458617,\n",
       "  'eval_auc': 0.5343399536346353,\n",
       "  'eval_accuracy': 0.5188626028806584,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 49,\n",
       "  'training_loss': 0.6910587980686373,\n",
       "  'eval_loss': 0.6904727679987749,\n",
       "  'eval_f1': 0.5137287633781782,\n",
       "  'eval_mcc': 0.04461309792553978,\n",
       "  'eval_precision': 0.5231289554071752,\n",
       "  'eval_recall': 0.5215137197521694,\n",
       "  'eval_auc': 0.5351102083805789,\n",
       "  'eval_accuracy': 0.5230817386831277,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 50,\n",
       "  'training_loss': 0.6909783158943991,\n",
       "  'eval_loss': 0.6903905558089415,\n",
       "  'eval_f1': 0.5162566834420598,\n",
       "  'eval_mcc': 0.043934236445890285,\n",
       "  'eval_precision': 0.5225104227307265,\n",
       "  'eval_recall': 0.5214372128786854,\n",
       "  'eval_auc': 0.5350598925969173,\n",
       "  'eval_accuracy': 0.5227370370370369,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 51,\n",
       "  'training_loss': 0.6909826696610506,\n",
       "  'eval_loss': 0.6904682219028473,\n",
       "  'eval_f1': 0.4642656361293234,\n",
       "  'eval_mcc': 0.04456676629459367,\n",
       "  'eval_precision': 0.528928682961927,\n",
       "  'eval_recall': 0.5171672538957109,\n",
       "  'eval_auc': 0.5349516697915265,\n",
       "  'eval_accuracy': 0.5209257716049384,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 52,\n",
       "  'training_loss': 0.6910128626635346,\n",
       "  'eval_loss': 0.6905806673069795,\n",
       "  'eval_f1': 0.5128502681890184,\n",
       "  'eval_mcc': 0.04358275095241871,\n",
       "  'eval_precision': 0.5226241180297676,\n",
       "  'eval_recall': 0.520989564867604,\n",
       "  'eval_auc': 0.5339519268806714,\n",
       "  'eval_accuracy': 0.5225863168724278,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 53,\n",
       "  'training_loss': 0.6909572036802907,\n",
       "  'eval_loss': 0.6905462568004926,\n",
       "  'eval_f1': 0.5190579321453039,\n",
       "  'eval_mcc': 0.04362132104418146,\n",
       "  'eval_precision': 0.5220785965001453,\n",
       "  'eval_recall': 0.5215460748865434,\n",
       "  'eval_auc': 0.5333765576885889,\n",
       "  'eval_accuracy': 0.5224791666666667,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 54,\n",
       "  'training_loss': 0.690925096414482,\n",
       "  'eval_loss': 0.6906892682115237,\n",
       "  'eval_f1': 0.4767423176022077,\n",
       "  'eval_mcc': 0.04509037275901562,\n",
       "  'eval_precision': 0.5275557531433531,\n",
       "  'eval_recall': 0.5184469679368046,\n",
       "  'eval_auc': 0.5337776352696141,\n",
       "  'eval_accuracy': 0.521836368312757,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 55,\n",
       "  'training_loss': 0.6910625621503578,\n",
       "  'eval_loss': 0.6904325932264328,\n",
       "  'eval_f1': 0.46978358289490957,\n",
       "  'eval_mcc': 0.04374917297734032,\n",
       "  'eval_precision': 0.5275932993153711,\n",
       "  'eval_recall': 0.5173435083216711,\n",
       "  'eval_auc': 0.5356195795201083,\n",
       "  'eval_accuracy': 0.5209349794238683,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 56,\n",
       "  'training_loss': 0.690952018352783,\n",
       "  'eval_loss': 0.6906627913316091,\n",
       "  'eval_f1': 0.5125169184137606,\n",
       "  'eval_mcc': 0.043161054963924646,\n",
       "  'eval_precision': 0.5224258312686352,\n",
       "  'eval_recall': 0.5207674076562402,\n",
       "  'eval_auc': 0.5337182371396433,\n",
       "  'eval_accuracy': 0.5223843621399177,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 57,\n",
       "  'training_loss': 0.6910276316158179,\n",
       "  'eval_loss': 0.690689733872811,\n",
       "  'eval_f1': 0.4354110245106284,\n",
       "  'eval_mcc': 0.04320257676104893,\n",
       "  'eval_precision': 0.5330184219871587,\n",
       "  'eval_recall': 0.514135633196673,\n",
       "  'eval_auc': 0.5349763081174284,\n",
       "  'eval_accuracy': 0.5185842078189301,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 58,\n",
       "  'training_loss': 0.6909462290960785,\n",
       "  'eval_loss': 0.690609031667312,\n",
       "  'eval_f1': 0.45925130434000466,\n",
       "  'eval_mcc': 0.04650761095408803,\n",
       "  'eval_precision': 0.5311399420031083,\n",
       "  'eval_recall': 0.5173675500889217,\n",
       "  'eval_auc': 0.5342248561211246,\n",
       "  'eval_accuracy': 0.5212836934156378,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 59,\n",
       "  'training_loss': 0.6909454375021419,\n",
       "  'eval_loss': 0.6905020537475745,\n",
       "  'eval_f1': 0.4768221046833083,\n",
       "  'eval_mcc': 0.04699577089990211,\n",
       "  'eval_precision': 0.5288354177457476,\n",
       "  'eval_recall': 0.5191502151164319,\n",
       "  'eval_auc': 0.5356735466816905,\n",
       "  'eval_accuracy': 0.5225639917695475,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 60,\n",
       "  'training_loss': 0.6909395044198445,\n",
       "  'eval_loss': 0.6906456537544727,\n",
       "  'eval_f1': 0.498708319466139,\n",
       "  'eval_mcc': 0.0441503346964937,\n",
       "  'eval_precision': 0.5243730029417789,\n",
       "  'eval_recall': 0.5199948428545789,\n",
       "  'eval_auc': 0.5347658058616774,\n",
       "  'eval_accuracy': 0.5224973251028805,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 61,\n",
       "  'training_loss': 0.6908944950302903,\n",
       "  'eval_loss': 0.6905582013229529,\n",
       "  'eval_f1': 0.5209920738991268,\n",
       "  'eval_mcc': 0.045630740341779275,\n",
       "  'eval_precision': 0.5230060105598469,\n",
       "  'eval_recall': 0.5226263874723359,\n",
       "  'eval_auc': 0.535019547921898,\n",
       "  'eval_accuracy': 0.5233926954732511,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 62,\n",
       "  'training_loss': 0.6909040059125063,\n",
       "  'eval_loss': 0.6904270723462105,\n",
       "  'eval_f1': 0.5147916578172879,\n",
       "  'eval_mcc': 0.04448412260417189,\n",
       "  'eval_precision': 0.52295423749554,\n",
       "  'eval_recall': 0.5215522502554608,\n",
       "  'eval_auc': 0.5349816423623465,\n",
       "  'eval_accuracy': 0.5230186728395062,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 63,\n",
       "  'training_loss': 0.6909607834163232,\n",
       "  'eval_loss': 0.6903953837851683,\n",
       "  'eval_f1': 0.5007584794604016,\n",
       "  'eval_mcc': 0.04629273825327109,\n",
       "  'eval_precision': 0.5254404523630974,\n",
       "  'eval_recall': 0.521059866444588,\n",
       "  'eval_auc': 0.5355693098180466,\n",
       "  'eval_accuracy': 0.5235133230452675,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 64,\n",
       "  'training_loss': 0.6908997792378933,\n",
       "  'eval_loss': 0.6907666561504205,\n",
       "  'eval_f1': 0.5130608712924564,\n",
       "  'eval_mcc': 0.045416613980715566,\n",
       "  'eval_precision': 0.5236539978507442,\n",
       "  'eval_recall': 0.521800760268037,\n",
       "  'eval_auc': 0.5341860519913911,\n",
       "  'eval_accuracy': 0.5234643518518519,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 65,\n",
       "  'training_loss': 0.6908159746924575,\n",
       "  'eval_loss': 0.6903407437105974,\n",
       "  'eval_f1': 0.5120310239244642,\n",
       "  'eval_mcc': 0.0447206730253632,\n",
       "  'eval_precision': 0.5233544894461966,\n",
       "  'eval_recall': 0.5214088173502253,\n",
       "  'eval_auc': 0.5348870428502058,\n",
       "  'eval_accuracy': 0.5231216049382718,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 66,\n",
       "  'training_loss': 0.6908624412841974,\n",
       "  'eval_loss': 0.6907678705950578,\n",
       "  'eval_f1': 0.47783113175257247,\n",
       "  'eval_mcc': 0.04336260604349692,\n",
       "  'eval_precision': 0.5262659443669614,\n",
       "  'eval_recall': 0.5178994405752122,\n",
       "  'eval_auc': 0.5345064720476977,\n",
       "  'eval_accuracy': 0.5212310185185185,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 67,\n",
       "  'training_loss': 0.6908759415287983,\n",
       "  'eval_loss': 0.6905465051531792,\n",
       "  'eval_f1': 0.5187324714428037,\n",
       "  'eval_mcc': 0.043432601881380574,\n",
       "  'eval_precision': 0.5220052854279478,\n",
       "  'eval_recall': 0.5214312064519154,\n",
       "  'eval_auc': 0.5339296770301588,\n",
       "  'eval_accuracy': 0.5223912551440328,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 68,\n",
       "  'training_loss': 0.6909824933364054,\n",
       "  'eval_loss': 0.6904331209758917,\n",
       "  'eval_f1': 0.517418088963498,\n",
       "  'eval_mcc': 0.045160553390564157,\n",
       "  'eval_precision': 0.5230851114744669,\n",
       "  'eval_recall': 0.5220866600024507,\n",
       "  'eval_auc': 0.5350303809476333,\n",
       "  'eval_accuracy': 0.5233319444444444,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 69,\n",
       "  'training_loss': 0.690888879608942,\n",
       "  'eval_loss': 0.6906701860328516,\n",
       "  'eval_f1': 0.4969733778158824,\n",
       "  'eval_mcc': 0.044163513926503535,\n",
       "  'eval_precision': 0.5245622439030058,\n",
       "  'eval_recall': 0.5198527919824171,\n",
       "  'eval_auc': 0.5336864192072314,\n",
       "  'eval_accuracy': 0.5224407407407407,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 70,\n",
       "  'training_loss': 0.6909933138612805,\n",
       "  'eval_loss': 0.6906337179243565,\n",
       "  'eval_f1': 0.5065283065751317,\n",
       "  'eval_mcc': 0.04279173728077099,\n",
       "  'eval_precision': 0.5227795917804637,\n",
       "  'eval_recall': 0.5200967775746996,\n",
       "  'eval_auc': 0.5337018077295049,\n",
       "  'eval_accuracy': 0.5221305041152264,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 71,\n",
       "  'training_loss': 0.6908499866793161,\n",
       "  'eval_loss': 0.6903360486030579,\n",
       "  'eval_f1': 0.5121126629728957,\n",
       "  'eval_mcc': 0.0443016899514688,\n",
       "  'eval_precision': 0.5231039090588909,\n",
       "  'eval_recall': 0.521237468846543,\n",
       "  'eval_auc': 0.535267626795959,\n",
       "  'eval_accuracy': 0.5229268518518518,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 72,\n",
       "  'training_loss': 0.6908328443281612,\n",
       "  'eval_loss': 0.6903208692868551,\n",
       "  'eval_f1': 0.5164369870352934,\n",
       "  'eval_mcc': 0.043839870383228,\n",
       "  'eval_precision': 0.522439349718015,\n",
       "  'eval_recall': 0.5214127316861945,\n",
       "  'eval_auc': 0.5353922960987804,\n",
       "  'eval_accuracy': 0.5226756172839506,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 73,\n",
       "  'training_loss': 0.6908011743474726,\n",
       "  'eval_loss': 0.6904530661801497,\n",
       "  'eval_f1': 0.4844557090493631,\n",
       "  'eval_mcc': 0.04425055173009216,\n",
       "  'eval_precision': 0.5260462130859013,\n",
       "  'eval_recall': 0.5187961630402212,\n",
       "  'eval_auc': 0.5358720723004249,\n",
       "  'eval_accuracy': 0.521902057613169,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 74,\n",
       "  'training_loss': 0.6908530379945883,\n",
       "  'eval_loss': 0.6903386376798153,\n",
       "  'eval_f1': 0.5198862835792325,\n",
       "  'eval_mcc': 0.04560651990134149,\n",
       "  'eval_precision': 0.5230985097797188,\n",
       "  'eval_recall': 0.522511862166288,\n",
       "  'eval_auc': 0.5353655790577149,\n",
       "  'eval_accuracy': 0.5234598251028806,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 75,\n",
       "  'training_loss': 0.6908458674590162,\n",
       "  'eval_loss': 0.6903583121796449,\n",
       "  'eval_f1': 0.512708224716542,\n",
       "  'eval_mcc': 0.04668978300441493,\n",
       "  'eval_precision': 0.5244163830310818,\n",
       "  'eval_recall': 0.5223207831092652,\n",
       "  'eval_auc': 0.5359296574571889,\n",
       "  'eval_accuracy': 0.5240564300411523,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 76,\n",
       "  'training_loss': 0.6908717744588299,\n",
       "  'eval_loss': 0.6906370868285497,\n",
       "  'eval_f1': 0.4883095009142813,\n",
       "  'eval_mcc': 0.04524079255815155,\n",
       "  'eval_precision': 0.5262151410142875,\n",
       "  'eval_recall': 0.519519929152421,\n",
       "  'eval_auc': 0.5354402599927314,\n",
       "  'eval_accuracy': 0.5224970164609054,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 77,\n",
       "  'training_loss': 0.690815444750465,\n",
       "  'eval_loss': 0.6904451586306095,\n",
       "  'eval_f1': 0.5065612186864321,\n",
       "  'eval_mcc': 0.04447189988854689,\n",
       "  'eval_precision': 0.5237501592863253,\n",
       "  'eval_recall': 0.5208189375658244,\n",
       "  'eval_auc': 0.534610797067952,\n",
       "  'eval_accuracy': 0.5228949588477367,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 78,\n",
       "  'training_loss': 0.6908623011925381,\n",
       "  'eval_loss': 0.690516841908296,\n",
       "  'eval_f1': 0.5076082530542078,\n",
       "  'eval_mcc': 0.04360416494489782,\n",
       "  'eval_precision': 0.5231437765306883,\n",
       "  'eval_recall': 0.5205387390475379,\n",
       "  'eval_auc': 0.535033427259337,\n",
       "  'eval_accuracy': 0.5225203703703705,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 79,\n",
       "  'training_loss': 0.6908242927903089,\n",
       "  'eval_loss': 0.6904332066575686,\n",
       "  'eval_f1': 0.49351165010411674,\n",
       "  'eval_mcc': 0.04452389938363482,\n",
       "  'eval_precision': 0.5251553012446838,\n",
       "  'eval_recall': 0.519702255062969,\n",
       "  'eval_auc': 0.5343938166008019,\n",
       "  'eval_accuracy': 0.5224534465020575,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 80,\n",
       "  'training_loss': 0.6908061151714723,\n",
       "  'eval_loss': 0.6905737891793251,\n",
       "  'eval_f1': 0.48607927010201674,\n",
       "  'eval_mcc': 0.045194530471152815,\n",
       "  'eval_precision': 0.5264333838869676,\n",
       "  'eval_recall': 0.5193190728465868,\n",
       "  'eval_auc': 0.533907387331223,\n",
       "  'eval_accuracy': 0.5223804012345679,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 81,\n",
       "  'training_loss': 0.6907729671062284,\n",
       "  'eval_loss': 0.6905314363539219,\n",
       "  'eval_f1': 0.5142059921427037,\n",
       "  'eval_mcc': 0.04272999973100495,\n",
       "  'eval_precision': 0.5220268251423005,\n",
       "  'eval_recall': 0.5207233204715886,\n",
       "  'eval_auc': 0.5351807886315195,\n",
       "  'eval_accuracy': 0.5221626028806586,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 82,\n",
       "  'training_loss': 0.690837227136519,\n",
       "  'eval_loss': 0.6905870325863361,\n",
       "  'eval_f1': 0.522105934578623,\n",
       "  'eval_mcc': 0.0442774293821421,\n",
       "  'eval_precision': 0.5221407447687441,\n",
       "  'eval_recall': 0.522136686344001,\n",
       "  'eval_auc': 0.5345422945018514,\n",
       "  'eval_accuracy': 0.522255195473251,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 83,\n",
       "  'training_loss': 0.6907567040273043,\n",
       "  'eval_loss': 0.6905454633136591,\n",
       "  'eval_f1': 0.5120175015158882,\n",
       "  'eval_mcc': 0.04473665322118279,\n",
       "  'eval_precision': 0.523366731244321,\n",
       "  'eval_recall': 0.5214130192459813,\n",
       "  'eval_auc': 0.5342856638369334,\n",
       "  'eval_accuracy': 0.5231262860082305,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 84,\n",
       "  'training_loss': 0.6907912946355869,\n",
       "  'eval_loss': 0.6904970606168112,\n",
       "  'eval_f1': 0.5220060382584176,\n",
       "  'eval_mcc': 0.04630229870275263,\n",
       "  'eval_precision': 0.5232756889132689,\n",
       "  'eval_recall': 0.5230273224801031,\n",
       "  'eval_auc': 0.5345087216486465,\n",
       "  'eval_accuracy': 0.5236480967078189,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 85,\n",
       "  'training_loss': 0.6907335754890176,\n",
       "  'eval_loss': 0.6903550152977308,\n",
       "  'eval_f1': 0.5102298228146647,\n",
       "  'eval_mcc': 0.04436872584288007,\n",
       "  'eval_precision': 0.5233289275606658,\n",
       "  'eval_recall': 0.5210963656303665,\n",
       "  'eval_auc': 0.5356067250510984,\n",
       "  'eval_accuracy': 0.5229251028806584,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 86,\n",
       "  'training_loss': 0.6907475380499236,\n",
       "  'eval_loss': 0.6904147466023763,\n",
       "  'eval_f1': 0.5130535957644461,\n",
       "  'eval_mcc': 0.04456753548487166,\n",
       "  'eval_precision': 0.52317119923829,\n",
       "  'eval_recall': 0.5214306177902942,\n",
       "  'eval_auc': 0.534739792173022,\n",
       "  'eval_accuracy': 0.5230574588477366,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 87,\n",
       "  'training_loss': 0.6907115420996451,\n",
       "  'eval_loss': 0.6905043857793013,\n",
       "  'eval_f1': 0.5100605997520717,\n",
       "  'eval_mcc': 0.0453615835667931,\n",
       "  'eval_precision': 0.5239166964518703,\n",
       "  'eval_recall': 0.5215091232180431,\n",
       "  'eval_auc': 0.5352263356930428,\n",
       "  'eval_accuracy': 0.5233787551440331,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 88,\n",
       "  'training_loss': 0.6907361696048568,\n",
       "  'eval_loss': 0.6904868707060814,\n",
       "  'eval_f1': 0.46508074750965767,\n",
       "  'eval_mcc': 0.04539206454465644,\n",
       "  'eval_precision': 0.5294049643585631,\n",
       "  'eval_recall': 0.5175204627452719,\n",
       "  'eval_auc': 0.5355578235507282,\n",
       "  'eval_accuracy': 0.5212655864197531,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 89,\n",
       "  'training_loss': 0.6907581934519544,\n",
       "  'eval_loss': 0.6902883487443129,\n",
       "  'eval_f1': 0.5196155681480553,\n",
       "  'eval_mcc': 0.04615084844226038,\n",
       "  'eval_precision': 0.5234276279910479,\n",
       "  'eval_recall': 0.5227286436824593,\n",
       "  'eval_auc': 0.5358764141271143,\n",
       "  'eval_accuracy': 0.5237461419753088,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 90,\n",
       "  'training_loss': 0.6907680426009016,\n",
       "  'eval_loss': 0.6901327235003313,\n",
       "  'eval_f1': 0.5190149125971194,\n",
       "  'eval_mcc': 0.0458101362579886,\n",
       "  'eval_precision': 0.5232956860717415,\n",
       "  'eval_recall': 0.5225211622732674,\n",
       "  'eval_auc': 0.5364245406540576,\n",
       "  'eval_accuracy': 0.523603755144033,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 91,\n",
       "  'training_loss': 0.6906568766193434,\n",
       "  'eval_loss': 0.6902439321080843,\n",
       "  'eval_f1': 0.4861789914419144,\n",
       "  'eval_mcc': 0.04479764041091503,\n",
       "  'eval_precision': 0.5261893585325083,\n",
       "  'eval_recall': 0.519158257388202,\n",
       "  'eval_auc': 0.5360421662047297,\n",
       "  'eval_accuracy': 0.5222062242798352,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 92,\n",
       "  'training_loss': 0.6906256457215949,\n",
       "  'eval_loss': 0.6902099711199602,\n",
       "  'eval_f1': 0.5084561116545894,\n",
       "  'eval_mcc': 0.04536728205915406,\n",
       "  'eval_precision': 0.524081179109921,\n",
       "  'eval_recall': 0.5213677059441195,\n",
       "  'eval_auc': 0.5357435622391905,\n",
       "  'eval_accuracy': 0.5233432613168724,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 93,\n",
       "  'training_loss': 0.6906930466815656,\n",
       "  'eval_loss': 0.6902526306609312,\n",
       "  'eval_f1': 0.4901649648876086,\n",
       "  'eval_mcc': 0.04500675364423481,\n",
       "  'eval_precision': 0.5258355699900518,\n",
       "  'eval_recall': 0.5196023623769482,\n",
       "  'eval_auc': 0.5364104418122706,\n",
       "  'eval_accuracy': 0.5224973765432098,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 94,\n",
       "  'training_loss': 0.6906346255554677,\n",
       "  'eval_loss': 0.6904465444386005,\n",
       "  'eval_f1': 0.5113379529733985,\n",
       "  'eval_mcc': 0.045662627720383035,\n",
       "  'eval_precision': 0.5239656461814789,\n",
       "  'eval_recall': 0.5217509821809617,\n",
       "  'eval_auc': 0.5356453659975463,\n",
       "  'eval_accuracy': 0.5235534979423869,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 95,\n",
       "  'training_loss': 0.6906029381497554,\n",
       "  'eval_loss': 0.6902438079317411,\n",
       "  'eval_f1': 0.507652568917053,\n",
       "  'eval_mcc': 0.04487700390202495,\n",
       "  'eval_precision': 0.5238791466529791,\n",
       "  'eval_recall': 0.521085347890219,\n",
       "  'eval_auc': 0.5353172691560583,\n",
       "  'eval_accuracy': 0.5231069958847735,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 96,\n",
       "  'training_loss': 0.690668929757209,\n",
       "  'eval_loss': 0.6904666225115458,\n",
       "  'eval_f1': 0.46574502735162354,\n",
       "  'eval_mcc': 0.0453885225582284,\n",
       "  'eval_precision': 0.5293264623605703,\n",
       "  'eval_recall': 0.5175647498337156,\n",
       "  'eval_auc': 0.5357713614256537,\n",
       "  'eval_accuracy': 0.5212929526748968,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 97,\n",
       "  'training_loss': 0.6906923597760654,\n",
       "  'eval_loss': 0.6902539556225141,\n",
       "  'eval_f1': 0.500682147230877,\n",
       "  'eval_mcc': 0.042987758555848125,\n",
       "  'eval_precision': 0.5234775310227938,\n",
       "  'eval_recall': 0.5196788217692067,\n",
       "  'eval_auc': 0.5352592666408998,\n",
       "  'eval_accuracy': 0.522041512345679,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 98,\n",
       "  'training_loss': 0.6906113899777494,\n",
       "  'eval_loss': 0.6902919361988703,\n",
       "  'eval_f1': 0.4823509866977172,\n",
       "  'eval_mcc': 0.044099375086207565,\n",
       "  'eval_precision': 0.5261982411386963,\n",
       "  'eval_recall': 0.5185597301249106,\n",
       "  'eval_auc': 0.5352780601772863,\n",
       "  'eval_accuracy': 0.5217434670781894,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 99,\n",
       "  'training_loss': 0.6906544487326991,\n",
       "  'eval_loss': 0.6903775619963805,\n",
       "  'eval_f1': 0.5070738471659098,\n",
       "  'eval_mcc': 0.04503804305338469,\n",
       "  'eval_precision': 0.524033360283393,\n",
       "  'eval_recall': 0.5211007839030587,\n",
       "  'eval_auc': 0.5351701709018929,\n",
       "  'eval_accuracy': 0.5231703703703703,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 100,\n",
       "  'training_loss': 0.6907166318661099,\n",
       "  'eval_loss': 0.6902521351973215,\n",
       "  'eval_f1': 0.5207701121708667,\n",
       "  'eval_mcc': 0.048202976311737956,\n",
       "  'eval_precision': 0.524455358379239,\n",
       "  'eval_recall': 0.5237528536954624,\n",
       "  'eval_auc': 0.5361312058866247,\n",
       "  'eval_accuracy': 0.5247619855967076,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 101,\n",
       "  'training_loss': 0.6906176704541713,\n",
       "  'eval_loss': 0.6904911336799463,\n",
       "  'eval_f1': 0.4926478067168532,\n",
       "  'eval_mcc': 0.04531103011027951,\n",
       "  'eval_precision': 0.525745353800618,\n",
       "  'eval_recall': 0.519937732740464,\n",
       "  'eval_auc': 0.5357916231716964,\n",
       "  'eval_accuracy': 0.5227395576131687,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 102,\n",
       "  'training_loss': 0.6906287256636918,\n",
       "  'eval_loss': 0.690484789510568,\n",
       "  'eval_f1': 0.4808721166031142,\n",
       "  'eval_mcc': 0.04424548760218627,\n",
       "  'eval_precision': 0.5264863563350995,\n",
       "  'eval_recall': 0.5184800842212288,\n",
       "  'eval_auc': 0.5361066974957895,\n",
       "  'eval_accuracy': 0.5217234053497942,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 103,\n",
       "  'training_loss': 0.6906246536015911,\n",
       "  'eval_loss': 0.6903970787922541,\n",
       "  'eval_f1': 0.49349455865894737,\n",
       "  'eval_mcc': 0.045017218499163104,\n",
       "  'eval_precision': 0.5254676858055783,\n",
       "  'eval_recall': 0.5198945523671438,\n",
       "  'eval_auc': 0.5359297982693091,\n",
       "  'eval_accuracy': 0.522661316872428,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 104,\n",
       "  'training_loss': 0.6906239205059486,\n",
       "  'eval_loss': 0.6902831445137659,\n",
       "  'eval_f1': 0.4978137550637993,\n",
       "  'eval_mcc': 0.04545357838640989,\n",
       "  'eval_precision': 0.5252548658763405,\n",
       "  'eval_recall': 0.5204527989987917,\n",
       "  'eval_auc': 0.5361928095020517,\n",
       "  'eval_accuracy': 0.5230331275720164,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 105,\n",
       "  'training_loss': 0.6905907511434533,\n",
       "  'eval_loss': 0.6903811072309812,\n",
       "  'eval_f1': 0.4815844033024861,\n",
       "  'eval_mcc': 0.04552911042422936,\n",
       "  'eval_precision': 0.5272141134871946,\n",
       "  'eval_recall': 0.5190445554632167,\n",
       "  'eval_auc': 0.5359770733352665,\n",
       "  'eval_accuracy': 0.5222809156378602,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 106,\n",
       "  'training_loss': 0.6906390740533992,\n",
       "  'eval_loss': 0.6904994659125805,\n",
       "  'eval_f1': 0.5015341946784364,\n",
       "  'eval_mcc': 0.04419970478614043,\n",
       "  'eval_precision': 0.524102332442317,\n",
       "  'eval_recall': 0.5202643983913174,\n",
       "  'eval_auc': 0.5347920341265816,\n",
       "  'eval_accuracy': 0.522616718106996,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 107,\n",
       "  'training_loss': 0.690623739341019,\n",
       "  'eval_loss': 0.6903569089869658,\n",
       "  'eval_f1': 0.4871108009783776,\n",
       "  'eval_mcc': 0.04672790062039675,\n",
       "  'eval_precision': 0.5273060267544062,\n",
       "  'eval_recall': 0.5199926278881594,\n",
       "  'eval_auc': 0.5364934823169191,\n",
       "  'eval_accuracy': 0.5230434670781893,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 108,\n",
       "  'training_loss': 0.6905380531696045,\n",
       "  'eval_loss': 0.6904355064034462,\n",
       "  'eval_f1': 0.5059018884338448,\n",
       "  'eval_mcc': 0.04573156436405196,\n",
       "  'eval_precision': 0.5245580074176998,\n",
       "  'eval_recall': 0.5212908144466694,\n",
       "  'eval_auc': 0.5356571117719924,\n",
       "  'eval_accuracy': 0.5234475823045267,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 109,\n",
       "  'training_loss': 0.690546613143381,\n",
       "  'eval_loss': 0.6905676623185476,\n",
       "  'eval_f1': 0.5078922202830931,\n",
       "  'eval_mcc': 0.045916247817651336,\n",
       "  'eval_precision': 0.5244565449412957,\n",
       "  'eval_recall': 0.5215520699086468,\n",
       "  'eval_auc': 0.5356250355640979,\n",
       "  'eval_accuracy': 0.5235901748971193,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 110,\n",
       "  'training_loss': 0.690620017024038,\n",
       "  'eval_loss': 0.6903442405164242,\n",
       "  'eval_f1': 0.5120755260627933,\n",
       "  'eval_mcc': 0.044359749328453824,\n",
       "  'eval_precision': 0.5231493836511968,\n",
       "  'eval_recall': 0.5212512928746853,\n",
       "  'eval_auc': 0.5349892246919933,\n",
       "  'eval_accuracy': 0.5229484053497943,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 111,\n",
       "  'training_loss': 0.690572417390872,\n",
       "  'eval_loss': 0.6904522875944773,\n",
       "  'eval_f1': 0.4867389963681517,\n",
       "  'eval_mcc': 0.04550636407856037,\n",
       "  'eval_precision': 0.5265560046132486,\n",
       "  'eval_recall': 0.5194965805497007,\n",
       "  'eval_auc': 0.5350793236589636,\n",
       "  'eval_accuracy': 0.522543158436214,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 112,\n",
       "  'training_loss': 0.6905951184629011,\n",
       "  'eval_loss': 0.6903044432401657,\n",
       "  'eval_f1': 0.5017908340100391,\n",
       "  'eval_mcc': 0.04449176957390311,\n",
       "  'eval_precision': 0.5242475268200709,\n",
       "  'eval_recall': 0.5204102848237631,\n",
       "  'eval_auc': 0.5356061013098118,\n",
       "  'eval_accuracy': 0.522760185185185,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 113,\n",
       "  'training_loss': 0.6905665986775799,\n",
       "  'eval_loss': 0.6902841478586197,\n",
       "  'eval_f1': 0.4926976533422795,\n",
       "  'eval_mcc': 0.047592659911779134,\n",
       "  'eval_precision': 0.5271598797166788,\n",
       "  'eval_recall': 0.5208504626657914,\n",
       "  'eval_auc': 0.5363772885548072,\n",
       "  'eval_accuracy': 0.5237000514403293,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 114,\n",
       "  'training_loss': 0.6905035657285261,\n",
       "  'eval_loss': 0.6903311150769392,\n",
       "  'eval_f1': 0.5115282640986913,\n",
       "  'eval_mcc': 0.04868592399623126,\n",
       "  'eval_precision': 0.5256907636783242,\n",
       "  'eval_recall': 0.5230663032087203,\n",
       "  'eval_auc': 0.5362090270280503,\n",
       "  'eval_accuracy': 0.5249547839506173,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 115,\n",
       "  'training_loss': 0.690504071192509,\n",
       "  'eval_loss': 0.6904240685204664,\n",
       "  'eval_f1': 0.49604218840388525,\n",
       "  'eval_mcc': 0.04625070471902906,\n",
       "  'eval_precision': 0.5259404258366156,\n",
       "  'eval_recall': 0.5206168215916763,\n",
       "  'eval_auc': 0.5357835715254629,\n",
       "  'eval_accuracy': 0.5232949074074075,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 116,\n",
       "  'training_loss': 0.6905651186569107,\n",
       "  'eval_loss': 0.6903616711497307,\n",
       "  'eval_f1': 0.4989564577895434,\n",
       "  'eval_mcc': 0.045934489289758046,\n",
       "  'eval_precision': 0.5254267382014346,\n",
       "  'eval_recall': 0.5207464434015625,\n",
       "  'eval_auc': 0.5360025640050977,\n",
       "  'eval_accuracy': 0.5232826131687242,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 117,\n",
       "  'training_loss': 0.6904840000544236,\n",
       "  'eval_loss': 0.6904312695066134,\n",
       "  'eval_f1': 0.4708437341664637,\n",
       "  'eval_mcc': 0.04782288648511717,\n",
       "  'eval_precision': 0.5302571456059048,\n",
       "  'eval_recall': 0.5188992057071627,\n",
       "  'eval_auc': 0.5367224331964267,\n",
       "  'eval_accuracy': 0.5225132716049382,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 118,\n",
       "  'training_loss': 0.6905412301939767,\n",
       "  'eval_loss': 0.690245204915603,\n",
       "  'eval_f1': 0.4887634707298684,\n",
       "  'eval_mcc': 0.046870004630328116,\n",
       "  'eval_precision': 0.5271801312111758,\n",
       "  'eval_recall': 0.5202077269045222,\n",
       "  'eval_auc': 0.5367487951549625,\n",
       "  'eval_accuracy': 0.5232066872427984,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:06'},\n",
       " {'epoch': 119,\n",
       "  'training_loss': 0.690497181255137,\n",
       "  'eval_loss': 0.6902843502660593,\n",
       "  'eval_f1': 0.49498518753060633,\n",
       "  'eval_mcc': 0.04795031529055533,\n",
       "  'eval_precision': 0.5271111055270031,\n",
       "  'eval_recall': 0.5212031665449762,\n",
       "  'eval_auc': 0.5365583900263603,\n",
       "  'eval_accuracy': 0.5239651748971194,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 120,\n",
       "  'training_loss': 0.6905525117905124,\n",
       "  'eval_loss': 0.6902438153823217,\n",
       "  'eval_f1': 0.4987364566739829,\n",
       "  'eval_mcc': 0.048228407621520475,\n",
       "  'eval_precision': 0.5268408916471953,\n",
       "  'eval_recall': 0.5216653793243098,\n",
       "  'eval_auc': 0.5366328586574446,\n",
       "  'eval_accuracy': 0.5242632201646091,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 121,\n",
       "  'training_loss': 0.6905070008092026,\n",
       "  'eval_loss': 0.6903750486671925,\n",
       "  'eval_f1': 0.5203371955627938,\n",
       "  'eval_mcc': 0.045026004025580095,\n",
       "  'eval_precision': 0.5227351204298968,\n",
       "  'eval_recall': 0.5222931418036173,\n",
       "  'eval_auc': 0.5361314143391472,\n",
       "  'eval_accuracy': 0.5231250000000001,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 122,\n",
       "  'training_loss': 0.6905151813046838,\n",
       "  'eval_loss': 0.6903343784312407,\n",
       "  'eval_f1': 0.4968926371022913,\n",
       "  'eval_mcc': 0.04733833056331318,\n",
       "  'eval_precision': 0.5265184577151119,\n",
       "  'eval_recall': 0.5211269327069105,\n",
       "  'eval_auc': 0.5362615065592922,\n",
       "  'eval_accuracy': 0.5237819444444445,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 123,\n",
       "  'training_loss': 0.6905303425965895,\n",
       "  'eval_loss': 0.6902105212211609,\n",
       "  'eval_f1': 0.5049942698898663,\n",
       "  'eval_mcc': 0.04807723383607678,\n",
       "  'eval_precision': 0.526039167598849,\n",
       "  'eval_recall': 0.5221922095882363,\n",
       "  'eval_auc': 0.5364351336973344,\n",
       "  'eval_accuracy': 0.5244642489711934,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 124,\n",
       "  'training_loss': 0.6905349215056116,\n",
       "  'eval_loss': 0.6904285562535127,\n",
       "  'eval_f1': 0.484849868601652,\n",
       "  'eval_mcc': 0.044728264881228684,\n",
       "  'eval_precision': 0.5262981185617239,\n",
       "  'eval_recall': 0.5190202140082502,\n",
       "  'eval_auc': 0.5350373254424466,\n",
       "  'eval_accuracy': 0.5221191872427985,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 125,\n",
       "  'training_loss': 0.6905874233787962,\n",
       "  'eval_loss': 0.6904175529877344,\n",
       "  'eval_f1': 0.5005176702614434,\n",
       "  'eval_mcc': 0.04537317875744773,\n",
       "  'eval_precision': 0.5249145918236447,\n",
       "  'eval_recall': 0.5206585035676605,\n",
       "  'eval_auc': 0.534609268151513,\n",
       "  'eval_accuracy': 0.5230902777777778,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 126,\n",
       "  'training_loss': 0.6905524216229291,\n",
       "  'eval_loss': 0.6904571652412415,\n",
       "  'eval_f1': 0.49386231920463547,\n",
       "  'eval_mcc': 0.04532571243655259,\n",
       "  'eval_precision': 0.5256197499060805,\n",
       "  'eval_recall': 0.5200482209173719,\n",
       "  'eval_auc': 0.5355043818381334,\n",
       "  'eval_accuracy': 0.5227973251028807,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 127,\n",
       "  'training_loss': 0.690540185522314,\n",
       "  'eval_loss': 0.6902112637956938,\n",
       "  'eval_f1': 0.49944014166553613,\n",
       "  'eval_mcc': 0.04578345208966947,\n",
       "  'eval_precision': 0.5252702926994525,\n",
       "  'eval_recall': 0.5207378107863739,\n",
       "  'eval_auc': 0.5357671214346508,\n",
       "  'eval_accuracy': 0.5232385802469137,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 128,\n",
       "  'training_loss': 0.6904767805628323,\n",
       "  'eval_loss': 0.6901630361874899,\n",
       "  'eval_f1': 0.5123266482911436,\n",
       "  'eval_mcc': 0.04736722055477564,\n",
       "  'eval_precision': 0.524844822929806,\n",
       "  'eval_recall': 0.5225770311760624,\n",
       "  'eval_auc': 0.5363725319591487,\n",
       "  'eval_accuracy': 0.5243614197530864,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 129,\n",
       "  'training_loss': 0.690517146875023,\n",
       "  'eval_loss': 0.6903523951768875,\n",
       "  'eval_f1': 0.5139455147436857,\n",
       "  'eval_mcc': 0.046244104914875454,\n",
       "  'eval_precision': 0.524036201878862,\n",
       "  'eval_recall': 0.5222430049259322,\n",
       "  'eval_auc': 0.5353108879556062,\n",
       "  'eval_accuracy': 0.5238388374485599,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 130,\n",
       "  'training_loss': 0.6905060483795308,\n",
       "  'eval_loss': 0.6901336635152499,\n",
       "  'eval_f1': 0.47946553376245876,\n",
       "  'eval_mcc': 0.04523496876049953,\n",
       "  'eval_precision': 0.5272930413141835,\n",
       "  'eval_recall': 0.5187444858457834,\n",
       "  'eval_auc': 0.5359998571948726,\n",
       "  'eval_accuracy': 0.5220419753086419,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 131,\n",
       "  'training_loss': 0.6905199760903892,\n",
       "  'eval_loss': 0.6903027109801769,\n",
       "  'eval_f1': 0.47685753018868127,\n",
       "  'eval_mcc': 0.046851270632243196,\n",
       "  'eval_precision': 0.5287252904843155,\n",
       "  'eval_recall': 0.5191056815271324,\n",
       "  'eval_auc': 0.536679741031923,\n",
       "  'eval_accuracy': 0.522511522633745,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 132,\n",
       "  'training_loss': 0.6904690423310494,\n",
       "  'eval_loss': 0.6900064932803313,\n",
       "  'eval_f1': 0.49254189949652033,\n",
       "  'eval_mcc': 0.04691692422273606,\n",
       "  'eval_precision': 0.526758134669805,\n",
       "  'eval_recall': 0.5205667046559871,\n",
       "  'eval_auc': 0.5360849999133901,\n",
       "  'eval_accuracy': 0.5234014917695472,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 133,\n",
       "  'training_loss': 0.6904429148908557,\n",
       "  'eval_loss': 0.690297977377971,\n",
       "  'eval_f1': 0.4776979896695673,\n",
       "  'eval_mcc': 0.04706789987817688,\n",
       "  'eval_precision': 0.5287535779091267,\n",
       "  'eval_recall': 0.5192638802101177,\n",
       "  'eval_auc': 0.5364568668230922,\n",
       "  'eval_accuracy': 0.5226490226337449,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 134,\n",
       "  'training_loss': 0.6904129186805052,\n",
       "  'eval_loss': 0.6901815496385098,\n",
       "  'eval_f1': 0.5077948012958596,\n",
       "  'eval_mcc': 0.048109127538161704,\n",
       "  'eval_precision': 0.525754570209685,\n",
       "  'eval_recall': 0.5224673377422497,\n",
       "  'eval_auc': 0.5363492936316367,\n",
       "  'eval_accuracy': 0.5245792181069958,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 135,\n",
       "  'training_loss': 0.6904329974247518,\n",
       "  'eval_loss': 0.6903934143483639,\n",
       "  'eval_f1': 0.5072541924460893,\n",
       "  'eval_mcc': 0.0481534321280478,\n",
       "  'eval_precision': 0.5258384318694954,\n",
       "  'eval_recall': 0.5224355841426213,\n",
       "  'eval_auc': 0.536372978949691,\n",
       "  'eval_accuracy': 0.5245777263374486,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 136,\n",
       "  'training_loss': 0.6904306981513783,\n",
       "  'eval_loss': 0.6901456452906132,\n",
       "  'eval_f1': 0.5088872318025836,\n",
       "  'eval_mcc': 0.047239727122257436,\n",
       "  'eval_precision': 0.5251244402408678,\n",
       "  'eval_recall': 0.5222057813015002,\n",
       "  'eval_auc': 0.5361218537124873,\n",
       "  'eval_accuracy': 0.5242203703703703,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 137,\n",
       "  'training_loss': 0.6904320297827576,\n",
       "  'eval_loss': 0.6901491073270639,\n",
       "  'eval_f1': 0.5090664946443799,\n",
       "  'eval_mcc': 0.04467974838660993,\n",
       "  'eval_precision': 0.5236273450830907,\n",
       "  'eval_recall': 0.5211229464365571,\n",
       "  'eval_auc': 0.5360697323303515,\n",
       "  'eval_accuracy': 0.5230439814814817,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 138,\n",
       "  'training_loss': 0.6903082231911042,\n",
       "  'eval_loss': 0.6902269447843233,\n",
       "  'eval_f1': 0.5052910317317555,\n",
       "  'eval_mcc': 0.045946094132961524,\n",
       "  'eval_precision': 0.524745732324035,\n",
       "  'eval_recall': 0.5213279112502466,\n",
       "  'eval_auc': 0.5364072780820485,\n",
       "  'eval_accuracy': 0.5235246399176955,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 139,\n",
       "  'training_loss': 0.6904361141530101,\n",
       "  'eval_loss': 0.6901469528675079,\n",
       "  'eval_f1': 0.4931370269364921,\n",
       "  'eval_mcc': 0.04368805003074278,\n",
       "  'eval_precision': 0.5246924252047053,\n",
       "  'eval_recall': 0.5193253267011139,\n",
       "  'eval_auc': 0.5359415695414508,\n",
       "  'eval_accuracy': 0.5220795267489712,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 140,\n",
       "  'training_loss': 0.6904364897590779,\n",
       "  'eval_loss': 0.6901471416155497,\n",
       "  'eval_f1': 0.5098174299086203,\n",
       "  'eval_mcc': 0.04526056129911785,\n",
       "  'eval_precision': 0.5238826203877279,\n",
       "  'eval_recall': 0.5214441059803228,\n",
       "  'eval_auc': 0.5359064602048714,\n",
       "  'eval_accuracy': 0.5233292181069958,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 141,\n",
       "  'training_loss': 0.6903944092947479,\n",
       "  'eval_loss': 0.6902291215956211,\n",
       "  'eval_f1': 0.49791233839576937,\n",
       "  'eval_mcc': 0.046033586306038154,\n",
       "  'eval_precision': 0.5255879840348631,\n",
       "  'eval_recall': 0.520704778113916,\n",
       "  'eval_auc': 0.5367397794884691,\n",
       "  'eval_accuracy': 0.5232730967078187,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 142,\n",
       "  'training_loss': 0.6903704482275482,\n",
       "  'eval_loss': 0.6899368415276209,\n",
       "  'eval_f1': 0.5098310935788218,\n",
       "  'eval_mcc': 0.047382588550545966,\n",
       "  'eval_precision': 0.5251131022358373,\n",
       "  'eval_recall': 0.5223504671888382,\n",
       "  'eval_auc': 0.5371128516125243,\n",
       "  'eval_accuracy': 0.5243109567901234,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 143,\n",
       "  'training_loss': 0.6903061731232292,\n",
       "  'eval_loss': 0.6901580641667048,\n",
       "  'eval_f1': 0.4900372792352398,\n",
       "  'eval_mcc': 0.04621000028043205,\n",
       "  'eval_precision': 0.5266218714187326,\n",
       "  'eval_recall': 0.5200539497038695,\n",
       "  'eval_auc': 0.5370592234036718,\n",
       "  'eval_accuracy': 0.5229773662551439,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 144,\n",
       "  'training_loss': 0.6903682783972083,\n",
       "  'eval_loss': 0.6902206987142563,\n",
       "  'eval_f1': 0.49982594495724303,\n",
       "  'eval_mcc': 0.045950193461772836,\n",
       "  'eval_precision': 0.5253312047488433,\n",
       "  'eval_recall': 0.5208388806746855,\n",
       "  'eval_auc': 0.5362438189668529,\n",
       "  'eval_accuracy': 0.5233179526748971,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 145,\n",
       "  'training_loss': 0.6903862023851435,\n",
       "  'eval_loss': 0.6902047110100588,\n",
       "  'eval_f1': 0.5064428326569368,\n",
       "  'eval_mcc': 0.046470361380012364,\n",
       "  'eval_precision': 0.52493583332199,\n",
       "  'eval_recall': 0.5216509400749694,\n",
       "  'eval_auc': 0.5362303392300991,\n",
       "  'eval_accuracy': 0.5237885802469134,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 146,\n",
       "  'training_loss': 0.6903263882252014,\n",
       "  'eval_loss': 0.690035093575716,\n",
       "  'eval_f1': 0.5019996768223705,\n",
       "  'eval_mcc': 0.045804146892923336,\n",
       "  'eval_precision': 0.5250153430742245,\n",
       "  'eval_recall': 0.5209681169213863,\n",
       "  'eval_auc': 0.53638542388467,\n",
       "  'eval_accuracy': 0.5233461419753088,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 147,\n",
       "  'training_loss': 0.6903121843415457,\n",
       "  'eval_loss': 0.6898843310773373,\n",
       "  'eval_f1': 0.5113463379972594,\n",
       "  'eval_mcc': 0.047009714981629064,\n",
       "  'eval_precision': 0.5247378263400307,\n",
       "  'eval_recall': 0.5223336701064426,\n",
       "  'eval_auc': 0.5370482983808104,\n",
       "  'eval_accuracy': 0.5241741255144035,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 148,\n",
       "  'training_loss': 0.6903444998778766,\n",
       "  'eval_loss': 0.6900215844313303,\n",
       "  'eval_f1': 0.5153143103492468,\n",
       "  'eval_mcc': 0.04740886521393561,\n",
       "  'eval_precision': 0.5245611435016572,\n",
       "  'eval_recall': 0.5228778754099653,\n",
       "  'eval_auc': 0.5364482210569101,\n",
       "  'eval_accuracy': 0.5244263374485597,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 149,\n",
       "  'training_loss': 0.6903751043045327,\n",
       "  'eval_loss': 0.6900400208930174,\n",
       "  'eval_f1': 0.5224420037040605,\n",
       "  'eval_mcc': 0.04785574945118342,\n",
       "  'eval_precision': 0.5240931546300113,\n",
       "  'eval_recall': 0.5237637822803191,\n",
       "  'eval_auc': 0.5368766560932002,\n",
       "  'eval_accuracy': 0.5244532407407407,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 150,\n",
       "  'training_loss': 0.6903066453966906,\n",
       "  'eval_loss': 0.690154142677784,\n",
       "  'eval_f1': 0.5125226348690549,\n",
       "  'eval_mcc': 0.046112849868482055,\n",
       "  'eval_precision': 0.524101491841927,\n",
       "  'eval_recall': 0.5220570170217788,\n",
       "  'eval_auc': 0.5359236982445007,\n",
       "  'eval_accuracy': 0.5237826646090533,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 151,\n",
       "  'training_loss': 0.6902433766566407,\n",
       "  'eval_loss': 0.6900546190639337,\n",
       "  'eval_f1': 0.5120503047990282,\n",
       "  'eval_mcc': 0.0476612105263226,\n",
       "  'eval_precision': 0.5250412899488006,\n",
       "  'eval_recall': 0.5226787849367267,\n",
       "  'eval_auc': 0.5366463519127523,\n",
       "  'eval_accuracy': 0.524490329218107,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 152,\n",
       "  'training_loss': 0.6902971700559912,\n",
       "  'eval_loss': 0.6900741631786028,\n",
       "  'eval_f1': 0.5131982236090545,\n",
       "  'eval_mcc': 0.047104888955219866,\n",
       "  'eval_precision': 0.5246064562894143,\n",
       "  'eval_recall': 0.5225438848644776,\n",
       "  'eval_auc': 0.5368050857089915,\n",
       "  'eval_accuracy': 0.5242527777777778,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 153,\n",
       "  'training_loss': 0.690227648774875,\n",
       "  'eval_loss': 0.6899452296396097,\n",
       "  'eval_f1': 0.5172066730209572,\n",
       "  'eval_mcc': 0.04785612894628788,\n",
       "  'eval_precision': 0.52461998314961,\n",
       "  'eval_recall': 0.5232558394592083,\n",
       "  'eval_auc': 0.5368308519724454,\n",
       "  'eval_accuracy': 0.5246541666666669,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 154,\n",
       "  'training_loss': 0.6902611499042909,\n",
       "  'eval_loss': 0.690094937880834,\n",
       "  'eval_f1': 0.5072639977079573,\n",
       "  'eval_mcc': 0.04619225031946469,\n",
       "  'eval_precision': 0.5246923855864345,\n",
       "  'eval_recall': 0.5216035783816729,\n",
       "  'eval_auc': 0.5370311106055438,\n",
       "  'eval_accuracy': 0.5236967078189301,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 155,\n",
       "  'training_loss': 0.6902722611228164,\n",
       "  'eval_loss': 0.6899835454920927,\n",
       "  'eval_f1': 0.51544304489212,\n",
       "  'eval_mcc': 0.04688307996579081,\n",
       "  'eval_precision': 0.5242500227914777,\n",
       "  'eval_recall': 0.5226602992669892,\n",
       "  'eval_auc': 0.536612089257531,\n",
       "  'eval_accuracy': 0.5241831790123457,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 156,\n",
       "  'training_loss': 0.690263537547428,\n",
       "  'eval_loss': 0.6898794906834761,\n",
       "  'eval_f1': 0.5161502226597006,\n",
       "  'eval_mcc': 0.04658508015361979,\n",
       "  'eval_precision': 0.5240101432792073,\n",
       "  'eval_recall': 0.5225966244332555,\n",
       "  'eval_auc': 0.5370576093622649,\n",
       "  'eval_accuracy': 0.5240358539094653,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 157,\n",
       "  'training_loss': 0.6902587151029547,\n",
       "  'eval_loss': 0.6899896649022897,\n",
       "  'eval_f1': 0.49921552526005913,\n",
       "  'eval_mcc': 0.04647182515702225,\n",
       "  'eval_precision': 0.5257118831429861,\n",
       "  'eval_recall': 0.5209991722637445,\n",
       "  'eval_auc': 0.5368590195624628,\n",
       "  'eval_accuracy': 0.5235274691358024,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 158,\n",
       "  'training_loss': 0.6902124181977557,\n",
       "  'eval_loss': 0.6900045486787955,\n",
       "  'eval_f1': 0.5087422723831704,\n",
       "  'eval_mcc': 0.04762656535719257,\n",
       "  'eval_precision': 0.5253678723479803,\n",
       "  'eval_recall': 0.5223545568346715,\n",
       "  'eval_auc': 0.536651854431263,\n",
       "  'eval_accuracy': 0.5243872942386832,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 159,\n",
       "  'training_loss': 0.690236926493678,\n",
       "  'eval_loss': 0.6900565885007381,\n",
       "  'eval_f1': 0.504084063157083,\n",
       "  'eval_mcc': 0.04687684276400448,\n",
       "  'eval_precision': 0.525429672632287,\n",
       "  'eval_recall': 0.52160378439494,\n",
       "  'eval_auc': 0.5365119820017381,\n",
       "  'eval_accuracy': 0.5238941872427985,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 160,\n",
       "  'training_loss': 0.6902197130594895,\n",
       "  'eval_loss': 0.6899172551929951,\n",
       "  'eval_f1': 0.5231454626126385,\n",
       "  'eval_mcc': 0.047319332451053235,\n",
       "  'eval_precision': 0.5237217133460673,\n",
       "  'eval_recall': 0.5235978048323845,\n",
       "  'eval_auc': 0.5363508006374126,\n",
       "  'eval_accuracy': 0.5240333847736625,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 161,\n",
       "  'training_loss': 0.6902918399348337,\n",
       "  'eval_loss': 0.6898874789476395,\n",
       "  'eval_f1': 0.5114676192622133,\n",
       "  'eval_mcc': 0.04661446998885533,\n",
       "  'eval_precision': 0.5244959723977429,\n",
       "  'eval_recall': 0.5221765962018948,\n",
       "  'eval_auc': 0.536487267857418,\n",
       "  'eval_accuracy': 0.5240005658436214,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 162,\n",
       "  'training_loss': 0.6902968169918193,\n",
       "  'eval_loss': 0.6899260692298412,\n",
       "  'eval_f1': 0.5225049097545179,\n",
       "  'eval_mcc': 0.04687648967043528,\n",
       "  'eval_precision': 0.5235428362916539,\n",
       "  'eval_recall': 0.5233341584413576,\n",
       "  'eval_auc': 0.5366359208481497,\n",
       "  'eval_accuracy': 0.5239091563786008,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 163,\n",
       "  'training_loss': 0.6902686526216653,\n",
       "  'eval_loss': 0.6899776508410772,\n",
       "  'eval_f1': 0.5104522889237985,\n",
       "  'eval_mcc': 0.04513193797716839,\n",
       "  'eval_precision': 0.5237472542611729,\n",
       "  'eval_recall': 0.5214438698983385,\n",
       "  'eval_auc': 0.5362208913631298,\n",
       "  'eval_accuracy': 0.5232907407407409,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 164,\n",
       "  'training_loss': 0.6902122031508355,\n",
       "  'eval_loss': 0.6899945649007956,\n",
       "  'eval_f1': 0.5239185556589805,\n",
       "  'eval_mcc': 0.04806299786096382,\n",
       "  'eval_precision': 0.5240466918749197,\n",
       "  'eval_recall': 0.5240163221519998,\n",
       "  'eval_auc': 0.5370245054570131,\n",
       "  'eval_accuracy': 0.5242395061728394,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 165,\n",
       "  'training_loss': 0.6901990931714493,\n",
       "  'eval_loss': 0.6901202276349068,\n",
       "  'eval_f1': 0.5205447021675466,\n",
       "  'eval_mcc': 0.04634475408568727,\n",
       "  'eval_precision': 0.5234453417747861,\n",
       "  'eval_recall': 0.5229026845018175,\n",
       "  'eval_auc': 0.5362120364414925,\n",
       "  'eval_accuracy': 0.523804012345679,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 166,\n",
       "  'training_loss': 0.6902104477871321,\n",
       "  'eval_loss': 0.689982458949089,\n",
       "  'eval_f1': 0.5071100885073365,\n",
       "  'eval_mcc': 0.045596896691300765,\n",
       "  'eval_precision': 0.5243521465041626,\n",
       "  'eval_recall': 0.5213444096022676,\n",
       "  'eval_auc': 0.5361588403711252,\n",
       "  'eval_accuracy': 0.5234318930041152,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 167,\n",
       "  'training_loss': 0.6902400155631683,\n",
       "  'eval_loss': 0.6898226700723171,\n",
       "  'eval_f1': 0.522469578536655,\n",
       "  'eval_mcc': 0.04717289904766509,\n",
       "  'eval_precision': 0.523710530663184,\n",
       "  'eval_recall': 0.5234630580302647,\n",
       "  'eval_auc': 0.5368937850624028,\n",
       "  'eval_accuracy': 0.5240716563786006,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 168,\n",
       "  'training_loss': 0.6901959775495419,\n",
       "  'eval_loss': 0.6899301595985889,\n",
       "  'eval_f1': 0.5221206319299739,\n",
       "  'eval_mcc': 0.04616818738864675,\n",
       "  'eval_precision': 0.5231443648768906,\n",
       "  'eval_recall': 0.5230239995962587,\n",
       "  'eval_auc': 0.536653544511921,\n",
       "  'eval_accuracy': 0.5226093621399177,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 169,\n",
       "  'training_loss': 0.6901763431434011,\n",
       "  'eval_loss': 0.6899450868368149,\n",
       "  'eval_f1': 0.5206665148194373,\n",
       "  'eval_mcc': 0.046257333258649176,\n",
       "  'eval_precision': 0.5233065217821619,\n",
       "  'eval_recall': 0.5229522158464759,\n",
       "  'eval_auc': 0.5366815932549037,\n",
       "  'eval_accuracy': 0.522229681069959,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 170,\n",
       "  'training_loss': 0.6901730589413034,\n",
       "  'eval_loss': 0.6898590897520384,\n",
       "  'eval_f1': 0.5210796302604995,\n",
       "  'eval_mcc': 0.045807525733488175,\n",
       "  'eval_precision': 0.5230946353447711,\n",
       "  'eval_recall': 0.5227145477919387,\n",
       "  'eval_auc': 0.536760873748402,\n",
       "  'eval_accuracy': 0.523479269547325,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 171,\n",
       "  'training_loss': 0.6901878597011699,\n",
       "  'eval_loss': 0.689845584332943,\n",
       "  'eval_f1': 0.5228624319778103,\n",
       "  'eval_mcc': 0.04868134962296299,\n",
       "  'eval_precision': 0.5245070538727754,\n",
       "  'eval_recall': 0.5241754854627916,\n",
       "  'eval_auc': 0.5371322145809462,\n",
       "  'eval_accuracy': 0.5248579218106997,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 172,\n",
       "  'training_loss': 0.6901408294237407,\n",
       "  'eval_loss': 0.6899899815519651,\n",
       "  'eval_f1': 0.5084973489756214,\n",
       "  'eval_mcc': 0.04699399762792771,\n",
       "  'eval_precision': 0.5250231651674934,\n",
       "  'eval_recall': 0.5220644654751095,\n",
       "  'eval_auc': 0.5365416548968838,\n",
       "  'eval_accuracy': 0.5240998456790122,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 173,\n",
       "  'training_loss': 0.6901108556169921,\n",
       "  'eval_loss': 0.6898702618976434,\n",
       "  'eval_f1': 0.5240311467897241,\n",
       "  'eval_mcc': 0.04814103982586448,\n",
       "  'eval_precision': 0.5240720918736252,\n",
       "  'eval_recall': 0.5240689502153871,\n",
       "  'eval_auc': 0.5370967868180517,\n",
       "  'eval_accuracy': 0.5241544238683129,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 174,\n",
       "  'training_loss': 0.6901730272720142,\n",
       "  'eval_loss': 0.6899497024714947,\n",
       "  'eval_f1': 0.523241153528161,\n",
       "  'eval_mcc': 0.047852815420341345,\n",
       "  'eval_precision': 0.5240070948297643,\n",
       "  'eval_recall': 0.5238460230916538,\n",
       "  'eval_auc': 0.5363703294709402,\n",
       "  'eval_accuracy': 0.5243428497942385,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 175,\n",
       "  'training_loss': 0.6901394847927403,\n",
       "  'eval_loss': 0.6898481287062168,\n",
       "  'eval_f1': 0.5214104547751167,\n",
       "  'eval_mcc': 0.04776779186696448,\n",
       "  'eval_precision': 0.5241475178446786,\n",
       "  'eval_recall': 0.5236232486528548,\n",
       "  'eval_auc': 0.5367033865175298,\n",
       "  'eval_accuracy': 0.5244930041152264,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 176,\n",
       "  'training_loss': 0.6901607920011622,\n",
       "  'eval_loss': 0.6897924828032652,\n",
       "  'eval_f1': 0.5221725717399975,\n",
       "  'eval_mcc': 0.04868873087847939,\n",
       "  'eval_precision': 0.5245832563706524,\n",
       "  'eval_recall': 0.5241078899245327,\n",
       "  'eval_auc': 0.5371627686821419,\n",
       "  'eval_accuracy': 0.5249309156378601,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 177,\n",
       "  'training_loss': 0.6901288318799986,\n",
       "  'eval_loss': 0.6898532745738825,\n",
       "  'eval_f1': 0.5239226383103032,\n",
       "  'eval_mcc': 0.04903578945681789,\n",
       "  'eval_precision': 0.5245901795022704,\n",
       "  'eval_recall': 0.5244458457782661,\n",
       "  'eval_auc': 0.5371675944255279,\n",
       "  'eval_accuracy': 0.5249117283950616,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 178,\n",
       "  'training_loss': 0.6901244525289868,\n",
       "  'eval_loss': 0.689850427210331,\n",
       "  'eval_f1': 0.5230442174410569,\n",
       "  'eval_mcc': 0.04787775803665036,\n",
       "  'eval_precision': 0.5240419648816198,\n",
       "  'eval_recall': 0.523836265274288,\n",
       "  'eval_auc': 0.5369274296323828,\n",
       "  'eval_accuracy': 0.5243904835390948,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 179,\n",
       "  'training_loss': 0.6900950743538045,\n",
       "  'eval_loss': 0.6899313641091188,\n",
       "  'eval_f1': 0.5241655894049267,\n",
       "  'eval_mcc': 0.04851296309590374,\n",
       "  'eval_precision': 0.5242685757930323,\n",
       "  'eval_recall': 0.5242443986722138,\n",
       "  'eval_auc': 0.5367827704915372,\n",
       "  'eval_accuracy': 0.5244502057613167,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 180,\n",
       "  'training_loss': 0.6901205005059386,\n",
       "  'eval_loss': 0.6898466870188713,\n",
       "  'eval_f1': 0.5240608609999953,\n",
       "  'eval_mcc': 0.04888027243980539,\n",
       "  'eval_precision': 0.5244881894288789,\n",
       "  'eval_recall': 0.5243921961399075,\n",
       "  'eval_auc': 0.536878574466183,\n",
       "  'eval_accuracy': 0.5247793724279837,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 181,\n",
       "  'training_loss': 0.6901292067945971,\n",
       "  'eval_loss': 0.6898475016156832,\n",
       "  'eval_f1': 0.5238448213066339,\n",
       "  'eval_mcc': 0.04817684495322366,\n",
       "  'eval_precision': 0.5240966995807075,\n",
       "  'eval_recall': 0.5240801513350976,\n",
       "  'eval_auc': 0.5365304281141959,\n",
       "  'eval_accuracy': 0.5239156893004117,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 182,\n",
       "  'training_loss': 0.6900969664901149,\n",
       "  'eval_loss': 0.6899459895988306,\n",
       "  'eval_f1': 0.5228938333095604,\n",
       "  'eval_mcc': 0.04667574029991925,\n",
       "  'eval_precision': 0.5233605044860492,\n",
       "  'eval_recall': 0.523315267180216,\n",
       "  'eval_auc': 0.5360961737220652,\n",
       "  'eval_accuracy': 0.5230710905349795,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 183,\n",
       "  'training_loss': 0.6900854510386969,\n",
       "  'eval_loss': 0.6900004247824351,\n",
       "  'eval_f1': 0.5221383074711903,\n",
       "  'eval_mcc': 0.04592444890139519,\n",
       "  'eval_precision': 0.5230110185504585,\n",
       "  'eval_recall': 0.5229135515561625,\n",
       "  'eval_auc': 0.5362254996826998,\n",
       "  'eval_accuracy': 0.5225330246913581,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 184,\n",
       "  'training_loss': 0.6900935351433721,\n",
       "  'eval_loss': 0.6899028830230236,\n",
       "  'eval_f1': 0.5238729435484043,\n",
       "  'eval_mcc': 0.048356746394418254,\n",
       "  'eval_precision': 0.5242167853998442,\n",
       "  'eval_recall': 0.5241400383985912,\n",
       "  'eval_auc': 0.5363545773779023,\n",
       "  'eval_accuracy': 0.5244806584362139,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 185,\n",
       "  'training_loss': 0.6900849652124391,\n",
       "  'eval_loss': 0.6898724660277367,\n",
       "  'eval_f1': 0.5239727367090787,\n",
       "  'eval_mcc': 0.048107460126151,\n",
       "  'eval_precision': 0.524064470673333,\n",
       "  'eval_recall': 0.5240430001702157,\n",
       "  'eval_auc': 0.5366036431839148,\n",
       "  'eval_accuracy': 0.524236574074074,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 186,\n",
       "  'training_loss': 0.6901193575073561,\n",
       "  'eval_loss': 0.690014224499464,\n",
       "  'eval_f1': 0.5232561275124074,\n",
       "  'eval_mcc': 0.047275120657798736,\n",
       "  'eval_precision': 0.5236548752894971,\n",
       "  'eval_recall': 0.52362026491891,\n",
       "  'eval_auc': 0.5365863838122683,\n",
       "  'eval_accuracy': 0.5233921296296297,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 187,\n",
       "  'training_loss': 0.6901098540930073,\n",
       "  'eval_loss': 0.6900325405100981,\n",
       "  'eval_f1': 0.5233024245215057,\n",
       "  'eval_mcc': 0.04666422311332271,\n",
       "  'eval_precision': 0.5233312960370805,\n",
       "  'eval_recall': 0.5233329280372493,\n",
       "  'eval_auc': 0.5360531787536057,\n",
       "  'eval_accuracy': 0.523392438271605,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 188,\n",
       "  'training_loss': 0.6900651298653498,\n",
       "  'eval_loss': 0.6898818587263426,\n",
       "  'eval_f1': 0.5232426164434937,\n",
       "  'eval_mcc': 0.04791197249352359,\n",
       "  'eval_precision': 0.5240390965958269,\n",
       "  'eval_recall': 0.5238731970554199,\n",
       "  'eval_auc': 0.5366463342377232,\n",
       "  'eval_accuracy': 0.5243652263374486,\n",
       "  'training_time': '0:00:41',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 189,\n",
       "  'training_loss': 0.6900640900339715,\n",
       "  'eval_loss': 0.6898846042652925,\n",
       "  'eval_f1': 0.5243019075580496,\n",
       "  'eval_mcc': 0.048676717690770414,\n",
       "  'eval_precision': 0.5243385609946536,\n",
       "  'eval_recall': 0.5243381581487353,\n",
       "  'eval_auc': 0.536455138772015,\n",
       "  'eval_accuracy': 0.5244024691358025,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 190,\n",
       "  'training_loss': 0.6900548192298606,\n",
       "  'eval_loss': 0.6898972764611244,\n",
       "  'eval_f1': 0.5199485148070997,\n",
       "  'eval_mcc': 0.046512509272328965,\n",
       "  'eval_precision': 0.5235975695931626,\n",
       "  'eval_recall': 0.522919978181586,\n",
       "  'eval_auc': 0.536032982331846,\n",
       "  'eval_accuracy': 0.5239265946502056,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 191,\n",
       "  'training_loss': 0.6900649246372922,\n",
       "  'eval_loss': 0.6898312705258528,\n",
       "  'eval_f1': 0.5220911814018556,\n",
       "  'eval_mcc': 0.04817599346647335,\n",
       "  'eval_precision': 0.5243055928080045,\n",
       "  'eval_recall': 0.5238724253809739,\n",
       "  'eval_auc': 0.5367117569026844,\n",
       "  'eval_accuracy': 0.5246586419753086,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 192,\n",
       "  'training_loss': 0.6900496578271871,\n",
       "  'eval_loss': 0.6899081021547318,\n",
       "  'eval_f1': 0.5177804140380639,\n",
       "  'eval_mcc': 0.0454298248726305,\n",
       "  'eval_precision': 0.5232048795714462,\n",
       "  'eval_recall': 0.5222354466519713,\n",
       "  'eval_auc': 0.5357853029043084,\n",
       "  'eval_accuracy': 0.5234417695473251,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 193,\n",
       "  'training_loss': 0.6900191240686828,\n",
       "  'eval_loss': 0.6899476796388626,\n",
       "  'eval_f1': 0.5233069876852504,\n",
       "  'eval_mcc': 0.048727136480633516,\n",
       "  'eval_precision': 0.5244846362362291,\n",
       "  'eval_recall': 0.5242431361946994,\n",
       "  'eval_auc': 0.536458562709108,\n",
       "  'eval_accuracy': 0.5248378086419753,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 194,\n",
       "  'training_loss': 0.6900414008552126,\n",
       "  'eval_loss': 0.6900354934235414,\n",
       "  'eval_f1': 0.5232661475497397,\n",
       "  'eval_mcc': 0.047231128770550294,\n",
       "  'eval_precision': 0.5236311375585176,\n",
       "  'eval_recall': 0.5236000085280504,\n",
       "  'eval_auc': 0.5359682286427979,\n",
       "  'eval_accuracy': 0.5233875,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 195,\n",
       "  'training_loss': 0.6900145700525518,\n",
       "  'eval_loss': 0.6898640928169092,\n",
       "  'eval_f1': 0.5234005042225882,\n",
       "  'eval_mcc': 0.04685918839945238,\n",
       "  'eval_precision': 0.5234297656128448,\n",
       "  'eval_recall': 0.5234294238498599,\n",
       "  'eval_auc': 0.5365528213745391,\n",
       "  'eval_accuracy': 0.5235093621399176,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 196,\n",
       "  'training_loss': 0.6900034166544053,\n",
       "  'eval_loss': 0.689843642214934,\n",
       "  'eval_f1': 0.522209587692193,\n",
       "  'eval_mcc': 0.047228497901231174,\n",
       "  'eval_precision': 0.523710248627394,\n",
       "  'eval_recall': 0.5235186741179831,\n",
       "  'eval_auc': 0.5368556845768201,\n",
       "  'eval_accuracy': 0.5229885288065842,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 197,\n",
       "  'training_loss': 0.6900086122156572,\n",
       "  'eval_loss': 0.6898765365282694,\n",
       "  'eval_f1': 0.52328131935692,\n",
       "  'eval_mcc': 0.047581645538194835,\n",
       "  'eval_precision': 0.5238177101924926,\n",
       "  'eval_recall': 0.5237639774880684,\n",
       "  'eval_auc': 0.5368667092555542,\n",
       "  'eval_accuracy': 0.5234858024691358,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 198,\n",
       "  'training_loss': 0.6900040994110904,\n",
       "  'eval_loss': 0.6899845115840435,\n",
       "  'eval_f1': 0.520785531364623,\n",
       "  'eval_mcc': 0.047327000099755684,\n",
       "  'eval_precision': 0.5238826017528622,\n",
       "  'eval_recall': 0.5234464929415196,\n",
       "  'eval_auc': 0.5368758761681441,\n",
       "  'eval_accuracy': 0.5226615226337447,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 199,\n",
       "  'training_loss': 0.6899485839768518,\n",
       "  'eval_loss': 0.6899969664712747,\n",
       "  'eval_f1': 0.522539880383932,\n",
       "  'eval_mcc': 0.04725315196524932,\n",
       "  'eval_precision': 0.5236966771436511,\n",
       "  'eval_recall': 0.5235567016710396,\n",
       "  'eval_auc': 0.5367732512502063,\n",
       "  'eval_accuracy': 0.5231041666666668,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 200,\n",
       "  'training_loss': 0.6900076819129997,\n",
       "  'eval_loss': 0.6898020766675472,\n",
       "  'eval_f1': 0.5250046893646175,\n",
       "  'eval_mcc': 0.05023506330057264,\n",
       "  'eval_precision': 0.5251323255593549,\n",
       "  'eval_recall': 0.5251027539809544,\n",
       "  'eval_auc': 0.5371338708858107,\n",
       "  'eval_accuracy': 0.5253145061728395,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 201,\n",
       "  'training_loss': 0.6899476109413979,\n",
       "  'eval_loss': 0.6898283325135708,\n",
       "  'eval_f1': 0.5222078100020063,\n",
       "  'eval_mcc': 0.048053228387198554,\n",
       "  'eval_precision': 0.5241582445169285,\n",
       "  'eval_recall': 0.5238957535334593,\n",
       "  'eval_auc': 0.5367536025310427,\n",
       "  'eval_accuracy': 0.5232845679012345,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 202,\n",
       "  'training_loss': 0.6899763438375256,\n",
       "  'eval_loss': 0.6899468128879865,\n",
       "  'eval_f1': 0.5234109254972971,\n",
       "  'eval_mcc': 0.04777988499187238,\n",
       "  'eval_precision': 0.5239149159595041,\n",
       "  'eval_recall': 0.5238650048445533,\n",
       "  'eval_auc': 0.5365655737918286,\n",
       "  'eval_accuracy': 0.5235914609053498,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 203,\n",
       "  'training_loss': 0.6899390639672424,\n",
       "  'eval_loss': 0.6899653983612856,\n",
       "  'eval_f1': 0.5227416553001876,\n",
       "  'eval_mcc': 0.04730899681197226,\n",
       "  'eval_precision': 0.5237110791293746,\n",
       "  'eval_recall': 0.5235980730341748,\n",
       "  'eval_auc': 0.5366965873846185,\n",
       "  'eval_accuracy': 0.5231884773662551,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 204,\n",
       "  'training_loss': 0.6900073111472163,\n",
       "  'eval_loss': 0.68994598214825,\n",
       "  'eval_f1': 0.5206651394875444,\n",
       "  'eval_mcc': 0.04746981332884132,\n",
       "  'eval_precision': 0.5239696677649063,\n",
       "  'eval_recall': 0.523502530639258,\n",
       "  'eval_auc': 0.5368384507739722,\n",
       "  'eval_accuracy': 0.5226879629629629,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 205,\n",
       "  'training_loss': 0.6899439651009102,\n",
       "  'eval_loss': 0.6899894302090009,\n",
       "  'eval_f1': 0.5200657198010651,\n",
       "  'eval_mcc': 0.04714237792198441,\n",
       "  'eval_precision': 0.5238427337980022,\n",
       "  'eval_recall': 0.5233028344137726,\n",
       "  'eval_auc': 0.5367452482495191,\n",
       "  'eval_accuracy': 0.5224241769547326,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 206,\n",
       "  'training_loss': 0.6899242016666174,\n",
       "  'eval_loss': 0.6899153937896093,\n",
       "  'eval_f1': 0.5199365452153738,\n",
       "  'eval_mcc': 0.04766268437204509,\n",
       "  'eval_precision': 0.5241376320330812,\n",
       "  'eval_recall': 0.5235290525410692,\n",
       "  'eval_auc': 0.5368335978310484,\n",
       "  'eval_accuracy': 0.5225987139917695,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 207,\n",
       "  'training_loss': 0.6899526570070094,\n",
       "  'eval_loss': 0.6899908011158308,\n",
       "  'eval_f1': 0.5175442201246797,\n",
       "  'eval_mcc': 0.046976088337209454,\n",
       "  'eval_precision': 0.5239703102623289,\n",
       "  'eval_recall': 0.5230156504959557,\n",
       "  'eval_auc': 0.5367468550551846,\n",
       "  'eval_accuracy': 0.5218479938271605,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 208,\n",
       "  'training_loss': 0.6899081082742341,\n",
       "  'eval_loss': 0.6900684783856074,\n",
       "  'eval_f1': 0.5204786815756403,\n",
       "  'eval_mcc': 0.048928366252564574,\n",
       "  'eval_precision': 0.5247886293136499,\n",
       "  'eval_recall': 0.5241440898752651,\n",
       "  'eval_auc': 0.5368449943253658,\n",
       "  'eval_accuracy': 0.523201903292181,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 209,\n",
       "  'training_loss': 0.689956237572805,\n",
       "  'eval_loss': 0.6899244859814644,\n",
       "  'eval_f1': 0.5192567093377441,\n",
       "  'eval_mcc': 0.048855958548620064,\n",
       "  'eval_precision': 0.5248582731997757,\n",
       "  'eval_recall': 0.5240053089690614,\n",
       "  'eval_auc': 0.5370688860797027,\n",
       "  'eval_accuracy': 0.5229229938271605,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 210,\n",
       "  'training_loss': 0.689903237565211,\n",
       "  'eval_loss': 0.6899319862325987,\n",
       "  'eval_f1': 0.5180830952728547,\n",
       "  'eval_mcc': 0.04699766430963529,\n",
       "  'eval_precision': 0.5239340428395093,\n",
       "  'eval_recall': 0.5230716869845945,\n",
       "  'eval_auc': 0.5366889448444869,\n",
       "  'eval_accuracy': 0.5219656378600822,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 211,\n",
       "  'training_loss': 0.6899082940028605,\n",
       "  'eval_loss': 0.6899514446655909,\n",
       "  'eval_f1': 0.5192546071850263,\n",
       "  'eval_mcc': 0.04890533445036074,\n",
       "  'eval_precision': 0.5248846774457929,\n",
       "  'eval_recall': 0.5240283217076024,\n",
       "  'eval_auc': 0.5365804796348753,\n",
       "  'eval_accuracy': 0.522939351851852,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 212,\n",
       "  'training_loss': 0.6899414350151186,\n",
       "  'eval_loss': 0.6899538797636827,\n",
       "  'eval_f1': 0.5212539892627132,\n",
       "  'eval_mcc': 0.049032819341313365,\n",
       "  'eval_precision': 0.5247771280994991,\n",
       "  'eval_recall': 0.5242585263895144,\n",
       "  'eval_auc': 0.5366555772104161,\n",
       "  'eval_accuracy': 0.5234141460905349,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 213,\n",
       "  'training_loss': 0.6899548540812357,\n",
       "  'eval_loss': 0.6899261511862278,\n",
       "  'eval_f1': 0.5191782464575313,\n",
       "  'eval_mcc': 0.04825305870263083,\n",
       "  'eval_precision': 0.5245316722479143,\n",
       "  'eval_recall': 0.5237282118510566,\n",
       "  'eval_auc': 0.5370625558437729,\n",
       "  'eval_accuracy': 0.5226683127572015,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 214,\n",
       "  'training_loss': 0.689890283304688,\n",
       "  'eval_loss': 0.6898761615157127,\n",
       "  'eval_f1': 0.5201185132766517,\n",
       "  'eval_mcc': 0.04871205489629316,\n",
       "  'eval_precision': 0.5247017274627689,\n",
       "  'eval_recall': 0.5240152796426981,\n",
       "  'eval_auc': 0.536790753417536,\n",
       "  'eval_accuracy': 0.5230421296296298,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 215,\n",
       "  'training_loss': 0.689887803557854,\n",
       "  'eval_loss': 0.6898156106472015,\n",
       "  'eval_f1': 0.5205010442656713,\n",
       "  'eval_mcc': 0.048629254413482564,\n",
       "  'eval_precision': 0.5246218225374704,\n",
       "  'eval_recall': 0.524011383944438,\n",
       "  'eval_auc': 0.5373631448286585,\n",
       "  'eval_accuracy': 0.5230882716049383,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 216,\n",
       "  'training_loss': 0.6898622711960511,\n",
       "  'eval_loss': 0.6898034413655599,\n",
       "  'eval_f1': 0.5216714728376934,\n",
       "  'eval_mcc': 0.04855501440133791,\n",
       "  'eval_precision': 0.5244781030516232,\n",
       "  'eval_recall': 0.524078630000662,\n",
       "  'eval_auc': 0.537416913127858,\n",
       "  'eval_accuracy': 0.5233259773662553,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 217,\n",
       "  'training_loss': 0.6898927388501002,\n",
       "  'eval_loss': 0.6898261358340582,\n",
       "  'eval_f1': 0.5218481513238952,\n",
       "  'eval_mcc': 0.04839246876681713,\n",
       "  'eval_precision': 0.5243742907248619,\n",
       "  'eval_recall': 0.5240195444384869,\n",
       "  'eval_auc': 0.5370077918861821,\n",
       "  'eval_accuracy': 0.523310802469136,\n",
       "  'training_time': '0:00:38',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 218,\n",
       "  'training_loss': 0.6898612230670425,\n",
       "  'eval_loss': 0.6898627181847891,\n",
       "  'eval_f1': 0.5222970921592582,\n",
       "  'eval_mcc': 0.048255840945651274,\n",
       "  'eval_precision': 0.5242620580970742,\n",
       "  'eval_recall': 0.5239945781632257,\n",
       "  'eval_auc': 0.5367382489472917,\n",
       "  'eval_accuracy': 0.5233796810699589,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 219,\n",
       "  'training_loss': 0.6898444247909599,\n",
       "  'eval_loss': 0.6898307502269745,\n",
       "  'eval_f1': 0.520937859005318,\n",
       "  'eval_mcc': 0.04745929998191656,\n",
       "  'eval_precision': 0.5239427028038237,\n",
       "  'eval_recall': 0.5235185751175485,\n",
       "  'eval_auc': 0.5367886136560082,\n",
       "  'eval_accuracy': 0.5227480452674896,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 220,\n",
       "  'training_loss': 0.6898084177771743,\n",
       "  'eval_loss': 0.689753836641709,\n",
       "  'eval_f1': 0.5216022991061177,\n",
       "  'eval_mcc': 0.04829433364632372,\n",
       "  'eval_precision': 0.5243422327578062,\n",
       "  'eval_recall': 0.5239537484446882,\n",
       "  'eval_auc': 0.5370898214977287,\n",
       "  'eval_accuracy': 0.5232235082304527,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 221,\n",
       "  'training_loss': 0.6898467448084095,\n",
       "  'eval_loss': 0.6897401909033457,\n",
       "  'eval_f1': 0.5235524042389395,\n",
       "  'eval_mcc': 0.04890125983851745,\n",
       "  'eval_precision': 0.5245083875530292,\n",
       "  'eval_recall': 0.5243930316632525,\n",
       "  'eval_auc': 0.5372758956237904,\n",
       "  'eval_accuracy': 0.5239882716049381,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 222,\n",
       "  'training_loss': 0.689846551473622,\n",
       "  'eval_loss': 0.6897783875465393,\n",
       "  'eval_f1': 0.5227248813570956,\n",
       "  'eval_mcc': 0.04813106845925042,\n",
       "  'eval_precision': 0.5241592482592299,\n",
       "  'eval_recall': 0.5239722254900299,\n",
       "  'eval_auc': 0.5371252468376363,\n",
       "  'eval_accuracy': 0.5234686213991768,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 223,\n",
       "  'training_loss': 0.6898772766307999,\n",
       "  'eval_loss': 0.6897403498490652,\n",
       "  'eval_f1': 0.5241978053303419,\n",
       "  'eval_mcc': 0.048472015882998994,\n",
       "  'eval_precision': 0.5242362150591635,\n",
       "  'eval_recall': 0.5242358023289075,\n",
       "  'eval_auc': 0.5373281144920736,\n",
       "  'eval_accuracy': 0.5242936728395063,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 224,\n",
       "  'training_loss': 0.6898625849847727,\n",
       "  'eval_loss': 0.6898760559658209,\n",
       "  'eval_f1': 0.523963725240302,\n",
       "  'eval_mcc': 0.04828587326660272,\n",
       "  'eval_precision': 0.5241471534454153,\n",
       "  'eval_recall': 0.5241387228066715,\n",
       "  'eval_auc': 0.5372890313912706,\n",
       "  'eval_accuracy': 0.524016255144033,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 225,\n",
       "  'training_loss': 0.6898583382575528,\n",
       "  'eval_loss': 0.689831580966711,\n",
       "  'eval_f1': 0.5237089750194468,\n",
       "  'eval_mcc': 0.0478954478567925,\n",
       "  'eval_precision': 0.5239557503544643,\n",
       "  'eval_recall': 0.5239397040226818,\n",
       "  'eval_auc': 0.5372678733086637,\n",
       "  'eval_accuracy': 0.5237838477366256,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 226,\n",
       "  'training_loss': 0.6898438659455549,\n",
       "  'eval_loss': 0.6897785154481729,\n",
       "  'eval_f1': 0.5246332121002845,\n",
       "  'eval_mcc': 0.04935411892044011,\n",
       "  'eval_precision': 0.5246757639286224,\n",
       "  'eval_recall': 0.5246783556898895,\n",
       "  'eval_auc': 0.5371488403023199,\n",
       "  'eval_accuracy': 0.5246997942386831,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 227,\n",
       "  'training_loss': 0.6898394650207041,\n",
       "  'eval_loss': 0.6897940126558145,\n",
       "  'eval_f1': 0.5242234302606191,\n",
       "  'eval_mcc': 0.04867470405425545,\n",
       "  'eval_precision': 0.5243383484946146,\n",
       "  'eval_recall': 0.5243363569516546,\n",
       "  'eval_auc': 0.5370311167892691,\n",
       "  'eval_accuracy': 0.5242676954732509,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 228,\n",
       "  'training_loss': 0.6898026556260625,\n",
       "  'eval_loss': 0.6897464146216711,\n",
       "  'eval_f1': 0.5241031124132904,\n",
       "  'eval_mcc': 0.04854384083776702,\n",
       "  'eval_precision': 0.5242939431693713,\n",
       "  'eval_recall': 0.5242499276470824,\n",
       "  'eval_auc': 0.5371663674616347,\n",
       "  'eval_accuracy': 0.5245133230452675,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 229,\n",
       "  'training_loss': 0.689801325654209,\n",
       "  'eval_loss': 0.6897899843752384,\n",
       "  'eval_f1': 0.5243180466825031,\n",
       "  'eval_mcc': 0.04874440580277531,\n",
       "  'eval_precision': 0.524371103231937,\n",
       "  'eval_recall': 0.5243733033915646,\n",
       "  'eval_auc': 0.5369142832548712,\n",
       "  'eval_accuracy': 0.5243745884773664,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:06'},\n",
       " {'epoch': 230,\n",
       "  'training_loss': 0.6897861275761421,\n",
       "  'eval_loss': 0.6897076529761156,\n",
       "  'eval_f1': 0.5237450353721999,\n",
       "  'eval_mcc': 0.04782999800203905,\n",
       "  'eval_precision': 0.5239369010130207,\n",
       "  'eval_recall': 0.5238931271307752,\n",
       "  'eval_auc': 0.5371607438376806,\n",
       "  'eval_accuracy': 0.5241544753086421,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 231,\n",
       "  'training_loss': 0.6897650479993798,\n",
       "  'eval_loss': 0.6896802646418413,\n",
       "  'eval_f1': 0.5207569973766893,\n",
       "  'eval_mcc': 0.04776569320116982,\n",
       "  'eval_precision': 0.5242135536230893,\n",
       "  'eval_recall': 0.5235567789133951,\n",
       "  'eval_auc': 0.5372111587735168,\n",
       "  'eval_accuracy': 0.5245299897119343,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 232,\n",
       "  'training_loss': 0.6898022742116534,\n",
       "  'eval_loss': 0.6896175419290861,\n",
       "  'eval_f1': 0.5217698117530961,\n",
       "  'eval_mcc': 0.048645833463475625,\n",
       "  'eval_precision': 0.5245998158652875,\n",
       "  'eval_recall': 0.5240492385401759,\n",
       "  'eval_auc': 0.5372579492291998,\n",
       "  'eval_accuracy': 0.5249317386831276,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 233,\n",
       "  'training_loss': 0.6897906822837423,\n",
       "  'eval_loss': 0.6896249788502852,\n",
       "  'eval_f1': 0.5217749798091971,\n",
       "  'eval_mcc': 0.04902563797912491,\n",
       "  'eval_precision': 0.5248106356630958,\n",
       "  'eval_recall': 0.5242186926943891,\n",
       "  'eval_auc': 0.5374147973228621,\n",
       "  'eval_accuracy': 0.5251304526748971,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 234,\n",
       "  'training_loss': 0.6897907746640269,\n",
       "  'eval_loss': 0.6896177803476652,\n",
       "  'eval_f1': 0.5204361264936478,\n",
       "  'eval_mcc': 0.04850721366257169,\n",
       "  'eval_precision': 0.5246595510046316,\n",
       "  'eval_recall': 0.523854497423569,\n",
       "  'eval_auc': 0.5372646495812615,\n",
       "  'eval_accuracy': 0.5249197016460906,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 235,\n",
       "  'training_loss': 0.6897503376836843,\n",
       "  'eval_loss': 0.6896301334102949,\n",
       "  'eval_f1': 0.5219482105554468,\n",
       "  'eval_mcc': 0.048417141206161994,\n",
       "  'eval_precision': 0.5244535390449788,\n",
       "  'eval_recall': 0.523966142443961,\n",
       "  'eval_auc': 0.537248853654166,\n",
       "  'eval_accuracy': 0.5248024691358025,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 236,\n",
       "  'training_loss': 0.6897432703153163,\n",
       "  'eval_loss': 0.6896128915250301,\n",
       "  'eval_f1': 0.5175988059835629,\n",
       "  'eval_mcc': 0.04821062826874223,\n",
       "  'eval_precision': 0.5247834242858184,\n",
       "  'eval_recall': 0.523446006458578,\n",
       "  'eval_auc': 0.5373350287478037,\n",
       "  'eval_accuracy': 0.5248233539094652,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 237,\n",
       "  'training_loss': 0.6897592627531968,\n",
       "  'eval_loss': 0.6895909644663334,\n",
       "  'eval_f1': 0.5189703408556781,\n",
       "  'eval_mcc': 0.04883959053482253,\n",
       "  'eval_precision': 0.5249955255906222,\n",
       "  'eval_recall': 0.5238575678255465,\n",
       "  'eval_auc': 0.5374073302899691,\n",
       "  'eval_accuracy': 0.5251221193415638,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 238,\n",
       "  'training_loss': 0.6897362738916879,\n",
       "  'eval_loss': 0.6896061661342779,\n",
       "  'eval_f1': 0.5181940664365025,\n",
       "  'eval_mcc': 0.04880784533216289,\n",
       "  'eval_precision': 0.5250576719414622,\n",
       "  'eval_recall': 0.5237674816952608,\n",
       "  'eval_auc': 0.5373907578289984,\n",
       "  'eval_accuracy': 0.52510591563786,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 239,\n",
       "  'training_loss': 0.689735364609694,\n",
       "  'eval_loss': 0.6895812464257082,\n",
       "  'eval_f1': 0.5149433860296213,\n",
       "  'eval_mcc': 0.04748158867335797,\n",
       "  'eval_precision': 0.5246414481279253,\n",
       "  'eval_recall': 0.522873365854288,\n",
       "  'eval_auc': 0.5375172290873993,\n",
       "  'eval_accuracy': 0.5244571502057612,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 240,\n",
       "  'training_loss': 0.6897581880717709,\n",
       "  'eval_loss': 0.689607052753369,\n",
       "  'eval_f1': 0.5100370338773325,\n",
       "  'eval_mcc': 0.04705056445703856,\n",
       "  'eval_precision': 0.524902573986293,\n",
       "  'eval_recall': 0.5222246498399264,\n",
       "  'eval_auc': 0.5374950163334457,\n",
       "  'eval_accuracy': 0.5241647633744856,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 241,\n",
       "  'training_loss': 0.6897260794230238,\n",
       "  'eval_loss': 0.6895965238412222,\n",
       "  'eval_f1': 0.5150714252019842,\n",
       "  'eval_mcc': 0.04779788854831927,\n",
       "  'eval_precision': 0.5248086096273635,\n",
       "  'eval_recall': 0.5230229428007447,\n",
       "  'eval_auc': 0.537449805964883,\n",
       "  'eval_accuracy': 0.5246094135802469,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 242,\n",
       "  'training_loss': 0.689695773434473,\n",
       "  'eval_loss': 0.6896005272865295,\n",
       "  'eval_f1': 0.5163917807687273,\n",
       "  'eval_mcc': 0.04779389450225841,\n",
       "  'eval_precision': 0.5246685634746457,\n",
       "  'eval_recall': 0.5231497453800877,\n",
       "  'eval_auc': 0.5374202085614854,\n",
       "  'eval_accuracy': 0.5246197016460907,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:04'},\n",
       " {'epoch': 243,\n",
       "  'training_loss': 0.6897309202605776,\n",
       "  'eval_loss': 0.6895984783768654,\n",
       "  'eval_f1': 0.516605153777858,\n",
       "  'eval_mcc': 0.048142638289002955,\n",
       "  'eval_precision': 0.5248445036599406,\n",
       "  'eval_recall': 0.5233224682699998,\n",
       "  'eval_auc': 0.5375435886893086,\n",
       "  'eval_accuracy': 0.5247893004115225,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 244,\n",
       "  'training_loss': 0.6896949471287827,\n",
       "  'eval_loss': 0.6895903286834558,\n",
       "  'eval_f1': 0.5167158851346053,\n",
       "  'eval_mcc': 0.0485776712187217,\n",
       "  'eval_precision': 0.5250816491480433,\n",
       "  'eval_recall': 0.5235213532328118,\n",
       "  'eval_auc': 0.5375258329801215,\n",
       "  'eval_accuracy': 0.5249939300411522,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 245,\n",
       "  'training_loss': 0.6896779918891924,\n",
       "  'eval_loss': 0.6895989030599594,\n",
       "  'eval_f1': 0.5215073165750773,\n",
       "  'eval_mcc': 0.04957489907955567,\n",
       "  'eval_precision': 0.5251447360628753,\n",
       "  'eval_recall': 0.5244353748379201,\n",
       "  'eval_auc': 0.5374248050221292,\n",
       "  'eval_accuracy': 0.5254338477366255,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 246,\n",
       "  'training_loss': 0.6897024604947827,\n",
       "  'eval_loss': 0.6895945432285467,\n",
       "  'eval_f1': 0.5225616537986438,\n",
       "  'eval_mcc': 0.04858022137661657,\n",
       "  'eval_precision': 0.5244817484460054,\n",
       "  'eval_recall': 0.5241000383224873,\n",
       "  'eval_auc': 0.537555145289437,\n",
       "  'eval_accuracy': 0.5248382716049382,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 247,\n",
       "  'training_loss': 0.6897032700669185,\n",
       "  'eval_loss': 0.689615352700154,\n",
       "  'eval_f1': 0.5243067780663032,\n",
       "  'eval_mcc': 0.04907164846725589,\n",
       "  'eval_precision': 0.5245654443611371,\n",
       "  'eval_recall': 0.5245062534284289,\n",
       "  'eval_auc': 0.53752219633307,\n",
       "  'eval_accuracy': 0.5248007201646091,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 248,\n",
       "  'training_loss': 0.6896912732146455,\n",
       "  'eval_loss': 0.6896205246448517,\n",
       "  'eval_f1': 0.5246082583923799,\n",
       "  'eval_mcc': 0.049354265200323065,\n",
       "  'eval_precision': 0.5246761006393678,\n",
       "  'eval_recall': 0.5246781652424913,\n",
       "  'eval_auc': 0.5375654721749784,\n",
       "  'eval_accuracy': 0.5246554012345679,\n",
       "  'training_time': '0:00:39',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 249,\n",
       "  'training_loss': 0.6896830468056097,\n",
       "  'eval_loss': 0.6896495272715887,\n",
       "  'eval_f1': 0.5240078298897847,\n",
       "  'eval_mcc': 0.04884120376327435,\n",
       "  'eval_precision': 0.5244408321077272,\n",
       "  'eval_recall': 0.5244003961794089,\n",
       "  'eval_auc': 0.5375198740807682,\n",
       "  'eval_accuracy': 0.5241549382716048,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'},\n",
       " {'epoch': 250,\n",
       "  'training_loss': 0.6896718076652828,\n",
       "  'eval_loss': 0.6896807538966337,\n",
       "  'eval_f1': 0.5227784237956916,\n",
       "  'eval_mcc': 0.04854948693775135,\n",
       "  'eval_precision': 0.524380646307366,\n",
       "  'eval_recall': 0.5241693401687926,\n",
       "  'eval_auc': 0.5375334747815499,\n",
       "  'eval_accuracy': 0.523618878600823,\n",
       "  'training_time': '0:00:40',\n",
       "  'eval_time': '0:00:05'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this to train from scratch\n",
    "trainer.train ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:17:39.280878Z",
     "iopub.status.busy": "2021-01-17T10:17:39.280107Z",
     "iopub.status.idle": "2021-01-17T10:17:39.284259Z",
     "shell.execute_reply": "2021-01-17T10:17:39.283601Z"
    },
    "papermill": {
     "duration": 1.178727,
     "end_time": "2021-01-17T10:17:39.284382",
     "exception": false,
     "start_time": "2021-01-17T10:17:38.105655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5897"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this to train from scratch\n",
    "# Load the best model so far\n",
    "# del model\n",
    "gc.collect ()\n",
    "# model = Clf_Model ()\n",
    "# try:\n",
    "#     model.load_state_dict (torch.load (\"jane_embed_nn_model_rishi.pt\"))\n",
    "# except:\n",
    "#     model.load_state_dict (torch.load (\"jane_embed_nn_model_rishi.pt\", map_location='cpu'))\n",
    "# model = model.float ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:17:41.101492Z",
     "iopub.status.busy": "2021-01-17T10:17:41.100673Z",
     "iopub.status.idle": "2021-01-17T10:17:41.104621Z",
     "shell.execute_reply": "2021-01-17T10:17:41.103942Z"
    },
    "papermill": {
     "duration": 0.919363,
     "end_time": "2021-01-17T10:17:41.104802",
     "exception": false,
     "start_time": "2021-01-17T10:17:40.185439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments (\n",
    "\n",
    "    output_dir      = './results',     # output directory\n",
    "    num_train_epochs= 2,               # for training from scratch\n",
    "    warmup_steps    = 20,              # for lr scheduling\n",
    "    eval_steps      = 0,               # Number of update steps between two evaluations, if <=0 then eval at end of each epoch\n",
    "    max_steps       = 0,               # If set to a positive number, the total number of training steps to perform. Overrides num_train_epochs\n",
    "    learning_rate   = 5e-4,            # Actually = 1e-2 for training from scratch, without using the jane_embed_nn_model_rishi.pt\n",
    "    # adam_epsilon  = 1e-8             # - default is 1e-8 is “a very small number to prevent any division by zero\"\n",
    "    per_device_train_batch_size= 5000, # batch size per device during training\n",
    "    per_device_eval_batch_size = 5000, # batch size for evaluation\n",
    ")\n",
    "trainer = MyTrainer (\n",
    "    \n",
    "    model         = model,           # the instantiated 🤗 Transformers model to be trained\n",
    "    args          = training_args,   # training arguments, defined above\n",
    "    train_dataset = eval_dataset,    # training dataset\n",
    "    eval_dataset  = None,            # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:17:42.923883Z",
     "iopub.status.busy": "2021-01-17T10:17:42.922767Z",
     "iopub.status.idle": "2021-01-17T10:17:51.937347Z",
     "shell.execute_reply": "2021-01-17T10:17:51.936572Z"
    },
    "papermill": {
     "duration": 9.924201,
     "end_time": "2021-01-17T10:17:51.937514",
     "exception": false,
     "start_time": "2021-01-17T10:17:42.013313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    50  of     48.    Elapsed: 0:00:00.\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:05\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:00:09 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccs       : -1\n",
      "accuracies : -1\n",
      "precisions : -1\n",
      "recalls    : -1\n",
      "f1_scores  : -1\n",
      "auc        : -1\n",
      "losses     : -1\n",
      "tr_losses  : [0.6899628813068072, 0.6899352396527926]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'epoch': 1, 'training_loss': 0.6899628813068072, 'training_time': '0:00:04'},\n",
       " {'epoch': 2, 'training_loss': 0.6899352396527926, 'training_time': '0:00:05'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uncomment this to train from scratch\n",
    "trainer.train ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.899121,
     "end_time": "2021-01-17T10:17:53.741704",
     "exception": false,
     "start_time": "2021-01-17T10:17:52.842583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:17:55.552633Z",
     "iopub.status.busy": "2021-01-17T10:17:55.551888Z",
     "iopub.status.idle": "2021-01-17T10:17:55.581758Z",
     "shell.execute_reply": "2021-01-17T10:17:55.580992Z"
    },
    "papermill": {
     "duration": 0.941792,
     "end_time": "2021-01-17T10:17:55.581901",
     "exception": false,
     "start_time": "2021-01-17T10:17:54.640109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import janestreet\n",
    "env      = janestreet.make_env() # initialize the environment\n",
    "env_iter = env.iter_test() # an iterator which loops over the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.908101,
     "end_time": "2021-01-17T10:17:57.398403",
     "exception": false,
     "start_time": "2021-01-17T10:17:56.490302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# For direct submission, without using the Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:17:59.266753Z",
     "iopub.status.busy": "2021-01-17T10:17:59.264324Z",
     "iopub.status.idle": "2021-01-17T10:21:59.655405Z",
     "shell.execute_reply": "2021-01-17T10:21:59.653800Z"
    },
    "papermill": {
     "duration": 241.338652,
     "end_time": "2021-01-17T10:21:59.655567",
     "exception": false,
     "start_time": "2021-01-17T10:17:58.316915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for test_df, pred_df in env_iter:\n",
    "    if test_df[\"weight\"].item () > 0:\n",
    "        \n",
    "        test_df.drop (columns=['weight', 'date'], inplace=True)\n",
    "        test_df.reset_index (drop=True, inplace=True)\n",
    "        test_df = preprocess_pipe.transform (test_df)        \n",
    "        test_dataset = JaneDataset (test_df)\n",
    "        pred = []\n",
    "        for i in range (len (test_dataset)):\n",
    "            \n",
    "            batch = test_dataset[i]\n",
    "            # Add batch to GPU\n",
    "            for k in batch:\n",
    "                batch[k] = torch.tensor (batch[k]).to (DEVICE).float ()\n",
    "            pred_logits  = model (**batch).logits.detach ().cpu ().numpy ()\n",
    "            pred.append (pred_logits)\n",
    "        \n",
    "        pred_logits    = np.concatenate (pred, axis=0).reshape ((-1, 2))\n",
    "        pred_labels    = np.argmax (pred_logits, axis=1).flatten ()\n",
    "        pred_df.action = pred_labels.astype (int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "        \n",
    "    # print (pred_df)\n",
    "    # print (\"--------------\")\n",
    "    env.predict (pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T10:22:01.626253Z",
     "iopub.status.busy": "2021-01-17T10:22:01.625492Z",
     "iopub.status.idle": "2021-01-17T10:22:01.628427Z",
     "shell.execute_reply": "2021-01-17T10:22:01.629022Z"
    },
    "papermill": {
     "duration": 1.034904,
     "end_time": "2021-01-17T10:22:01.629196",
     "exception": false,
     "start_time": "2021-01-17T10:22:00.594292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print ('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.902705,
     "end_time": "2021-01-17T10:22:03.438656",
     "exception": false,
     "start_time": "2021-01-17T10:22:02.535951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 11419.808852,
   "end_time": "2021-01-17T10:22:04.552514",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-17T07:11:44.743662",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
